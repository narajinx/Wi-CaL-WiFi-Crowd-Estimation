{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# regressors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "\n",
    "# for results\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "division = 'm'  # s or m (s = small-sized meeting room, m = medium-sized seminar room)\n",
    "\n",
    "# session 1\n",
    "if division == 's':\n",
    "    l = glob.glob(r'..\\..\\datasets\\small-room\\sess1\\S=*.csv')\n",
    "elif division == 'm':\n",
    "    l = glob.glob(r'..\\..\\datasets\\medium-room\\sess1\\S=*.csv')\n",
    "l.sort()\n",
    "\n",
    "df_fea_sess1 = []\n",
    "for i in l:\n",
    "    df_fea_sess1.append(pd.read_csv(i, header=None))\n",
    "\n",
    "# session 2\n",
    "if division == 's':\n",
    "    l = glob.glob(r'..\\..\\datasets\\small-room\\sess2\\S=*.csv')\n",
    "elif division == 'm':\n",
    "    l = glob.glob(r'..\\..\\datasets\\medium-room\\sess2\\S=*.csv')\n",
    "l.sort()\n",
    "\n",
    "df_fea_sess2 = []\n",
    "for i in l:\n",
    "    df_fea_sess2.append(pd.read_csv(i, header=None))\n",
    "    \n",
    "# session 3\n",
    "if division == 's':\n",
    "    l = glob.glob(r'..\\..\\datasets\\small-room\\sess3\\S=*.csv')\n",
    "elif division == 'm':\n",
    "    l = glob.glob(r'..\\..\\datasets\\medium-room\\sess3\\S=*.csv')\n",
    "l.sort()\n",
    "\n",
    "df_fea_sess3 = []\n",
    "for i in l:\n",
    "    df_fea_sess3.append(pd.read_csv(i, header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\S=0.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\S=1.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\S=2.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\S=3.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\S=4.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select session (sess1, sess2, sess3)\n",
    "\n",
    "df_fea = df_fea_sess1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 357)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column label (feature name)\n",
    "# l(N1)_xxx(N2) >> N1: link number, N2: subcarrier number.\n",
    "\n",
    "nof_link = 4\n",
    "nof_usedsubc = 13\n",
    "\n",
    "col_label = []\n",
    "\n",
    "for i in range(nof_link):\n",
    "    \n",
    "    for j in range(nof_usedsubc):\n",
    "        col_label.append('l%d_std%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_min%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_max%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_qtl%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_qtu%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_avg%d' %(i+1,j+1))\n",
    "        \n",
    "    for j in range(6):\n",
    "        col_label.append('l%d_cur%d' %(i+1,j+1))\n",
    "    for j in range(5):\n",
    "        col_label.append('l%d_der%d' %(i+1,j+1))    \n",
    "\n",
    "len(col_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column label\n",
    "\n",
    "for i in range(len(df_fea)):\n",
    "    df_fea[i].columns = col_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>l1_qtl2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_cur2</th>\n",
       "      <th>l4_cur3</th>\n",
       "      <th>l4_cur4</th>\n",
       "      <th>l4_cur5</th>\n",
       "      <th>l4_cur6</th>\n",
       "      <th>l4_der1</th>\n",
       "      <th>l4_der2</th>\n",
       "      <th>l4_der3</th>\n",
       "      <th>l4_der4</th>\n",
       "      <th>l4_der5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.461229</td>\n",
       "      <td>1.403337</td>\n",
       "      <td>1.329958</td>\n",
       "      <td>1.183326</td>\n",
       "      <td>1.083925</td>\n",
       "      <td>1.030910</td>\n",
       "      <td>1.060135</td>\n",
       "      <td>0.948225</td>\n",
       "      <td>0.944712</td>\n",
       "      <td>0.878323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.001783</td>\n",
       "      <td>0.071555</td>\n",
       "      <td>-0.451787</td>\n",
       "      <td>9.110630</td>\n",
       "      <td>8.476972e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>-0.451787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.206355</td>\n",
       "      <td>1.028218</td>\n",
       "      <td>0.993922</td>\n",
       "      <td>0.874931</td>\n",
       "      <td>0.872215</td>\n",
       "      <td>0.911993</td>\n",
       "      <td>0.961354</td>\n",
       "      <td>0.854425</td>\n",
       "      <td>0.843202</td>\n",
       "      <td>0.776964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>0.079066</td>\n",
       "      <td>-0.526390</td>\n",
       "      <td>10.690206</td>\n",
       "      <td>-2.650281e-07</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-0.007657</td>\n",
       "      <td>0.158133</td>\n",
       "      <td>-0.526390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747694</td>\n",
       "      <td>0.706687</td>\n",
       "      <td>0.675697</td>\n",
       "      <td>0.677832</td>\n",
       "      <td>0.596699</td>\n",
       "      <td>0.656809</td>\n",
       "      <td>0.696858</td>\n",
       "      <td>0.723022</td>\n",
       "      <td>0.759360</td>\n",
       "      <td>0.710899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.003094</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>-0.587742</td>\n",
       "      <td>10.941266</td>\n",
       "      <td>-7.766324e-07</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.009282</td>\n",
       "      <td>0.175934</td>\n",
       "      <td>-0.587742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680562</td>\n",
       "      <td>0.652428</td>\n",
       "      <td>0.617645</td>\n",
       "      <td>0.655980</td>\n",
       "      <td>0.595589</td>\n",
       "      <td>0.618400</td>\n",
       "      <td>0.705216</td>\n",
       "      <td>0.705249</td>\n",
       "      <td>0.719335</td>\n",
       "      <td>0.599678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.002280</td>\n",
       "      <td>0.079904</td>\n",
       "      <td>-0.622525</td>\n",
       "      <td>10.893866</td>\n",
       "      <td>1.265775e-07</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.006841</td>\n",
       "      <td>0.159808</td>\n",
       "      <td>-0.622525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.418847</td>\n",
       "      <td>1.444397</td>\n",
       "      <td>1.328114</td>\n",
       "      <td>1.280205</td>\n",
       "      <td>1.189202</td>\n",
       "      <td>1.207989</td>\n",
       "      <td>1.236722</td>\n",
       "      <td>1.037668</td>\n",
       "      <td>1.032366</td>\n",
       "      <td>0.900402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>0.069126</td>\n",
       "      <td>-0.568937</td>\n",
       "      <td>10.664818</td>\n",
       "      <td>9.074015e-07</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.004569</td>\n",
       "      <td>0.138252</td>\n",
       "      <td>-0.568937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2.234998</td>\n",
       "      <td>1.952983</td>\n",
       "      <td>1.642235</td>\n",
       "      <td>1.552838</td>\n",
       "      <td>1.686878</td>\n",
       "      <td>2.188347</td>\n",
       "      <td>2.466221</td>\n",
       "      <td>2.025162</td>\n",
       "      <td>1.933353</td>\n",
       "      <td>1.760320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>0.049112</td>\n",
       "      <td>-0.179824</td>\n",
       "      <td>10.048577</td>\n",
       "      <td>-3.035061e-07</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.005625</td>\n",
       "      <td>0.098223</td>\n",
       "      <td>-0.179824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2.136482</td>\n",
       "      <td>2.112427</td>\n",
       "      <td>1.756895</td>\n",
       "      <td>1.640038</td>\n",
       "      <td>1.605874</td>\n",
       "      <td>2.040877</td>\n",
       "      <td>2.245979</td>\n",
       "      <td>1.822832</td>\n",
       "      <td>1.856636</td>\n",
       "      <td>1.732509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>0.020199</td>\n",
       "      <td>0.219921</td>\n",
       "      <td>8.553810</td>\n",
       "      <td>-3.865501e-08</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.003129</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>0.219921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2.320379</td>\n",
       "      <td>2.269228</td>\n",
       "      <td>1.839009</td>\n",
       "      <td>1.702551</td>\n",
       "      <td>1.535080</td>\n",
       "      <td>1.516574</td>\n",
       "      <td>1.428790</td>\n",
       "      <td>1.220235</td>\n",
       "      <td>1.294640</td>\n",
       "      <td>1.203857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>0.070145</td>\n",
       "      <td>-0.218774</td>\n",
       "      <td>8.743192</td>\n",
       "      <td>-1.336387e-06</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.009325</td>\n",
       "      <td>0.140289</td>\n",
       "      <td>-0.218774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2.107777</td>\n",
       "      <td>1.920989</td>\n",
       "      <td>1.682704</td>\n",
       "      <td>1.690026</td>\n",
       "      <td>1.659764</td>\n",
       "      <td>1.700245</td>\n",
       "      <td>1.649740</td>\n",
       "      <td>1.328510</td>\n",
       "      <td>1.216458</td>\n",
       "      <td>1.217324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.004302</td>\n",
       "      <td>0.102801</td>\n",
       "      <td>-0.535439</td>\n",
       "      <td>8.660696</td>\n",
       "      <td>-1.910258e-06</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>-0.012905</td>\n",
       "      <td>0.205601</td>\n",
       "      <td>-0.535439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2.135057</td>\n",
       "      <td>2.084120</td>\n",
       "      <td>1.973285</td>\n",
       "      <td>1.859319</td>\n",
       "      <td>1.853333</td>\n",
       "      <td>1.854966</td>\n",
       "      <td>1.956917</td>\n",
       "      <td>1.716792</td>\n",
       "      <td>1.669001</td>\n",
       "      <td>1.492656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.002610</td>\n",
       "      <td>0.059049</td>\n",
       "      <td>-0.154157</td>\n",
       "      <td>8.851754</td>\n",
       "      <td>-1.147777e-06</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-0.007830</td>\n",
       "      <td>0.118099</td>\n",
       "      <td>-0.154157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_std2  \\\n",
       "0    1.461229  1.403337  1.329958  1.183326  1.083925  1.030910  1.060135   \n",
       "1    1.206355  1.028218  0.993922  0.874931  0.872215  0.911993  0.961354   \n",
       "2    0.747694  0.706687  0.675697  0.677832  0.596699  0.656809  0.696858   \n",
       "3    0.680562  0.652428  0.617645  0.655980  0.595589  0.618400  0.705216   \n",
       "4    1.418847  1.444397  1.328114  1.280205  1.189202  1.207989  1.236722   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "394  2.234998  1.952983  1.642235  1.552838  1.686878  2.188347  2.466221   \n",
       "395  2.136482  2.112427  1.756895  1.640038  1.605874  2.040877  2.245979   \n",
       "396  2.320379  2.269228  1.839009  1.702551  1.535080  1.516574  1.428790   \n",
       "397  2.107777  1.920989  1.682704  1.690026  1.659764  1.700245  1.649740   \n",
       "398  2.135057  2.084120  1.973285  1.859319  1.853333  1.854966  1.956917   \n",
       "\n",
       "      l1_min2   l1_max2   l1_qtl2  ...   l4_cur2   l4_cur3   l4_cur4  \\\n",
       "0    0.948225  0.944712  0.878323  ...  0.000003 -0.001783  0.071555   \n",
       "1    0.854425  0.843202  0.776964  ...  0.000027 -0.002552  0.079066   \n",
       "2    0.723022  0.759360  0.710899  ...  0.000040 -0.003094  0.087967   \n",
       "3    0.705249  0.719335  0.599678  ...  0.000018 -0.002280  0.079904   \n",
       "4    1.037668  1.032366  0.900402  ... -0.000001 -0.001523  0.069126   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "394  2.025162  1.933353  1.760320  ...  0.000023 -0.001875  0.049112   \n",
       "395  1.822832  1.856636  1.732509  ...  0.000012 -0.001043  0.020199   \n",
       "396  1.220235  1.294640  1.203857  ...  0.000050 -0.003108  0.070145   \n",
       "397  1.328510  1.216458  1.217324  ...  0.000069 -0.004302  0.102801   \n",
       "398  1.716792  1.669001  1.492656  ...  0.000042 -0.002610  0.059049   \n",
       "\n",
       "      l4_cur5    l4_cur6       l4_der1   l4_der2   l4_der3   l4_der4   l4_der5  \n",
       "0   -0.451787   9.110630  8.476972e-07  0.000011 -0.005350  0.143110 -0.451787  \n",
       "1   -0.526390  10.690206 -2.650281e-07  0.000107 -0.007657  0.158133 -0.526390  \n",
       "2   -0.587742  10.941266 -7.766324e-07  0.000158 -0.009282  0.175934 -0.587742  \n",
       "3   -0.622525  10.893866  1.265775e-07  0.000071 -0.006841  0.159808 -0.622525  \n",
       "4   -0.568937  10.664818  9.074015e-07 -0.000005 -0.004569  0.138252 -0.568937  \n",
       "..        ...        ...           ...       ...       ...       ...       ...  \n",
       "394 -0.179824  10.048577 -3.035061e-07  0.000090 -0.005625  0.098223 -0.179824  \n",
       "395  0.219921   8.553810 -3.865501e-08  0.000048 -0.003129  0.040398  0.219921  \n",
       "396 -0.218774   8.743192 -1.336387e-06  0.000199 -0.009325  0.140289 -0.218774  \n",
       "397 -0.535439   8.660696 -1.910258e-06  0.000275 -0.012905  0.205601 -0.535439  \n",
       "398 -0.154157   8.851754 -1.147777e-06  0.000168 -0.007830  0.118099 -0.154157  \n",
       "\n",
       "[399 rows x 356 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "\n",
    "for i in range(len(df_fea)):\n",
    "    df_fea[i]['S'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>l1_qtl2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_cur3</th>\n",
       "      <th>l4_cur4</th>\n",
       "      <th>l4_cur5</th>\n",
       "      <th>l4_cur6</th>\n",
       "      <th>l4_der1</th>\n",
       "      <th>l4_der2</th>\n",
       "      <th>l4_der3</th>\n",
       "      <th>l4_der4</th>\n",
       "      <th>l4_der5</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.461229</td>\n",
       "      <td>1.403337</td>\n",
       "      <td>1.329958</td>\n",
       "      <td>1.183326</td>\n",
       "      <td>1.083925</td>\n",
       "      <td>1.030910</td>\n",
       "      <td>1.060135</td>\n",
       "      <td>0.948225</td>\n",
       "      <td>0.944712</td>\n",
       "      <td>0.878323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001783</td>\n",
       "      <td>0.071555</td>\n",
       "      <td>-0.451787</td>\n",
       "      <td>9.110630</td>\n",
       "      <td>8.476972e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>-0.451787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.206355</td>\n",
       "      <td>1.028218</td>\n",
       "      <td>0.993922</td>\n",
       "      <td>0.874931</td>\n",
       "      <td>0.872215</td>\n",
       "      <td>0.911993</td>\n",
       "      <td>0.961354</td>\n",
       "      <td>0.854425</td>\n",
       "      <td>0.843202</td>\n",
       "      <td>0.776964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>0.079066</td>\n",
       "      <td>-0.526390</td>\n",
       "      <td>10.690206</td>\n",
       "      <td>-2.650281e-07</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-0.007657</td>\n",
       "      <td>0.158133</td>\n",
       "      <td>-0.526390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747694</td>\n",
       "      <td>0.706687</td>\n",
       "      <td>0.675697</td>\n",
       "      <td>0.677832</td>\n",
       "      <td>0.596699</td>\n",
       "      <td>0.656809</td>\n",
       "      <td>0.696858</td>\n",
       "      <td>0.723022</td>\n",
       "      <td>0.759360</td>\n",
       "      <td>0.710899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003094</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>-0.587742</td>\n",
       "      <td>10.941266</td>\n",
       "      <td>-7.766324e-07</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.009282</td>\n",
       "      <td>0.175934</td>\n",
       "      <td>-0.587742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680562</td>\n",
       "      <td>0.652428</td>\n",
       "      <td>0.617645</td>\n",
       "      <td>0.655980</td>\n",
       "      <td>0.595589</td>\n",
       "      <td>0.618400</td>\n",
       "      <td>0.705216</td>\n",
       "      <td>0.705249</td>\n",
       "      <td>0.719335</td>\n",
       "      <td>0.599678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002280</td>\n",
       "      <td>0.079904</td>\n",
       "      <td>-0.622525</td>\n",
       "      <td>10.893866</td>\n",
       "      <td>1.265775e-07</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.006841</td>\n",
       "      <td>0.159808</td>\n",
       "      <td>-0.622525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.418847</td>\n",
       "      <td>1.444397</td>\n",
       "      <td>1.328114</td>\n",
       "      <td>1.280205</td>\n",
       "      <td>1.189202</td>\n",
       "      <td>1.207989</td>\n",
       "      <td>1.236722</td>\n",
       "      <td>1.037668</td>\n",
       "      <td>1.032366</td>\n",
       "      <td>0.900402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>0.069126</td>\n",
       "      <td>-0.568937</td>\n",
       "      <td>10.664818</td>\n",
       "      <td>9.074015e-07</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.004569</td>\n",
       "      <td>0.138252</td>\n",
       "      <td>-0.568937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2.234998</td>\n",
       "      <td>1.952983</td>\n",
       "      <td>1.642235</td>\n",
       "      <td>1.552838</td>\n",
       "      <td>1.686878</td>\n",
       "      <td>2.188347</td>\n",
       "      <td>2.466221</td>\n",
       "      <td>2.025162</td>\n",
       "      <td>1.933353</td>\n",
       "      <td>1.760320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>0.049112</td>\n",
       "      <td>-0.179824</td>\n",
       "      <td>10.048577</td>\n",
       "      <td>-3.035061e-07</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.005625</td>\n",
       "      <td>0.098223</td>\n",
       "      <td>-0.179824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2.136482</td>\n",
       "      <td>2.112427</td>\n",
       "      <td>1.756895</td>\n",
       "      <td>1.640038</td>\n",
       "      <td>1.605874</td>\n",
       "      <td>2.040877</td>\n",
       "      <td>2.245979</td>\n",
       "      <td>1.822832</td>\n",
       "      <td>1.856636</td>\n",
       "      <td>1.732509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>0.020199</td>\n",
       "      <td>0.219921</td>\n",
       "      <td>8.553810</td>\n",
       "      <td>-3.865501e-08</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.003129</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>0.219921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2.320379</td>\n",
       "      <td>2.269228</td>\n",
       "      <td>1.839009</td>\n",
       "      <td>1.702551</td>\n",
       "      <td>1.535080</td>\n",
       "      <td>1.516574</td>\n",
       "      <td>1.428790</td>\n",
       "      <td>1.220235</td>\n",
       "      <td>1.294640</td>\n",
       "      <td>1.203857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>0.070145</td>\n",
       "      <td>-0.218774</td>\n",
       "      <td>8.743192</td>\n",
       "      <td>-1.336387e-06</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.009325</td>\n",
       "      <td>0.140289</td>\n",
       "      <td>-0.218774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2.107777</td>\n",
       "      <td>1.920989</td>\n",
       "      <td>1.682704</td>\n",
       "      <td>1.690026</td>\n",
       "      <td>1.659764</td>\n",
       "      <td>1.700245</td>\n",
       "      <td>1.649740</td>\n",
       "      <td>1.328510</td>\n",
       "      <td>1.216458</td>\n",
       "      <td>1.217324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004302</td>\n",
       "      <td>0.102801</td>\n",
       "      <td>-0.535439</td>\n",
       "      <td>8.660696</td>\n",
       "      <td>-1.910258e-06</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>-0.012905</td>\n",
       "      <td>0.205601</td>\n",
       "      <td>-0.535439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2.135057</td>\n",
       "      <td>2.084120</td>\n",
       "      <td>1.973285</td>\n",
       "      <td>1.859319</td>\n",
       "      <td>1.853333</td>\n",
       "      <td>1.854966</td>\n",
       "      <td>1.956917</td>\n",
       "      <td>1.716792</td>\n",
       "      <td>1.669001</td>\n",
       "      <td>1.492656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002610</td>\n",
       "      <td>0.059049</td>\n",
       "      <td>-0.154157</td>\n",
       "      <td>8.851754</td>\n",
       "      <td>-1.147777e-06</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>-0.007830</td>\n",
       "      <td>0.118099</td>\n",
       "      <td>-0.154157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_std2  \\\n",
       "0    1.461229  1.403337  1.329958  1.183326  1.083925  1.030910  1.060135   \n",
       "1    1.206355  1.028218  0.993922  0.874931  0.872215  0.911993  0.961354   \n",
       "2    0.747694  0.706687  0.675697  0.677832  0.596699  0.656809  0.696858   \n",
       "3    0.680562  0.652428  0.617645  0.655980  0.595589  0.618400  0.705216   \n",
       "4    1.418847  1.444397  1.328114  1.280205  1.189202  1.207989  1.236722   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "394  2.234998  1.952983  1.642235  1.552838  1.686878  2.188347  2.466221   \n",
       "395  2.136482  2.112427  1.756895  1.640038  1.605874  2.040877  2.245979   \n",
       "396  2.320379  2.269228  1.839009  1.702551  1.535080  1.516574  1.428790   \n",
       "397  2.107777  1.920989  1.682704  1.690026  1.659764  1.700245  1.649740   \n",
       "398  2.135057  2.084120  1.973285  1.859319  1.853333  1.854966  1.956917   \n",
       "\n",
       "      l1_min2   l1_max2   l1_qtl2  ...   l4_cur3   l4_cur4   l4_cur5  \\\n",
       "0    0.948225  0.944712  0.878323  ... -0.001783  0.071555 -0.451787   \n",
       "1    0.854425  0.843202  0.776964  ... -0.002552  0.079066 -0.526390   \n",
       "2    0.723022  0.759360  0.710899  ... -0.003094  0.087967 -0.587742   \n",
       "3    0.705249  0.719335  0.599678  ... -0.002280  0.079904 -0.622525   \n",
       "4    1.037668  1.032366  0.900402  ... -0.001523  0.069126 -0.568937   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "394  2.025162  1.933353  1.760320  ... -0.001875  0.049112 -0.179824   \n",
       "395  1.822832  1.856636  1.732509  ... -0.001043  0.020199  0.219921   \n",
       "396  1.220235  1.294640  1.203857  ... -0.003108  0.070145 -0.218774   \n",
       "397  1.328510  1.216458  1.217324  ... -0.004302  0.102801 -0.535439   \n",
       "398  1.716792  1.669001  1.492656  ... -0.002610  0.059049 -0.154157   \n",
       "\n",
       "       l4_cur6       l4_der1   l4_der2   l4_der3   l4_der4   l4_der5  S  \n",
       "0     9.110630  8.476972e-07  0.000011 -0.005350  0.143110 -0.451787  0  \n",
       "1    10.690206 -2.650281e-07  0.000107 -0.007657  0.158133 -0.526390  0  \n",
       "2    10.941266 -7.766324e-07  0.000158 -0.009282  0.175934 -0.587742  0  \n",
       "3    10.893866  1.265775e-07  0.000071 -0.006841  0.159808 -0.622525  0  \n",
       "4    10.664818  9.074015e-07 -0.000005 -0.004569  0.138252 -0.568937  0  \n",
       "..         ...           ...       ...       ...       ...       ... ..  \n",
       "394  10.048577 -3.035061e-07  0.000090 -0.005625  0.098223 -0.179824  0  \n",
       "395   8.553810 -3.865501e-08  0.000048 -0.003129  0.040398  0.219921  0  \n",
       "396   8.743192 -1.336387e-06  0.000199 -0.009325  0.140289 -0.218774  0  \n",
       "397   8.660696 -1.910258e-06  0.000275 -0.012905  0.205601 -0.535439  0  \n",
       "398   8.851754 -1.147777e-06  0.000168 -0.007830  0.118099 -0.154157  0  \n",
       "\n",
       "[399 rows x 357 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>l1_qtl2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_cur3</th>\n",
       "      <th>l4_cur4</th>\n",
       "      <th>l4_cur5</th>\n",
       "      <th>l4_cur6</th>\n",
       "      <th>l4_der1</th>\n",
       "      <th>l4_der2</th>\n",
       "      <th>l4_der3</th>\n",
       "      <th>l4_der4</th>\n",
       "      <th>l4_der5</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.461229</td>\n",
       "      <td>1.403337</td>\n",
       "      <td>1.329958</td>\n",
       "      <td>1.183326</td>\n",
       "      <td>1.083925</td>\n",
       "      <td>1.030910</td>\n",
       "      <td>1.060135</td>\n",
       "      <td>0.948225</td>\n",
       "      <td>0.944712</td>\n",
       "      <td>0.878323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001783</td>\n",
       "      <td>0.071555</td>\n",
       "      <td>-0.451787</td>\n",
       "      <td>9.110630</td>\n",
       "      <td>8.476972e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>-0.451787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.206355</td>\n",
       "      <td>1.028218</td>\n",
       "      <td>0.993922</td>\n",
       "      <td>0.874931</td>\n",
       "      <td>0.872215</td>\n",
       "      <td>0.911993</td>\n",
       "      <td>0.961354</td>\n",
       "      <td>0.854425</td>\n",
       "      <td>0.843202</td>\n",
       "      <td>0.776964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>0.079066</td>\n",
       "      <td>-0.526390</td>\n",
       "      <td>10.690206</td>\n",
       "      <td>-2.650281e-07</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-0.007657</td>\n",
       "      <td>0.158133</td>\n",
       "      <td>-0.526390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747694</td>\n",
       "      <td>0.706687</td>\n",
       "      <td>0.675697</td>\n",
       "      <td>0.677832</td>\n",
       "      <td>0.596699</td>\n",
       "      <td>0.656809</td>\n",
       "      <td>0.696858</td>\n",
       "      <td>0.723022</td>\n",
       "      <td>0.759360</td>\n",
       "      <td>0.710899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003094</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>-0.587742</td>\n",
       "      <td>10.941266</td>\n",
       "      <td>-7.766324e-07</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.009282</td>\n",
       "      <td>0.175934</td>\n",
       "      <td>-0.587742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680562</td>\n",
       "      <td>0.652428</td>\n",
       "      <td>0.617645</td>\n",
       "      <td>0.655980</td>\n",
       "      <td>0.595589</td>\n",
       "      <td>0.618400</td>\n",
       "      <td>0.705216</td>\n",
       "      <td>0.705249</td>\n",
       "      <td>0.719335</td>\n",
       "      <td>0.599678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002280</td>\n",
       "      <td>0.079904</td>\n",
       "      <td>-0.622525</td>\n",
       "      <td>10.893866</td>\n",
       "      <td>1.265775e-07</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.006841</td>\n",
       "      <td>0.159808</td>\n",
       "      <td>-0.622525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.418847</td>\n",
       "      <td>1.444397</td>\n",
       "      <td>1.328114</td>\n",
       "      <td>1.280205</td>\n",
       "      <td>1.189202</td>\n",
       "      <td>1.207989</td>\n",
       "      <td>1.236722</td>\n",
       "      <td>1.037668</td>\n",
       "      <td>1.032366</td>\n",
       "      <td>0.900402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>0.069126</td>\n",
       "      <td>-0.568937</td>\n",
       "      <td>10.664818</td>\n",
       "      <td>9.074015e-07</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.004569</td>\n",
       "      <td>0.138252</td>\n",
       "      <td>-0.568937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.917898</td>\n",
       "      <td>0.919850</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.727550</td>\n",
       "      <td>0.679315</td>\n",
       "      <td>0.650399</td>\n",
       "      <td>0.645671</td>\n",
       "      <td>0.707827</td>\n",
       "      <td>0.656676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>-0.062696</td>\n",
       "      <td>10.424669</td>\n",
       "      <td>1.781041e-06</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.030851</td>\n",
       "      <td>-0.062696</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.993171</td>\n",
       "      <td>1.055292</td>\n",
       "      <td>0.918394</td>\n",
       "      <td>0.886796</td>\n",
       "      <td>0.840524</td>\n",
       "      <td>0.783448</td>\n",
       "      <td>0.783273</td>\n",
       "      <td>0.697142</td>\n",
       "      <td>0.768202</td>\n",
       "      <td>0.650290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>-0.000815</td>\n",
       "      <td>-0.047433</td>\n",
       "      <td>10.910980</td>\n",
       "      <td>2.140359e-06</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>-0.001630</td>\n",
       "      <td>-0.047433</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.913375</td>\n",
       "      <td>1.006806</td>\n",
       "      <td>1.072936</td>\n",
       "      <td>1.082991</td>\n",
       "      <td>1.013199</td>\n",
       "      <td>0.927840</td>\n",
       "      <td>0.883479</td>\n",
       "      <td>0.827988</td>\n",
       "      <td>0.818503</td>\n",
       "      <td>0.758421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.027969</td>\n",
       "      <td>-0.485448</td>\n",
       "      <td>11.351925</td>\n",
       "      <td>1.960868e-06</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.055939</td>\n",
       "      <td>-0.485448</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.987489</td>\n",
       "      <td>1.093021</td>\n",
       "      <td>1.092624</td>\n",
       "      <td>1.122730</td>\n",
       "      <td>1.011742</td>\n",
       "      <td>0.943294</td>\n",
       "      <td>0.923651</td>\n",
       "      <td>0.845975</td>\n",
       "      <td>0.821050</td>\n",
       "      <td>0.787015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.029154</td>\n",
       "      <td>-0.436101</td>\n",
       "      <td>10.818459</td>\n",
       "      <td>2.029731e-06</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.058308</td>\n",
       "      <td>-0.436101</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.870196</td>\n",
       "      <td>0.895927</td>\n",
       "      <td>0.797970</td>\n",
       "      <td>0.818034</td>\n",
       "      <td>0.758689</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>0.791259</td>\n",
       "      <td>0.751083</td>\n",
       "      <td>0.748708</td>\n",
       "      <td>0.753879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.018640</td>\n",
       "      <td>-0.339106</td>\n",
       "      <td>10.723187</td>\n",
       "      <td>2.690457e-06</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.037279</td>\n",
       "      <td>-0.339106</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1995 rows × 357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_std2  \\\n",
       "0     1.461229  1.403337  1.329958  1.183326  1.083925  1.030910  1.060135   \n",
       "1     1.206355  1.028218  0.993922  0.874931  0.872215  0.911993  0.961354   \n",
       "2     0.747694  0.706687  0.675697  0.677832  0.596699  0.656809  0.696858   \n",
       "3     0.680562  0.652428  0.617645  0.655980  0.595589  0.618400  0.705216   \n",
       "4     1.418847  1.444397  1.328114  1.280205  1.189202  1.207989  1.236722   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1990  0.917898  0.919850  0.856698  0.804004  0.727550  0.679315  0.650399   \n",
       "1991  0.993171  1.055292  0.918394  0.886796  0.840524  0.783448  0.783273   \n",
       "1992  0.913375  1.006806  1.072936  1.082991  1.013199  0.927840  0.883479   \n",
       "1993  0.987489  1.093021  1.092624  1.122730  1.011742  0.943294  0.923651   \n",
       "1994  0.870196  0.895927  0.797970  0.818034  0.758689  0.781200  0.791259   \n",
       "\n",
       "       l1_min2   l1_max2   l1_qtl2  ...   l4_cur3   l4_cur4   l4_cur5  \\\n",
       "0     0.948225  0.944712  0.878323  ... -0.001783  0.071555 -0.451787   \n",
       "1     0.854425  0.843202  0.776964  ... -0.002552  0.079066 -0.526390   \n",
       "2     0.723022  0.759360  0.710899  ... -0.003094  0.087967 -0.587742   \n",
       "3     0.705249  0.719335  0.599678  ... -0.002280  0.079904 -0.622525   \n",
       "4     1.037668  1.032366  0.900402  ... -0.001523  0.069126 -0.568937   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1990  0.645671  0.707827  0.656676  ...  0.000444  0.015425 -0.062696   \n",
       "1991  0.697142  0.768202  0.650290  ...  0.001289 -0.000815 -0.047433   \n",
       "1992  0.827988  0.818503  0.758421  ...  0.000557  0.027969 -0.485448   \n",
       "1993  0.845975  0.821050  0.787015  ...  0.000407  0.029154 -0.436101   \n",
       "1994  0.751083  0.748708  0.753879  ...  0.001050  0.018640 -0.339106   \n",
       "\n",
       "        l4_cur6       l4_der1   l4_der2   l4_der3   l4_der4   l4_der5  S  \n",
       "0      9.110630  8.476972e-07  0.000011 -0.005350  0.143110 -0.451787  0  \n",
       "1     10.690206 -2.650281e-07  0.000107 -0.007657  0.158133 -0.526390  0  \n",
       "2     10.941266 -7.766324e-07  0.000158 -0.009282  0.175934 -0.587742  0  \n",
       "3     10.893866  1.265775e-07  0.000071 -0.006841  0.159808 -0.622525  0  \n",
       "4     10.664818  9.074015e-07 -0.000005 -0.004569  0.138252 -0.568937  0  \n",
       "...         ...           ...       ...       ...       ...       ... ..  \n",
       "1990  10.424669  1.781041e-06 -0.000127  0.001333  0.030851 -0.062696  4  \n",
       "1991  10.910980  2.140359e-06 -0.000183  0.003866 -0.001630 -0.047433  4  \n",
       "1992  11.351925  1.960868e-06 -0.000151  0.001671  0.055939 -0.485448  4  \n",
       "1993  10.818459  2.029731e-06 -0.000146  0.001221  0.058308 -0.436101  4  \n",
       "1994  10.723187  2.690457e-06 -0.000209  0.003149  0.037279 -0.339106  4  \n",
       "\n",
       "[1995 rows x 357 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea_all = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df_fea)):\n",
    "    df_fea_all = pd.concat([df_fea_all, df_fea[i]], axis=0)\n",
    "\n",
    "df_fea_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Stratified k-fold 1 回目 #####\n",
      "TRAIN:  1710\n",
      "TEST:  285\n",
      "##### Stratified k-fold 2 回目 #####\n",
      "TRAIN:  1710\n",
      "TEST:  285\n",
      "##### Stratified k-fold 3 回目 #####\n",
      "TRAIN:  1710\n",
      "TEST:  285\n",
      "##### Stratified k-fold 4 回目 #####\n",
      "TRAIN:  1710\n",
      "TEST:  285\n",
      "##### Stratified k-fold 5 回目 #####\n",
      "TRAIN:  1710\n",
      "TEST:  285\n",
      "##### Stratified k-fold 6 回目 #####\n",
      "TRAIN:  1710\n",
      "TEST:  285\n",
      "##### Stratified k-fold 7 回目 #####\n",
      "TRAIN:  1710\n",
      "TEST:  285\n"
     ]
    }
   ],
   "source": [
    "# set k for k-hold cross-validation\n",
    "k = 7\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "X = df_fea_all.drop('S', axis=1)\n",
    "y = df_fea_all['S']\n",
    "\n",
    "X = X.reset_index()\n",
    "X = X.drop('index', axis = 1)\n",
    "y = y.reset_index()\n",
    "y = y.drop('index', axis = 1)\n",
    "\n",
    "train_index = [[] for _ in range(k)]\n",
    "test_index = [[] for _ in range(k)]\n",
    "\n",
    "n = 0\n",
    "for tra_idx, tes_idx in skf.split(X,y):\n",
    "    \n",
    "    print('##### Stratified k-fold',n+1,'回目 #####')\n",
    "    print(\"TRAIN: \",len(tra_idx))\n",
    "    print(\"TEST: \",len(tes_idx))\n",
    "    \n",
    "    train_index[n] = tra_idx\n",
    "    test_index[n] = tes_idx\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-dd17f4cfa02f>:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_1.fit(X_train, y_train)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-dd17f4cfa02f>:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_1.fit(X_train, y_train)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-dd17f4cfa02f>:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_1.fit(X_train, y_train)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-dd17f4cfa02f>:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_1.fit(X_train, y_train)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-dd17f4cfa02f>:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_1.fit(X_train, y_train)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-dd17f4cfa02f>:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_1.fit(X_train, y_train)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-dd17f4cfa02f>:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_1.fit(X_train, y_train)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jinchoi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# learning\n",
    "\n",
    "clf_1 = RandomForestClassifier(n_estimators=749,max_depth=15.295632458713467,criterion='entropy', min_samples_split=14)\n",
    "clf_2 = LogisticRegression(random_state=0,C=1.0)\n",
    "clf_3 = svm.SVC(gamma=0.001, C=1.)\n",
    "clf_4 = lgb.LGBMClassifier()\n",
    "\n",
    "y_test_list = [[] for _ in range(k)]\n",
    "\n",
    "y_pred_1_list = [[] for _ in range(k)]\n",
    "y_pred_2_list = [[] for _ in range(k)]\n",
    "y_pred_3_list = [[] for _ in range(k)]\n",
    "y_pred_4_list = [[] for _ in range(k)]\n",
    "\n",
    "for i in range(k):\n",
    "    \n",
    "    X_train = X.iloc[train_index[i]]\n",
    "    X_test = X.iloc[test_index[i]]\n",
    "    y_train = y.iloc[train_index[i]]\n",
    "    y_test = y.iloc[test_index[i]]\n",
    "    \n",
    "    # Feature standardization\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train=scaler.transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "    # fit\n",
    "    clf_1.fit(X_train, y_train)\n",
    "    clf_2.fit(X_train, y_train)\n",
    "    clf_3.fit(X_train, y_train)\n",
    "    clf_4.fit(X_train, y_train)\n",
    "    \n",
    "    # prediction\n",
    "    y_pred_1 = clf_1.predict(X_test)\n",
    "    y_pred_2 = clf_2.predict(X_test)\n",
    "    y_pred_3 = clf_3.predict(X_test)\n",
    "    y_pred_4 = clf_4.predict(X_test)\n",
    "    \n",
    "    y_test_list[i] = y_test\n",
    "    y_pred_1_list[i] = y_pred_1\n",
    "    y_pred_2_list[i] = y_pred_2\n",
    "    y_pred_3_list[i] = y_pred_3\n",
    "    y_pred_4_list[i] = y_pred_4\n",
    "    \n",
    "    print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test_list)):\n",
    "    y_test_list[i] = y_test_list[i].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tot = []\n",
    "\n",
    "y_pred_1_tot = []\n",
    "y_pred_2_tot = []\n",
    "y_pred_3_tot = []\n",
    "y_pred_4_tot = []\n",
    "\n",
    "for i in range(k):\n",
    "    y_test_tot.extend(y_test_list[i])\n",
    "    \n",
    "    y_pred_1_tot.extend(y_pred_1_list[i])\n",
    "    y_pred_2_tot.extend(y_pred_2_list[i])\n",
    "    y_pred_3_tot.extend(y_pred_3_list[i])\n",
    "    y_pred_4_tot.extend(y_pred_4_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### overall results ##################\n",
      "  \n",
      "############## Random Forest #############\n",
      "accuracy:  0.962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       399\n",
      "           1       0.98      0.96      0.97       399\n",
      "           2       0.98      0.98      0.98       399\n",
      "           3       0.96      0.99      0.98       399\n",
      "           4       0.94      0.98      0.96       399\n",
      "\n",
      "    accuracy                           0.96      1995\n",
      "   macro avg       0.96      0.96      0.96      1995\n",
      "weighted avg       0.96      0.96      0.96      1995\n",
      "\n",
      "[[358   7   6  13  15]\n",
      " [  0 383   3   2  11]\n",
      " [  6   0 390   3   0]\n",
      " [  2   0   0 397   0]\n",
      " [  6   1   0   0 392]]\n",
      "  \n",
      "############## LogisticRegression #############\n",
      "accuracy:  0.966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       399\n",
      "           1       0.98      0.97      0.98       399\n",
      "           2       0.97      0.99      0.98       399\n",
      "           3       0.98      0.99      0.98       399\n",
      "           4       0.92      0.99      0.96       399\n",
      "\n",
      "    accuracy                           0.97      1995\n",
      "   macro avg       0.97      0.97      0.97      1995\n",
      "weighted avg       0.97      0.97      0.97      1995\n",
      "\n",
      "[[356   6  11   7  19]\n",
      " [  0 387   2   0  10]\n",
      " [  4   0 394   1   0]\n",
      " [  1   0   0 394   4]\n",
      " [  2   0   0   0 397]]\n",
      "  \n",
      "############## svm #############\n",
      "accuracy:  0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       399\n",
      "           1       0.98      0.98      0.98       399\n",
      "           2       0.98      0.96      0.97       399\n",
      "           3       0.98      0.93      0.95       399\n",
      "           4       0.86      0.99      0.92       399\n",
      "\n",
      "    accuracy                           0.95      1995\n",
      "   macro avg       0.95      0.95      0.95      1995\n",
      "weighted avg       0.95      0.95      0.95      1995\n",
      "\n",
      "[[353   7   7   7  25]\n",
      " [  0 393   0   0   6]\n",
      " [  9   0 383   0   7]\n",
      " [  0   0   1 371  27]\n",
      " [  4   0   0   0 395]]\n",
      "  \n",
      "############## LightGBM #############\n",
      "accuracy:  0.957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       399\n",
      "           1       0.97      0.94      0.95       399\n",
      "           2       0.97      0.98      0.98       399\n",
      "           3       0.96      1.00      0.98       399\n",
      "           4       0.91      0.98      0.94       399\n",
      "\n",
      "    accuracy                           0.96      1995\n",
      "   macro avg       0.96      0.96      0.96      1995\n",
      "weighted avg       0.96      0.96      0.96      1995\n",
      "\n",
      "[[354  10   8  11  16]\n",
      " [  1 375   1   1  21]\n",
      " [  2   1 390   4   2]\n",
      " [  0   0   0 399   0]\n",
      " [  5   1   1   0 392]]\n"
     ]
    }
   ],
   "source": [
    "# result scores\n",
    "\n",
    "print(\"################### overall results ##################\")\n",
    "print(\"  \")\n",
    "\n",
    "print(\"############## Random Forest #############\")\n",
    "print(\"accuracy: \",round(accuracy_score(y_test_tot, y_pred_1_tot),3))\n",
    "print(classification_report(y_test_tot, y_pred_1_tot))\n",
    "print(confusion_matrix(y_test_tot, y_pred_1_tot))\n",
    "print(\"  \")\n",
    "\n",
    "print(\"############## LogisticRegression #############\")\n",
    "print(\"accuracy: \",round(accuracy_score(y_test_tot, y_pred_2_tot),3))\n",
    "print(classification_report(y_test_tot, y_pred_2_tot))\n",
    "print(confusion_matrix(y_test_tot, y_pred_2_tot))\n",
    "print(\"  \")\n",
    "\n",
    "print(\"############## svm #############\")\n",
    "print(\"accuracy: \",round(accuracy_score(y_test_tot, y_pred_3_tot),3))\n",
    "print(classification_report(y_test_tot, y_pred_3_tot))\n",
    "print(confusion_matrix(y_test_tot, y_pred_3_tot))\n",
    "print(\"  \")\n",
    "\n",
    "print(\"############## LightGBM #############\")\n",
    "print(\"accuracy: \",round(accuracy_score(y_test_tot, y_pred_4_tot),3))\n",
    "print(classification_report(y_test_tot, y_pred_4_tot))\n",
    "print(confusion_matrix(y_test_tot, y_pred_4_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
