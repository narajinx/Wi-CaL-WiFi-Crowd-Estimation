{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# for results\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DNN & initial setting\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def compare_TV(history, train_met, val_met):\n",
    "    acc = history.history[train_met]\n",
    "    val_acc = history.history[val_met]\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo' ,label = 'training '+train_met)\n",
    "    plt.plot(epochs, val_acc, 'b' , label= 'validation '+val_met)\n",
    "    plt.title('Training and Validation metrics')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo' ,label = 'training loss')\n",
    "    plt.plot(epochs, val_loss, 'b' , label= 'validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "division = 'm'  # s or m (s = small-sized meeting room, m = medium-sized seminar room)\n",
    "\n",
    "# session 1\n",
    "if division == 's':\n",
    "    l = glob.glob(r'..\\..\\datasets\\small-room\\sess1\\P=*.csv')\n",
    "elif division == 'm':\n",
    "    l = glob.glob(r'..\\..\\datasets\\medium-room\\sess1\\P=*.csv')\n",
    "l.sort()\n",
    "\n",
    "df_fea_sess1 = []\n",
    "for i in l:\n",
    "    df_fea_sess1.append(pd.read_csv(i, header=None))\n",
    "\n",
    "# session 2\n",
    "if division == 's':\n",
    "    l = glob.glob(r'..\\..\\datasets\\small-room\\sess2\\P=*.csv')\n",
    "elif division == 'm':\n",
    "    l = glob.glob(r'..\\..\\datasets\\medium-room\\sess2\\P=*.csv')\n",
    "l.sort()\n",
    "\n",
    "df_fea_sess2 = []\n",
    "for i in l:\n",
    "    df_fea_sess2.append(pd.read_csv(i, header=None))\n",
    "    \n",
    "# session 3\n",
    "if division == 's':\n",
    "    l = glob.glob(r'..\\..\\datasets\\small-room\\sess3\\P=*.csv')\n",
    "elif division == 'm':\n",
    "    l = glob.glob(r'..\\..\\datasets\\medium-room\\sess3\\P=*.csv')\n",
    "l.sort()\n",
    "\n",
    "df_fea_sess3 = []\n",
    "for i in l:\n",
    "    df_fea_sess3.append(pd.read_csv(i, header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=0.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=1.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=10.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=2.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=3.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=4.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=5.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=6.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=7.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=8.csv',\n",
       " '..\\\\..\\\\datasets\\\\medium-room\\\\sess3\\\\P=9.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "# In case of medium-room, bring P=10 dataset to behind\n",
    "\n",
    "if division == 'm':\n",
    "    # session 1\n",
    "    temp1 = df_fea_sess1[2]\n",
    "    del df_fea_sess1[2]\n",
    "    df_fea_sess1.append(temp1)\n",
    "\n",
    "    # session 2\n",
    "    temp2 = df_fea_sess2[2]\n",
    "    del df_fea_sess2[2]\n",
    "    df_fea_sess2.append(temp2)\n",
    "\n",
    "    # session 3\n",
    "    temp3 = df_fea_sess3[2]\n",
    "    del df_fea_sess3[2]\n",
    "    df_fea_sess3.append(temp3)\n",
    "    \n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column label (feature name)\n",
    "# l(N1)_xxx(N2) >> N1: link number, N2: subcarrier number.\n",
    "\n",
    "nof_link = 4\n",
    "nof_usedsubc = 13\n",
    "\n",
    "col_label = []\n",
    "\n",
    "for i in range(nof_link):\n",
    "    \n",
    "    for j in range(nof_usedsubc):\n",
    "        col_label.append('l%d_std%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_min%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_max%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_qtl%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_qtu%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_avg%d' %(i+1,j+1))\n",
    "        col_label.append('l%d_iqr%d' %(i+1,j+1))\n",
    "        \n",
    "    for j in range(nof_usedsubc-1):\n",
    "        col_label.append('l%d_adj%d' %(i+1,j+1))\n",
    "        \n",
    "    col_label.append('l%d_euc' %(i+1))\n",
    "    col_label.append('l%d_rss' %(i+1))\n",
    "\n",
    "len(col_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column label\n",
    "\n",
    "# sess1\n",
    "for i in range(len(df_fea_sess1)):\n",
    "    df_fea_sess1[i].columns = col_label\n",
    "    \n",
    "# sess2\n",
    "for i in range(len(df_fea_sess2)):\n",
    "    df_fea_sess2[i].columns = col_label\n",
    "    \n",
    "# sess3\n",
    "for i in range(len(df_fea_sess3)):\n",
    "    df_fea_sess3[i].columns = col_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_iqr1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_adj5</th>\n",
       "      <th>l4_adj6</th>\n",
       "      <th>l4_adj7</th>\n",
       "      <th>l4_adj8</th>\n",
       "      <th>l4_adj9</th>\n",
       "      <th>l4_adj10</th>\n",
       "      <th>l4_adj11</th>\n",
       "      <th>l4_adj12</th>\n",
       "      <th>l4_euc</th>\n",
       "      <th>l4_rss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.608206</td>\n",
       "      <td>0.657957</td>\n",
       "      <td>0.713833</td>\n",
       "      <td>0.640223</td>\n",
       "      <td>0.575257</td>\n",
       "      <td>0.601237</td>\n",
       "      <td>0.613863</td>\n",
       "      <td>0.665459</td>\n",
       "      <td>0.713174</td>\n",
       "      <td>0.690920</td>\n",
       "      <td>...</td>\n",
       "      <td>3.618943</td>\n",
       "      <td>3.065197</td>\n",
       "      <td>1.281392</td>\n",
       "      <td>1.155273</td>\n",
       "      <td>2.162608</td>\n",
       "      <td>3.203592</td>\n",
       "      <td>2.274834</td>\n",
       "      <td>1.566753</td>\n",
       "      <td>1.254732</td>\n",
       "      <td>0.393239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.558632</td>\n",
       "      <td>0.617536</td>\n",
       "      <td>0.591685</td>\n",
       "      <td>0.563507</td>\n",
       "      <td>0.521911</td>\n",
       "      <td>0.515001</td>\n",
       "      <td>0.523303</td>\n",
       "      <td>0.597528</td>\n",
       "      <td>0.630805</td>\n",
       "      <td>0.586206</td>\n",
       "      <td>...</td>\n",
       "      <td>3.696709</td>\n",
       "      <td>3.027887</td>\n",
       "      <td>1.221470</td>\n",
       "      <td>1.207575</td>\n",
       "      <td>2.186850</td>\n",
       "      <td>3.183312</td>\n",
       "      <td>2.212470</td>\n",
       "      <td>1.572496</td>\n",
       "      <td>1.303767</td>\n",
       "      <td>0.425122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.592736</td>\n",
       "      <td>0.582817</td>\n",
       "      <td>0.633832</td>\n",
       "      <td>0.626803</td>\n",
       "      <td>0.585176</td>\n",
       "      <td>0.538540</td>\n",
       "      <td>0.623852</td>\n",
       "      <td>0.641619</td>\n",
       "      <td>0.638701</td>\n",
       "      <td>0.628728</td>\n",
       "      <td>...</td>\n",
       "      <td>3.674395</td>\n",
       "      <td>3.510138</td>\n",
       "      <td>1.248484</td>\n",
       "      <td>1.387625</td>\n",
       "      <td>2.770313</td>\n",
       "      <td>3.221348</td>\n",
       "      <td>2.636359</td>\n",
       "      <td>1.518210</td>\n",
       "      <td>1.370761</td>\n",
       "      <td>0.852038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.612643</td>\n",
       "      <td>0.697871</td>\n",
       "      <td>0.679729</td>\n",
       "      <td>0.648263</td>\n",
       "      <td>0.644887</td>\n",
       "      <td>0.677691</td>\n",
       "      <td>0.702409</td>\n",
       "      <td>0.711609</td>\n",
       "      <td>0.689965</td>\n",
       "      <td>...</td>\n",
       "      <td>3.634260</td>\n",
       "      <td>3.630998</td>\n",
       "      <td>1.247647</td>\n",
       "      <td>1.399262</td>\n",
       "      <td>2.861530</td>\n",
       "      <td>3.240161</td>\n",
       "      <td>2.620684</td>\n",
       "      <td>1.443801</td>\n",
       "      <td>1.317635</td>\n",
       "      <td>0.847652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619375</td>\n",
       "      <td>0.638782</td>\n",
       "      <td>0.635583</td>\n",
       "      <td>0.603459</td>\n",
       "      <td>0.546585</td>\n",
       "      <td>0.617259</td>\n",
       "      <td>0.661036</td>\n",
       "      <td>0.660677</td>\n",
       "      <td>0.683433</td>\n",
       "      <td>0.642949</td>\n",
       "      <td>...</td>\n",
       "      <td>3.660280</td>\n",
       "      <td>3.219130</td>\n",
       "      <td>1.204450</td>\n",
       "      <td>1.301821</td>\n",
       "      <td>2.304961</td>\n",
       "      <td>3.240413</td>\n",
       "      <td>2.157819</td>\n",
       "      <td>1.472491</td>\n",
       "      <td>1.292279</td>\n",
       "      <td>0.570483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.537044</td>\n",
       "      <td>0.664771</td>\n",
       "      <td>0.598528</td>\n",
       "      <td>0.604271</td>\n",
       "      <td>0.538355</td>\n",
       "      <td>0.576979</td>\n",
       "      <td>0.648574</td>\n",
       "      <td>0.625194</td>\n",
       "      <td>0.684797</td>\n",
       "      <td>0.655365</td>\n",
       "      <td>...</td>\n",
       "      <td>3.651667</td>\n",
       "      <td>3.238755</td>\n",
       "      <td>1.280219</td>\n",
       "      <td>1.256110</td>\n",
       "      <td>2.389406</td>\n",
       "      <td>3.115170</td>\n",
       "      <td>2.401649</td>\n",
       "      <td>1.392681</td>\n",
       "      <td>1.245854</td>\n",
       "      <td>0.560617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.539713</td>\n",
       "      <td>0.613217</td>\n",
       "      <td>0.587085</td>\n",
       "      <td>0.576537</td>\n",
       "      <td>0.522141</td>\n",
       "      <td>0.525790</td>\n",
       "      <td>0.638952</td>\n",
       "      <td>0.629060</td>\n",
       "      <td>0.669724</td>\n",
       "      <td>0.618936</td>\n",
       "      <td>...</td>\n",
       "      <td>3.663798</td>\n",
       "      <td>3.168351</td>\n",
       "      <td>1.281291</td>\n",
       "      <td>1.300463</td>\n",
       "      <td>2.269914</td>\n",
       "      <td>3.102991</td>\n",
       "      <td>2.280982</td>\n",
       "      <td>1.498108</td>\n",
       "      <td>1.306935</td>\n",
       "      <td>0.515975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.593539</td>\n",
       "      <td>0.600516</td>\n",
       "      <td>0.615549</td>\n",
       "      <td>0.582337</td>\n",
       "      <td>0.533078</td>\n",
       "      <td>0.538357</td>\n",
       "      <td>0.683304</td>\n",
       "      <td>0.627985</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.631595</td>\n",
       "      <td>...</td>\n",
       "      <td>3.612947</td>\n",
       "      <td>3.440955</td>\n",
       "      <td>1.345388</td>\n",
       "      <td>1.346500</td>\n",
       "      <td>2.482081</td>\n",
       "      <td>3.134262</td>\n",
       "      <td>2.473267</td>\n",
       "      <td>1.460695</td>\n",
       "      <td>1.302883</td>\n",
       "      <td>0.740219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.617981</td>\n",
       "      <td>0.599394</td>\n",
       "      <td>0.647435</td>\n",
       "      <td>0.592281</td>\n",
       "      <td>0.547554</td>\n",
       "      <td>0.549678</td>\n",
       "      <td>0.655069</td>\n",
       "      <td>0.661747</td>\n",
       "      <td>0.680038</td>\n",
       "      <td>0.629131</td>\n",
       "      <td>...</td>\n",
       "      <td>3.629142</td>\n",
       "      <td>3.793051</td>\n",
       "      <td>1.327250</td>\n",
       "      <td>1.422077</td>\n",
       "      <td>2.775449</td>\n",
       "      <td>3.136796</td>\n",
       "      <td>2.720833</td>\n",
       "      <td>1.348311</td>\n",
       "      <td>1.315951</td>\n",
       "      <td>0.673454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.537492</td>\n",
       "      <td>0.598670</td>\n",
       "      <td>0.570872</td>\n",
       "      <td>0.573065</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.506846</td>\n",
       "      <td>0.585318</td>\n",
       "      <td>0.619244</td>\n",
       "      <td>0.648252</td>\n",
       "      <td>0.550255</td>\n",
       "      <td>...</td>\n",
       "      <td>3.534799</td>\n",
       "      <td>4.356573</td>\n",
       "      <td>1.394109</td>\n",
       "      <td>1.675847</td>\n",
       "      <td>3.245480</td>\n",
       "      <td>3.187347</td>\n",
       "      <td>3.214091</td>\n",
       "      <td>1.394432</td>\n",
       "      <td>1.335577</td>\n",
       "      <td>0.678139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_iqr1  \\\n",
       "0    0.608206  0.657957  0.713833  0.640223  0.575257  0.601237  0.613863   \n",
       "1    0.558632  0.617536  0.591685  0.563507  0.521911  0.515001  0.523303   \n",
       "2    0.592736  0.582817  0.633832  0.626803  0.585176  0.538540  0.623852   \n",
       "3    0.666356  0.612643  0.697871  0.679729  0.648263  0.644887  0.677691   \n",
       "4    0.619375  0.638782  0.635583  0.603459  0.546585  0.617259  0.661036   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "194  0.537044  0.664771  0.598528  0.604271  0.538355  0.576979  0.648574   \n",
       "195  0.539713  0.613217  0.587085  0.576537  0.522141  0.525790  0.638952   \n",
       "196  0.593539  0.600516  0.615549  0.582337  0.533078  0.538357  0.683304   \n",
       "197  0.617981  0.599394  0.647435  0.592281  0.547554  0.549678  0.655069   \n",
       "198  0.537492  0.598670  0.570872  0.573065  0.503333  0.506846  0.585318   \n",
       "\n",
       "      l1_std2   l1_min2   l1_max2  ...   l4_adj5   l4_adj6   l4_adj7  \\\n",
       "0    0.665459  0.713174  0.690920  ...  3.618943  3.065197  1.281392   \n",
       "1    0.597528  0.630805  0.586206  ...  3.696709  3.027887  1.221470   \n",
       "2    0.641619  0.638701  0.628728  ...  3.674395  3.510138  1.248484   \n",
       "3    0.702409  0.711609  0.689965  ...  3.634260  3.630998  1.247647   \n",
       "4    0.660677  0.683433  0.642949  ...  3.660280  3.219130  1.204450   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "194  0.625194  0.684797  0.655365  ...  3.651667  3.238755  1.280219   \n",
       "195  0.629060  0.669724  0.618936  ...  3.663798  3.168351  1.281291   \n",
       "196  0.627985  0.692913  0.631595  ...  3.612947  3.440955  1.345388   \n",
       "197  0.661747  0.680038  0.629131  ...  3.629142  3.793051  1.327250   \n",
       "198  0.619244  0.648252  0.550255  ...  3.534799  4.356573  1.394109   \n",
       "\n",
       "      l4_adj8   l4_adj9  l4_adj10  l4_adj11  l4_adj12    l4_euc    l4_rss  \n",
       "0    1.155273  2.162608  3.203592  2.274834  1.566753  1.254732  0.393239  \n",
       "1    1.207575  2.186850  3.183312  2.212470  1.572496  1.303767  0.425122  \n",
       "2    1.387625  2.770313  3.221348  2.636359  1.518210  1.370761  0.852038  \n",
       "3    1.399262  2.861530  3.240161  2.620684  1.443801  1.317635  0.847652  \n",
       "4    1.301821  2.304961  3.240413  2.157819  1.472491  1.292279  0.570483  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "194  1.256110  2.389406  3.115170  2.401649  1.392681  1.245854  0.560617  \n",
       "195  1.300463  2.269914  3.102991  2.280982  1.498108  1.306935  0.515975  \n",
       "196  1.346500  2.482081  3.134262  2.473267  1.460695  1.302883  0.740219  \n",
       "197  1.422077  2.775449  3.136796  2.720833  1.348311  1.315951  0.673454  \n",
       "198  1.675847  3.245480  3.187347  3.214091  1.394432  1.335577  0.678139  \n",
       "\n",
       "[199 rows x 420 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea_sess3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "\n",
    "for i in range(len(df_fea_sess1)):\n",
    "    df_fea_sess1[i]['GT'] = i  # GT: ground truth\n",
    "    \n",
    "for i in range(len(df_fea_sess2)):\n",
    "    df_fea_sess2[i]['GT'] = i  # GT: ground truth\n",
    "    \n",
    "for i in range(len(df_fea_sess3)):\n",
    "    df_fea_sess3[i]['GT'] = i  # GT: ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_iqr1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_adj6</th>\n",
       "      <th>l4_adj7</th>\n",
       "      <th>l4_adj8</th>\n",
       "      <th>l4_adj9</th>\n",
       "      <th>l4_adj10</th>\n",
       "      <th>l4_adj11</th>\n",
       "      <th>l4_adj12</th>\n",
       "      <th>l4_euc</th>\n",
       "      <th>l4_rss</th>\n",
       "      <th>GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.830603</td>\n",
       "      <td>1.873160</td>\n",
       "      <td>1.725519</td>\n",
       "      <td>1.594962</td>\n",
       "      <td>1.513311</td>\n",
       "      <td>1.417834</td>\n",
       "      <td>1.282464</td>\n",
       "      <td>1.052657</td>\n",
       "      <td>0.974200</td>\n",
       "      <td>0.959019</td>\n",
       "      <td>...</td>\n",
       "      <td>3.948070</td>\n",
       "      <td>1.619502</td>\n",
       "      <td>1.737586</td>\n",
       "      <td>3.056655</td>\n",
       "      <td>2.481858</td>\n",
       "      <td>3.216479</td>\n",
       "      <td>1.641629</td>\n",
       "      <td>2.833969</td>\n",
       "      <td>2.505928</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.653972</td>\n",
       "      <td>1.700725</td>\n",
       "      <td>1.442612</td>\n",
       "      <td>1.373765</td>\n",
       "      <td>1.360974</td>\n",
       "      <td>1.302505</td>\n",
       "      <td>1.178472</td>\n",
       "      <td>0.948451</td>\n",
       "      <td>0.962930</td>\n",
       "      <td>0.978861</td>\n",
       "      <td>...</td>\n",
       "      <td>2.887147</td>\n",
       "      <td>1.621722</td>\n",
       "      <td>1.422434</td>\n",
       "      <td>2.023871</td>\n",
       "      <td>2.392200</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.874043</td>\n",
       "      <td>2.460489</td>\n",
       "      <td>2.458782</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.919865</td>\n",
       "      <td>1.950287</td>\n",
       "      <td>1.596515</td>\n",
       "      <td>1.595795</td>\n",
       "      <td>1.476098</td>\n",
       "      <td>1.285457</td>\n",
       "      <td>1.212172</td>\n",
       "      <td>1.040958</td>\n",
       "      <td>1.112712</td>\n",
       "      <td>1.029208</td>\n",
       "      <td>...</td>\n",
       "      <td>2.433325</td>\n",
       "      <td>1.457065</td>\n",
       "      <td>1.313497</td>\n",
       "      <td>1.668600</td>\n",
       "      <td>2.215635</td>\n",
       "      <td>2.213719</td>\n",
       "      <td>1.742178</td>\n",
       "      <td>2.388251</td>\n",
       "      <td>1.841882</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.215348</td>\n",
       "      <td>2.244203</td>\n",
       "      <td>1.977337</td>\n",
       "      <td>1.939716</td>\n",
       "      <td>1.737858</td>\n",
       "      <td>1.500368</td>\n",
       "      <td>1.274563</td>\n",
       "      <td>1.022749</td>\n",
       "      <td>1.153209</td>\n",
       "      <td>1.155699</td>\n",
       "      <td>...</td>\n",
       "      <td>3.231465</td>\n",
       "      <td>1.457090</td>\n",
       "      <td>1.636411</td>\n",
       "      <td>2.088249</td>\n",
       "      <td>2.016143</td>\n",
       "      <td>2.699968</td>\n",
       "      <td>1.494795</td>\n",
       "      <td>2.451414</td>\n",
       "      <td>2.619573</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.056869</td>\n",
       "      <td>2.179477</td>\n",
       "      <td>2.168995</td>\n",
       "      <td>2.066923</td>\n",
       "      <td>1.973254</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>1.557790</td>\n",
       "      <td>1.185382</td>\n",
       "      <td>1.152784</td>\n",
       "      <td>1.106285</td>\n",
       "      <td>...</td>\n",
       "      <td>3.475257</td>\n",
       "      <td>1.680644</td>\n",
       "      <td>1.722947</td>\n",
       "      <td>2.527573</td>\n",
       "      <td>2.301586</td>\n",
       "      <td>2.812813</td>\n",
       "      <td>1.487229</td>\n",
       "      <td>2.523600</td>\n",
       "      <td>2.846565</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.910188</td>\n",
       "      <td>0.929432</td>\n",
       "      <td>0.820374</td>\n",
       "      <td>0.841888</td>\n",
       "      <td>0.818081</td>\n",
       "      <td>0.780074</td>\n",
       "      <td>0.837690</td>\n",
       "      <td>0.763892</td>\n",
       "      <td>0.778448</td>\n",
       "      <td>0.725079</td>\n",
       "      <td>...</td>\n",
       "      <td>2.053912</td>\n",
       "      <td>1.429570</td>\n",
       "      <td>1.451467</td>\n",
       "      <td>1.543837</td>\n",
       "      <td>1.651854</td>\n",
       "      <td>1.874679</td>\n",
       "      <td>1.503917</td>\n",
       "      <td>2.262251</td>\n",
       "      <td>1.437628</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.846394</td>\n",
       "      <td>0.832982</td>\n",
       "      <td>0.753228</td>\n",
       "      <td>0.761799</td>\n",
       "      <td>0.682601</td>\n",
       "      <td>0.734084</td>\n",
       "      <td>0.798138</td>\n",
       "      <td>0.713589</td>\n",
       "      <td>0.710684</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>...</td>\n",
       "      <td>3.388962</td>\n",
       "      <td>1.819057</td>\n",
       "      <td>1.783210</td>\n",
       "      <td>2.688159</td>\n",
       "      <td>2.718980</td>\n",
       "      <td>3.509049</td>\n",
       "      <td>2.113260</td>\n",
       "      <td>2.388466</td>\n",
       "      <td>2.251772</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.799441</td>\n",
       "      <td>0.832479</td>\n",
       "      <td>0.716002</td>\n",
       "      <td>0.716839</td>\n",
       "      <td>0.647494</td>\n",
       "      <td>0.697313</td>\n",
       "      <td>0.753961</td>\n",
       "      <td>0.733368</td>\n",
       "      <td>0.756890</td>\n",
       "      <td>0.748847</td>\n",
       "      <td>...</td>\n",
       "      <td>4.509243</td>\n",
       "      <td>2.614164</td>\n",
       "      <td>2.072276</td>\n",
       "      <td>3.154163</td>\n",
       "      <td>3.881063</td>\n",
       "      <td>4.361751</td>\n",
       "      <td>2.650688</td>\n",
       "      <td>2.747130</td>\n",
       "      <td>2.187316</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.862368</td>\n",
       "      <td>0.973360</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>0.845210</td>\n",
       "      <td>0.727936</td>\n",
       "      <td>0.765795</td>\n",
       "      <td>0.778770</td>\n",
       "      <td>0.725881</td>\n",
       "      <td>0.733296</td>\n",
       "      <td>0.758743</td>\n",
       "      <td>...</td>\n",
       "      <td>4.704748</td>\n",
       "      <td>3.276289</td>\n",
       "      <td>2.261142</td>\n",
       "      <td>2.710720</td>\n",
       "      <td>3.640153</td>\n",
       "      <td>3.909919</td>\n",
       "      <td>2.856965</td>\n",
       "      <td>3.130545</td>\n",
       "      <td>2.235205</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.804382</td>\n",
       "      <td>0.881502</td>\n",
       "      <td>0.849412</td>\n",
       "      <td>0.831112</td>\n",
       "      <td>0.729209</td>\n",
       "      <td>0.747993</td>\n",
       "      <td>0.824833</td>\n",
       "      <td>0.793283</td>\n",
       "      <td>0.794390</td>\n",
       "      <td>0.736457</td>\n",
       "      <td>...</td>\n",
       "      <td>4.373274</td>\n",
       "      <td>2.774319</td>\n",
       "      <td>2.226374</td>\n",
       "      <td>3.018054</td>\n",
       "      <td>3.097542</td>\n",
       "      <td>3.875439</td>\n",
       "      <td>2.652719</td>\n",
       "      <td>3.020947</td>\n",
       "      <td>3.054664</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_iqr1  \\\n",
       "0    1.830603  1.873160  1.725519  1.594962  1.513311  1.417834  1.282464   \n",
       "1    1.653972  1.700725  1.442612  1.373765  1.360974  1.302505  1.178472   \n",
       "2    1.919865  1.950287  1.596515  1.595795  1.476098  1.285457  1.212172   \n",
       "3    2.215348  2.244203  1.977337  1.939716  1.737858  1.500368  1.274563   \n",
       "4    2.056869  2.179477  2.168995  2.066923  1.973254  1.829268  1.557790   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "194  0.910188  0.929432  0.820374  0.841888  0.818081  0.780074  0.837690   \n",
       "195  0.846394  0.832982  0.753228  0.761799  0.682601  0.734084  0.798138   \n",
       "196  0.799441  0.832479  0.716002  0.716839  0.647494  0.697313  0.753961   \n",
       "197  0.862368  0.973360  0.861439  0.845210  0.727936  0.765795  0.778770   \n",
       "198  0.804382  0.881502  0.849412  0.831112  0.729209  0.747993  0.824833   \n",
       "\n",
       "      l1_std2   l1_min2   l1_max2  ...   l4_adj6   l4_adj7   l4_adj8  \\\n",
       "0    1.052657  0.974200  0.959019  ...  3.948070  1.619502  1.737586   \n",
       "1    0.948451  0.962930  0.978861  ...  2.887147  1.621722  1.422434   \n",
       "2    1.040958  1.112712  1.029208  ...  2.433325  1.457065  1.313497   \n",
       "3    1.022749  1.153209  1.155699  ...  3.231465  1.457090  1.636411   \n",
       "4    1.185382  1.152784  1.106285  ...  3.475257  1.680644  1.722947   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "194  0.763892  0.778448  0.725079  ...  2.053912  1.429570  1.451467   \n",
       "195  0.713589  0.710684  0.708480  ...  3.388962  1.819057  1.783210   \n",
       "196  0.733368  0.756890  0.748847  ...  4.509243  2.614164  2.072276   \n",
       "197  0.725881  0.733296  0.758743  ...  4.704748  3.276289  2.261142   \n",
       "198  0.793283  0.794390  0.736457  ...  4.373274  2.774319  2.226374   \n",
       "\n",
       "      l4_adj9  l4_adj10  l4_adj11  l4_adj12    l4_euc    l4_rss  GT  \n",
       "0    3.056655  2.481858  3.216479  1.641629  2.833969  2.505928   3  \n",
       "1    2.023871  2.392200  2.613357  1.874043  2.460489  2.458782   3  \n",
       "2    1.668600  2.215635  2.213719  1.742178  2.388251  1.841882   3  \n",
       "3    2.088249  2.016143  2.699968  1.494795  2.451414  2.619573   3  \n",
       "4    2.527573  2.301586  2.812813  1.487229  2.523600  2.846565   3  \n",
       "..        ...       ...       ...       ...       ...       ...  ..  \n",
       "194  1.543837  1.651854  1.874679  1.503917  2.262251  1.437628   3  \n",
       "195  2.688159  2.718980  3.509049  2.113260  2.388466  2.251772   3  \n",
       "196  3.154163  3.881063  4.361751  2.650688  2.747130  2.187316   3  \n",
       "197  2.710720  3.640153  3.909919  2.856965  3.130545  2.235205   3  \n",
       "198  3.018054  3.097542  3.875439  2.652719  3.020947  3.054664   3  \n",
       "\n",
       "[199 rows x 421 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea_sess1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sess1_tot = pd.DataFrame()\n",
    "df_sess2_tot = pd.DataFrame()\n",
    "df_sess3_tot = pd.DataFrame()\n",
    "\n",
    "for i in df_fea_sess1:\n",
    "    df_sess1_tot = pd.concat([df_sess1_tot, i], axis = 0)\n",
    "    \n",
    "for i in df_fea_sess2:\n",
    "    df_sess2_tot = pd.concat([df_sess2_tot, i], axis = 0)\n",
    "    \n",
    "for i in df_fea_sess3:\n",
    "    df_sess3_tot = pd.concat([df_sess3_tot, i], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_iqr1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_adj6</th>\n",
       "      <th>l4_adj7</th>\n",
       "      <th>l4_adj8</th>\n",
       "      <th>l4_adj9</th>\n",
       "      <th>l4_adj10</th>\n",
       "      <th>l4_adj11</th>\n",
       "      <th>l4_adj12</th>\n",
       "      <th>l4_euc</th>\n",
       "      <th>l4_rss</th>\n",
       "      <th>GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508360</td>\n",
       "      <td>0.556233</td>\n",
       "      <td>0.547783</td>\n",
       "      <td>0.554438</td>\n",
       "      <td>0.538969</td>\n",
       "      <td>0.528093</td>\n",
       "      <td>0.595343</td>\n",
       "      <td>0.578696</td>\n",
       "      <td>0.637909</td>\n",
       "      <td>0.631446</td>\n",
       "      <td>...</td>\n",
       "      <td>2.824882</td>\n",
       "      <td>1.398378</td>\n",
       "      <td>1.429693</td>\n",
       "      <td>2.379176</td>\n",
       "      <td>2.900677</td>\n",
       "      <td>2.177376</td>\n",
       "      <td>1.711222</td>\n",
       "      <td>1.581755</td>\n",
       "      <td>0.514346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.579260</td>\n",
       "      <td>0.549776</td>\n",
       "      <td>0.535239</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>0.543510</td>\n",
       "      <td>0.614083</td>\n",
       "      <td>0.611247</td>\n",
       "      <td>0.662962</td>\n",
       "      <td>0.590504</td>\n",
       "      <td>...</td>\n",
       "      <td>2.945392</td>\n",
       "      <td>1.482271</td>\n",
       "      <td>1.529019</td>\n",
       "      <td>2.439519</td>\n",
       "      <td>2.971721</td>\n",
       "      <td>2.243851</td>\n",
       "      <td>1.673655</td>\n",
       "      <td>1.701424</td>\n",
       "      <td>0.472633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523973</td>\n",
       "      <td>0.615076</td>\n",
       "      <td>0.563608</td>\n",
       "      <td>0.577708</td>\n",
       "      <td>0.536653</td>\n",
       "      <td>0.565550</td>\n",
       "      <td>0.661444</td>\n",
       "      <td>0.643379</td>\n",
       "      <td>0.719187</td>\n",
       "      <td>0.600445</td>\n",
       "      <td>...</td>\n",
       "      <td>3.144561</td>\n",
       "      <td>1.535579</td>\n",
       "      <td>1.655584</td>\n",
       "      <td>2.537666</td>\n",
       "      <td>3.056356</td>\n",
       "      <td>2.314811</td>\n",
       "      <td>1.652796</td>\n",
       "      <td>1.740957</td>\n",
       "      <td>0.570579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.521867</td>\n",
       "      <td>0.585397</td>\n",
       "      <td>0.514375</td>\n",
       "      <td>0.554391</td>\n",
       "      <td>0.509185</td>\n",
       "      <td>0.557026</td>\n",
       "      <td>0.588465</td>\n",
       "      <td>0.606894</td>\n",
       "      <td>0.623689</td>\n",
       "      <td>0.568644</td>\n",
       "      <td>...</td>\n",
       "      <td>3.027890</td>\n",
       "      <td>1.446881</td>\n",
       "      <td>1.501696</td>\n",
       "      <td>2.350605</td>\n",
       "      <td>3.039381</td>\n",
       "      <td>2.209710</td>\n",
       "      <td>1.695750</td>\n",
       "      <td>1.661805</td>\n",
       "      <td>0.603008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520318</td>\n",
       "      <td>0.607385</td>\n",
       "      <td>0.544917</td>\n",
       "      <td>0.574134</td>\n",
       "      <td>0.548106</td>\n",
       "      <td>0.562364</td>\n",
       "      <td>0.583918</td>\n",
       "      <td>0.614920</td>\n",
       "      <td>0.654618</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>...</td>\n",
       "      <td>2.818021</td>\n",
       "      <td>1.362363</td>\n",
       "      <td>1.330560</td>\n",
       "      <td>2.080632</td>\n",
       "      <td>2.943398</td>\n",
       "      <td>2.176994</td>\n",
       "      <td>1.660822</td>\n",
       "      <td>1.575143</td>\n",
       "      <td>0.435911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.917898</td>\n",
       "      <td>0.919850</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.727550</td>\n",
       "      <td>0.679315</td>\n",
       "      <td>0.650399</td>\n",
       "      <td>0.645671</td>\n",
       "      <td>0.707827</td>\n",
       "      <td>0.656676</td>\n",
       "      <td>...</td>\n",
       "      <td>4.454451</td>\n",
       "      <td>2.749956</td>\n",
       "      <td>2.607276</td>\n",
       "      <td>3.803033</td>\n",
       "      <td>2.618672</td>\n",
       "      <td>4.155710</td>\n",
       "      <td>1.962209</td>\n",
       "      <td>4.423469</td>\n",
       "      <td>3.771152</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.993171</td>\n",
       "      <td>1.055292</td>\n",
       "      <td>0.918394</td>\n",
       "      <td>0.886796</td>\n",
       "      <td>0.840524</td>\n",
       "      <td>0.783448</td>\n",
       "      <td>0.783273</td>\n",
       "      <td>0.697142</td>\n",
       "      <td>0.768202</td>\n",
       "      <td>0.650290</td>\n",
       "      <td>...</td>\n",
       "      <td>4.439517</td>\n",
       "      <td>3.112935</td>\n",
       "      <td>2.914972</td>\n",
       "      <td>3.582024</td>\n",
       "      <td>2.502279</td>\n",
       "      <td>4.593882</td>\n",
       "      <td>2.161841</td>\n",
       "      <td>4.788501</td>\n",
       "      <td>3.268520</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.913375</td>\n",
       "      <td>1.006806</td>\n",
       "      <td>1.072936</td>\n",
       "      <td>1.082991</td>\n",
       "      <td>1.013199</td>\n",
       "      <td>0.927840</td>\n",
       "      <td>0.883479</td>\n",
       "      <td>0.827988</td>\n",
       "      <td>0.818503</td>\n",
       "      <td>0.758421</td>\n",
       "      <td>...</td>\n",
       "      <td>4.656702</td>\n",
       "      <td>2.967989</td>\n",
       "      <td>2.856366</td>\n",
       "      <td>3.668633</td>\n",
       "      <td>2.768351</td>\n",
       "      <td>4.650457</td>\n",
       "      <td>2.228464</td>\n",
       "      <td>5.654283</td>\n",
       "      <td>3.655176</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.987489</td>\n",
       "      <td>1.093021</td>\n",
       "      <td>1.092624</td>\n",
       "      <td>1.122730</td>\n",
       "      <td>1.011742</td>\n",
       "      <td>0.943294</td>\n",
       "      <td>0.923651</td>\n",
       "      <td>0.845975</td>\n",
       "      <td>0.821050</td>\n",
       "      <td>0.787015</td>\n",
       "      <td>...</td>\n",
       "      <td>4.555711</td>\n",
       "      <td>2.941429</td>\n",
       "      <td>2.859348</td>\n",
       "      <td>3.872804</td>\n",
       "      <td>2.970375</td>\n",
       "      <td>4.116094</td>\n",
       "      <td>2.294561</td>\n",
       "      <td>5.577052</td>\n",
       "      <td>3.980606</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.870196</td>\n",
       "      <td>0.895927</td>\n",
       "      <td>0.797970</td>\n",
       "      <td>0.818034</td>\n",
       "      <td>0.758689</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>0.791259</td>\n",
       "      <td>0.751083</td>\n",
       "      <td>0.748708</td>\n",
       "      <td>0.753879</td>\n",
       "      <td>...</td>\n",
       "      <td>4.908675</td>\n",
       "      <td>3.591927</td>\n",
       "      <td>3.139552</td>\n",
       "      <td>3.839988</td>\n",
       "      <td>2.981654</td>\n",
       "      <td>4.177724</td>\n",
       "      <td>2.279231</td>\n",
       "      <td>5.084469</td>\n",
       "      <td>3.785224</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2189 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_iqr1  \\\n",
       "0    0.508360  0.556233  0.547783  0.554438  0.538969  0.528093  0.595343   \n",
       "1    0.485241  0.579260  0.549776  0.535239  0.512745  0.543510  0.614083   \n",
       "2    0.523973  0.615076  0.563608  0.577708  0.536653  0.565550  0.661444   \n",
       "3    0.521867  0.585397  0.514375  0.554391  0.509185  0.557026  0.588465   \n",
       "4    0.520318  0.607385  0.544917  0.574134  0.548106  0.562364  0.583918   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "194  0.917898  0.919850  0.856698  0.804004  0.727550  0.679315  0.650399   \n",
       "195  0.993171  1.055292  0.918394  0.886796  0.840524  0.783448  0.783273   \n",
       "196  0.913375  1.006806  1.072936  1.082991  1.013199  0.927840  0.883479   \n",
       "197  0.987489  1.093021  1.092624  1.122730  1.011742  0.943294  0.923651   \n",
       "198  0.870196  0.895927  0.797970  0.818034  0.758689  0.781200  0.791259   \n",
       "\n",
       "      l1_std2   l1_min2   l1_max2  ...   l4_adj6   l4_adj7   l4_adj8  \\\n",
       "0    0.578696  0.637909  0.631446  ...  2.824882  1.398378  1.429693   \n",
       "1    0.611247  0.662962  0.590504  ...  2.945392  1.482271  1.529019   \n",
       "2    0.643379  0.719187  0.600445  ...  3.144561  1.535579  1.655584   \n",
       "3    0.606894  0.623689  0.568644  ...  3.027890  1.446881  1.501696   \n",
       "4    0.614920  0.654618  0.599471  ...  2.818021  1.362363  1.330560   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "194  0.645671  0.707827  0.656676  ...  4.454451  2.749956  2.607276   \n",
       "195  0.697142  0.768202  0.650290  ...  4.439517  3.112935  2.914972   \n",
       "196  0.827988  0.818503  0.758421  ...  4.656702  2.967989  2.856366   \n",
       "197  0.845975  0.821050  0.787015  ...  4.555711  2.941429  2.859348   \n",
       "198  0.751083  0.748708  0.753879  ...  4.908675  3.591927  3.139552   \n",
       "\n",
       "      l4_adj9  l4_adj10  l4_adj11  l4_adj12    l4_euc    l4_rss  GT  \n",
       "0    2.379176  2.900677  2.177376  1.711222  1.581755  0.514346   0  \n",
       "1    2.439519  2.971721  2.243851  1.673655  1.701424  0.472633   0  \n",
       "2    2.537666  3.056356  2.314811  1.652796  1.740957  0.570579   0  \n",
       "3    2.350605  3.039381  2.209710  1.695750  1.661805  0.603008   0  \n",
       "4    2.080632  2.943398  2.176994  1.660822  1.575143  0.435911   0  \n",
       "..        ...       ...       ...       ...       ...       ...  ..  \n",
       "194  3.803033  2.618672  4.155710  1.962209  4.423469  3.771152  10  \n",
       "195  3.582024  2.502279  4.593882  2.161841  4.788501  3.268520  10  \n",
       "196  3.668633  2.768351  4.650457  2.228464  5.654283  3.655176  10  \n",
       "197  3.872804  2.970375  4.116094  2.294561  5.577052  3.980606  10  \n",
       "198  3.839988  2.981654  4.177724  2.279231  5.084469  3.785224  10  \n",
       "\n",
       "[2189 rows x 421 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sess1_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session number\n",
    "\n",
    "df_sess1_tot['session'] = 1\n",
    "df_sess2_tot['session'] = 2\n",
    "df_sess3_tot['session'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_iqr1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_adj7</th>\n",
       "      <th>l4_adj8</th>\n",
       "      <th>l4_adj9</th>\n",
       "      <th>l4_adj10</th>\n",
       "      <th>l4_adj11</th>\n",
       "      <th>l4_adj12</th>\n",
       "      <th>l4_euc</th>\n",
       "      <th>l4_rss</th>\n",
       "      <th>GT</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508360</td>\n",
       "      <td>0.556233</td>\n",
       "      <td>0.547783</td>\n",
       "      <td>0.554438</td>\n",
       "      <td>0.538969</td>\n",
       "      <td>0.528093</td>\n",
       "      <td>0.595343</td>\n",
       "      <td>0.578696</td>\n",
       "      <td>0.637909</td>\n",
       "      <td>0.631446</td>\n",
       "      <td>...</td>\n",
       "      <td>1.398378</td>\n",
       "      <td>1.429693</td>\n",
       "      <td>2.379176</td>\n",
       "      <td>2.900677</td>\n",
       "      <td>2.177376</td>\n",
       "      <td>1.711222</td>\n",
       "      <td>1.581755</td>\n",
       "      <td>0.514346</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.579260</td>\n",
       "      <td>0.549776</td>\n",
       "      <td>0.535239</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>0.543510</td>\n",
       "      <td>0.614083</td>\n",
       "      <td>0.611247</td>\n",
       "      <td>0.662962</td>\n",
       "      <td>0.590504</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482271</td>\n",
       "      <td>1.529019</td>\n",
       "      <td>2.439519</td>\n",
       "      <td>2.971721</td>\n",
       "      <td>2.243851</td>\n",
       "      <td>1.673655</td>\n",
       "      <td>1.701424</td>\n",
       "      <td>0.472633</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523973</td>\n",
       "      <td>0.615076</td>\n",
       "      <td>0.563608</td>\n",
       "      <td>0.577708</td>\n",
       "      <td>0.536653</td>\n",
       "      <td>0.565550</td>\n",
       "      <td>0.661444</td>\n",
       "      <td>0.643379</td>\n",
       "      <td>0.719187</td>\n",
       "      <td>0.600445</td>\n",
       "      <td>...</td>\n",
       "      <td>1.535579</td>\n",
       "      <td>1.655584</td>\n",
       "      <td>2.537666</td>\n",
       "      <td>3.056356</td>\n",
       "      <td>2.314811</td>\n",
       "      <td>1.652796</td>\n",
       "      <td>1.740957</td>\n",
       "      <td>0.570579</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.521867</td>\n",
       "      <td>0.585397</td>\n",
       "      <td>0.514375</td>\n",
       "      <td>0.554391</td>\n",
       "      <td>0.509185</td>\n",
       "      <td>0.557026</td>\n",
       "      <td>0.588465</td>\n",
       "      <td>0.606894</td>\n",
       "      <td>0.623689</td>\n",
       "      <td>0.568644</td>\n",
       "      <td>...</td>\n",
       "      <td>1.446881</td>\n",
       "      <td>1.501696</td>\n",
       "      <td>2.350605</td>\n",
       "      <td>3.039381</td>\n",
       "      <td>2.209710</td>\n",
       "      <td>1.695750</td>\n",
       "      <td>1.661805</td>\n",
       "      <td>0.603008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520318</td>\n",
       "      <td>0.607385</td>\n",
       "      <td>0.544917</td>\n",
       "      <td>0.574134</td>\n",
       "      <td>0.548106</td>\n",
       "      <td>0.562364</td>\n",
       "      <td>0.583918</td>\n",
       "      <td>0.614920</td>\n",
       "      <td>0.654618</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.362363</td>\n",
       "      <td>1.330560</td>\n",
       "      <td>2.080632</td>\n",
       "      <td>2.943398</td>\n",
       "      <td>2.176994</td>\n",
       "      <td>1.660822</td>\n",
       "      <td>1.575143</td>\n",
       "      <td>0.435911</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.917898</td>\n",
       "      <td>0.919850</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.727550</td>\n",
       "      <td>0.679315</td>\n",
       "      <td>0.650399</td>\n",
       "      <td>0.645671</td>\n",
       "      <td>0.707827</td>\n",
       "      <td>0.656676</td>\n",
       "      <td>...</td>\n",
       "      <td>2.749956</td>\n",
       "      <td>2.607276</td>\n",
       "      <td>3.803033</td>\n",
       "      <td>2.618672</td>\n",
       "      <td>4.155710</td>\n",
       "      <td>1.962209</td>\n",
       "      <td>4.423469</td>\n",
       "      <td>3.771152</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.993171</td>\n",
       "      <td>1.055292</td>\n",
       "      <td>0.918394</td>\n",
       "      <td>0.886796</td>\n",
       "      <td>0.840524</td>\n",
       "      <td>0.783448</td>\n",
       "      <td>0.783273</td>\n",
       "      <td>0.697142</td>\n",
       "      <td>0.768202</td>\n",
       "      <td>0.650290</td>\n",
       "      <td>...</td>\n",
       "      <td>3.112935</td>\n",
       "      <td>2.914972</td>\n",
       "      <td>3.582024</td>\n",
       "      <td>2.502279</td>\n",
       "      <td>4.593882</td>\n",
       "      <td>2.161841</td>\n",
       "      <td>4.788501</td>\n",
       "      <td>3.268520</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.913375</td>\n",
       "      <td>1.006806</td>\n",
       "      <td>1.072936</td>\n",
       "      <td>1.082991</td>\n",
       "      <td>1.013199</td>\n",
       "      <td>0.927840</td>\n",
       "      <td>0.883479</td>\n",
       "      <td>0.827988</td>\n",
       "      <td>0.818503</td>\n",
       "      <td>0.758421</td>\n",
       "      <td>...</td>\n",
       "      <td>2.967989</td>\n",
       "      <td>2.856366</td>\n",
       "      <td>3.668633</td>\n",
       "      <td>2.768351</td>\n",
       "      <td>4.650457</td>\n",
       "      <td>2.228464</td>\n",
       "      <td>5.654283</td>\n",
       "      <td>3.655176</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.987489</td>\n",
       "      <td>1.093021</td>\n",
       "      <td>1.092624</td>\n",
       "      <td>1.122730</td>\n",
       "      <td>1.011742</td>\n",
       "      <td>0.943294</td>\n",
       "      <td>0.923651</td>\n",
       "      <td>0.845975</td>\n",
       "      <td>0.821050</td>\n",
       "      <td>0.787015</td>\n",
       "      <td>...</td>\n",
       "      <td>2.941429</td>\n",
       "      <td>2.859348</td>\n",
       "      <td>3.872804</td>\n",
       "      <td>2.970375</td>\n",
       "      <td>4.116094</td>\n",
       "      <td>2.294561</td>\n",
       "      <td>5.577052</td>\n",
       "      <td>3.980606</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.870196</td>\n",
       "      <td>0.895927</td>\n",
       "      <td>0.797970</td>\n",
       "      <td>0.818034</td>\n",
       "      <td>0.758689</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>0.791259</td>\n",
       "      <td>0.751083</td>\n",
       "      <td>0.748708</td>\n",
       "      <td>0.753879</td>\n",
       "      <td>...</td>\n",
       "      <td>3.591927</td>\n",
       "      <td>3.139552</td>\n",
       "      <td>3.839988</td>\n",
       "      <td>2.981654</td>\n",
       "      <td>4.177724</td>\n",
       "      <td>2.279231</td>\n",
       "      <td>5.084469</td>\n",
       "      <td>3.785224</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2189 rows × 422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_iqr1  \\\n",
       "0    0.508360  0.556233  0.547783  0.554438  0.538969  0.528093  0.595343   \n",
       "1    0.485241  0.579260  0.549776  0.535239  0.512745  0.543510  0.614083   \n",
       "2    0.523973  0.615076  0.563608  0.577708  0.536653  0.565550  0.661444   \n",
       "3    0.521867  0.585397  0.514375  0.554391  0.509185  0.557026  0.588465   \n",
       "4    0.520318  0.607385  0.544917  0.574134  0.548106  0.562364  0.583918   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "194  0.917898  0.919850  0.856698  0.804004  0.727550  0.679315  0.650399   \n",
       "195  0.993171  1.055292  0.918394  0.886796  0.840524  0.783448  0.783273   \n",
       "196  0.913375  1.006806  1.072936  1.082991  1.013199  0.927840  0.883479   \n",
       "197  0.987489  1.093021  1.092624  1.122730  1.011742  0.943294  0.923651   \n",
       "198  0.870196  0.895927  0.797970  0.818034  0.758689  0.781200  0.791259   \n",
       "\n",
       "      l1_std2   l1_min2   l1_max2  ...   l4_adj7   l4_adj8   l4_adj9  \\\n",
       "0    0.578696  0.637909  0.631446  ...  1.398378  1.429693  2.379176   \n",
       "1    0.611247  0.662962  0.590504  ...  1.482271  1.529019  2.439519   \n",
       "2    0.643379  0.719187  0.600445  ...  1.535579  1.655584  2.537666   \n",
       "3    0.606894  0.623689  0.568644  ...  1.446881  1.501696  2.350605   \n",
       "4    0.614920  0.654618  0.599471  ...  1.362363  1.330560  2.080632   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "194  0.645671  0.707827  0.656676  ...  2.749956  2.607276  3.803033   \n",
       "195  0.697142  0.768202  0.650290  ...  3.112935  2.914972  3.582024   \n",
       "196  0.827988  0.818503  0.758421  ...  2.967989  2.856366  3.668633   \n",
       "197  0.845975  0.821050  0.787015  ...  2.941429  2.859348  3.872804   \n",
       "198  0.751083  0.748708  0.753879  ...  3.591927  3.139552  3.839988   \n",
       "\n",
       "     l4_adj10  l4_adj11  l4_adj12    l4_euc    l4_rss  GT  session  \n",
       "0    2.900677  2.177376  1.711222  1.581755  0.514346   0        1  \n",
       "1    2.971721  2.243851  1.673655  1.701424  0.472633   0        1  \n",
       "2    3.056356  2.314811  1.652796  1.740957  0.570579   0        1  \n",
       "3    3.039381  2.209710  1.695750  1.661805  0.603008   0        1  \n",
       "4    2.943398  2.176994  1.660822  1.575143  0.435911   0        1  \n",
       "..        ...       ...       ...       ...       ...  ..      ...  \n",
       "194  2.618672  4.155710  1.962209  4.423469  3.771152  10        1  \n",
       "195  2.502279  4.593882  2.161841  4.788501  3.268520  10        1  \n",
       "196  2.768351  4.650457  2.228464  5.654283  3.655176  10        1  \n",
       "197  2.970375  4.116094  2.294561  5.577052  3.980606  10        1  \n",
       "198  2.981654  4.177724  2.279231  5.084469  3.785224  10        1  \n",
       "\n",
       "[2189 rows x 422 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sess1_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_iqr1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_adj7</th>\n",
       "      <th>l4_adj8</th>\n",
       "      <th>l4_adj9</th>\n",
       "      <th>l4_adj10</th>\n",
       "      <th>l4_adj11</th>\n",
       "      <th>l4_adj12</th>\n",
       "      <th>l4_euc</th>\n",
       "      <th>l4_rss</th>\n",
       "      <th>GT</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508360</td>\n",
       "      <td>0.556233</td>\n",
       "      <td>0.547783</td>\n",
       "      <td>0.554438</td>\n",
       "      <td>0.538969</td>\n",
       "      <td>0.528093</td>\n",
       "      <td>0.595343</td>\n",
       "      <td>0.578696</td>\n",
       "      <td>0.637909</td>\n",
       "      <td>0.631446</td>\n",
       "      <td>...</td>\n",
       "      <td>1.398378</td>\n",
       "      <td>1.429693</td>\n",
       "      <td>2.379176</td>\n",
       "      <td>2.900677</td>\n",
       "      <td>2.177376</td>\n",
       "      <td>1.711222</td>\n",
       "      <td>1.581755</td>\n",
       "      <td>0.514346</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.579260</td>\n",
       "      <td>0.549776</td>\n",
       "      <td>0.535239</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>0.543510</td>\n",
       "      <td>0.614083</td>\n",
       "      <td>0.611247</td>\n",
       "      <td>0.662962</td>\n",
       "      <td>0.590504</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482271</td>\n",
       "      <td>1.529019</td>\n",
       "      <td>2.439519</td>\n",
       "      <td>2.971721</td>\n",
       "      <td>2.243851</td>\n",
       "      <td>1.673655</td>\n",
       "      <td>1.701424</td>\n",
       "      <td>0.472633</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523973</td>\n",
       "      <td>0.615076</td>\n",
       "      <td>0.563608</td>\n",
       "      <td>0.577708</td>\n",
       "      <td>0.536653</td>\n",
       "      <td>0.565550</td>\n",
       "      <td>0.661444</td>\n",
       "      <td>0.643379</td>\n",
       "      <td>0.719187</td>\n",
       "      <td>0.600445</td>\n",
       "      <td>...</td>\n",
       "      <td>1.535579</td>\n",
       "      <td>1.655584</td>\n",
       "      <td>2.537666</td>\n",
       "      <td>3.056356</td>\n",
       "      <td>2.314811</td>\n",
       "      <td>1.652796</td>\n",
       "      <td>1.740957</td>\n",
       "      <td>0.570579</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.521867</td>\n",
       "      <td>0.585397</td>\n",
       "      <td>0.514375</td>\n",
       "      <td>0.554391</td>\n",
       "      <td>0.509185</td>\n",
       "      <td>0.557026</td>\n",
       "      <td>0.588465</td>\n",
       "      <td>0.606894</td>\n",
       "      <td>0.623689</td>\n",
       "      <td>0.568644</td>\n",
       "      <td>...</td>\n",
       "      <td>1.446881</td>\n",
       "      <td>1.501696</td>\n",
       "      <td>2.350605</td>\n",
       "      <td>3.039381</td>\n",
       "      <td>2.209710</td>\n",
       "      <td>1.695750</td>\n",
       "      <td>1.661805</td>\n",
       "      <td>0.603008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520318</td>\n",
       "      <td>0.607385</td>\n",
       "      <td>0.544917</td>\n",
       "      <td>0.574134</td>\n",
       "      <td>0.548106</td>\n",
       "      <td>0.562364</td>\n",
       "      <td>0.583918</td>\n",
       "      <td>0.614920</td>\n",
       "      <td>0.654618</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.362363</td>\n",
       "      <td>1.330560</td>\n",
       "      <td>2.080632</td>\n",
       "      <td>2.943398</td>\n",
       "      <td>2.176994</td>\n",
       "      <td>1.660822</td>\n",
       "      <td>1.575143</td>\n",
       "      <td>0.435911</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.202281</td>\n",
       "      <td>1.290801</td>\n",
       "      <td>1.271125</td>\n",
       "      <td>1.305875</td>\n",
       "      <td>1.164755</td>\n",
       "      <td>1.178365</td>\n",
       "      <td>1.393361</td>\n",
       "      <td>1.390979</td>\n",
       "      <td>1.085079</td>\n",
       "      <td>1.281914</td>\n",
       "      <td>...</td>\n",
       "      <td>3.599491</td>\n",
       "      <td>3.233487</td>\n",
       "      <td>4.721437</td>\n",
       "      <td>3.916543</td>\n",
       "      <td>5.886878</td>\n",
       "      <td>4.088313</td>\n",
       "      <td>6.122421</td>\n",
       "      <td>3.924364</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.722978</td>\n",
       "      <td>0.720824</td>\n",
       "      <td>0.755536</td>\n",
       "      <td>0.760434</td>\n",
       "      <td>0.756769</td>\n",
       "      <td>0.859506</td>\n",
       "      <td>0.879017</td>\n",
       "      <td>0.809056</td>\n",
       "      <td>0.723456</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>...</td>\n",
       "      <td>3.853352</td>\n",
       "      <td>3.410025</td>\n",
       "      <td>5.080214</td>\n",
       "      <td>4.169576</td>\n",
       "      <td>6.019021</td>\n",
       "      <td>3.874508</td>\n",
       "      <td>6.068462</td>\n",
       "      <td>3.071311</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.439172</td>\n",
       "      <td>1.433734</td>\n",
       "      <td>1.375746</td>\n",
       "      <td>1.396880</td>\n",
       "      <td>1.182754</td>\n",
       "      <td>1.100798</td>\n",
       "      <td>1.080205</td>\n",
       "      <td>0.930623</td>\n",
       "      <td>0.951749</td>\n",
       "      <td>0.980427</td>\n",
       "      <td>...</td>\n",
       "      <td>3.939145</td>\n",
       "      <td>3.469200</td>\n",
       "      <td>4.786500</td>\n",
       "      <td>3.846884</td>\n",
       "      <td>5.735223</td>\n",
       "      <td>3.777857</td>\n",
       "      <td>6.277089</td>\n",
       "      <td>3.256937</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.687076</td>\n",
       "      <td>1.663921</td>\n",
       "      <td>1.522277</td>\n",
       "      <td>1.425893</td>\n",
       "      <td>1.212331</td>\n",
       "      <td>1.112767</td>\n",
       "      <td>1.146947</td>\n",
       "      <td>1.055635</td>\n",
       "      <td>1.047915</td>\n",
       "      <td>0.989870</td>\n",
       "      <td>...</td>\n",
       "      <td>3.470630</td>\n",
       "      <td>3.189984</td>\n",
       "      <td>4.881475</td>\n",
       "      <td>3.785914</td>\n",
       "      <td>5.302870</td>\n",
       "      <td>3.445231</td>\n",
       "      <td>5.274994</td>\n",
       "      <td>3.496227</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.183976</td>\n",
       "      <td>1.173874</td>\n",
       "      <td>1.093922</td>\n",
       "      <td>0.992997</td>\n",
       "      <td>0.859864</td>\n",
       "      <td>0.880510</td>\n",
       "      <td>1.061805</td>\n",
       "      <td>0.927424</td>\n",
       "      <td>0.942287</td>\n",
       "      <td>0.812715</td>\n",
       "      <td>...</td>\n",
       "      <td>3.035974</td>\n",
       "      <td>2.876209</td>\n",
       "      <td>4.537331</td>\n",
       "      <td>3.686244</td>\n",
       "      <td>5.232478</td>\n",
       "      <td>2.725681</td>\n",
       "      <td>4.490210</td>\n",
       "      <td>3.523084</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6567 rows × 422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_iqr1  \\\n",
       "0    0.508360  0.556233  0.547783  0.554438  0.538969  0.528093  0.595343   \n",
       "1    0.485241  0.579260  0.549776  0.535239  0.512745  0.543510  0.614083   \n",
       "2    0.523973  0.615076  0.563608  0.577708  0.536653  0.565550  0.661444   \n",
       "3    0.521867  0.585397  0.514375  0.554391  0.509185  0.557026  0.588465   \n",
       "4    0.520318  0.607385  0.544917  0.574134  0.548106  0.562364  0.583918   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "194  1.202281  1.290801  1.271125  1.305875  1.164755  1.178365  1.393361   \n",
       "195  0.722978  0.720824  0.755536  0.760434  0.756769  0.859506  0.879017   \n",
       "196  1.439172  1.433734  1.375746  1.396880  1.182754  1.100798  1.080205   \n",
       "197  1.687076  1.663921  1.522277  1.425893  1.212331  1.112767  1.146947   \n",
       "198  1.183976  1.173874  1.093922  0.992997  0.859864  0.880510  1.061805   \n",
       "\n",
       "      l1_std2   l1_min2   l1_max2  ...   l4_adj7   l4_adj8   l4_adj9  \\\n",
       "0    0.578696  0.637909  0.631446  ...  1.398378  1.429693  2.379176   \n",
       "1    0.611247  0.662962  0.590504  ...  1.482271  1.529019  2.439519   \n",
       "2    0.643379  0.719187  0.600445  ...  1.535579  1.655584  2.537666   \n",
       "3    0.606894  0.623689  0.568644  ...  1.446881  1.501696  2.350605   \n",
       "4    0.614920  0.654618  0.599471  ...  1.362363  1.330560  2.080632   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "194  1.390979  1.085079  1.281914  ...  3.599491  3.233487  4.721437   \n",
       "195  0.809056  0.723456  0.669041  ...  3.853352  3.410025  5.080214   \n",
       "196  0.930623  0.951749  0.980427  ...  3.939145  3.469200  4.786500   \n",
       "197  1.055635  1.047915  0.989870  ...  3.470630  3.189984  4.881475   \n",
       "198  0.927424  0.942287  0.812715  ...  3.035974  2.876209  4.537331   \n",
       "\n",
       "     l4_adj10  l4_adj11  l4_adj12    l4_euc    l4_rss  GT  session  \n",
       "0    2.900677  2.177376  1.711222  1.581755  0.514346   0        1  \n",
       "1    2.971721  2.243851  1.673655  1.701424  0.472633   0        1  \n",
       "2    3.056356  2.314811  1.652796  1.740957  0.570579   0        1  \n",
       "3    3.039381  2.209710  1.695750  1.661805  0.603008   0        1  \n",
       "4    2.943398  2.176994  1.660822  1.575143  0.435911   0        1  \n",
       "..        ...       ...       ...       ...       ...  ..      ...  \n",
       "194  3.916543  5.886878  4.088313  6.122421  3.924364  10        3  \n",
       "195  4.169576  6.019021  3.874508  6.068462  3.071311  10        3  \n",
       "196  3.846884  5.735223  3.777857  6.277089  3.256937  10        3  \n",
       "197  3.785914  5.302870  3.445231  5.274994  3.496227  10        3  \n",
       "198  3.686244  5.232478  2.725681  4.490210  3.523084  10        3  \n",
       "\n",
       "[6567 rows x 422 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sess_tot = pd.DataFrame()\n",
    "\n",
    "df_sess_tot = pd.concat([df_sess_tot,df_sess1_tot], axis = 0)\n",
    "df_sess_tot = pd.concat([df_sess_tot,df_sess2_tot], axis = 0)\n",
    "df_sess_tot = pd.concat([df_sess_tot,df_sess3_tot], axis = 0)\n",
    "\n",
    "df_sess_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_iqr1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_adj7</th>\n",
       "      <th>l4_adj8</th>\n",
       "      <th>l4_adj9</th>\n",
       "      <th>l4_adj10</th>\n",
       "      <th>l4_adj11</th>\n",
       "      <th>l4_adj12</th>\n",
       "      <th>l4_euc</th>\n",
       "      <th>l4_rss</th>\n",
       "      <th>GT</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508360</td>\n",
       "      <td>0.556233</td>\n",
       "      <td>0.547783</td>\n",
       "      <td>0.554438</td>\n",
       "      <td>0.538969</td>\n",
       "      <td>0.528093</td>\n",
       "      <td>0.595343</td>\n",
       "      <td>0.578696</td>\n",
       "      <td>0.637909</td>\n",
       "      <td>0.631446</td>\n",
       "      <td>...</td>\n",
       "      <td>1.398378</td>\n",
       "      <td>1.429693</td>\n",
       "      <td>2.379176</td>\n",
       "      <td>2.900677</td>\n",
       "      <td>2.177376</td>\n",
       "      <td>1.711222</td>\n",
       "      <td>1.581755</td>\n",
       "      <td>0.514346</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.579260</td>\n",
       "      <td>0.549776</td>\n",
       "      <td>0.535239</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>0.543510</td>\n",
       "      <td>0.614083</td>\n",
       "      <td>0.611247</td>\n",
       "      <td>0.662962</td>\n",
       "      <td>0.590504</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482271</td>\n",
       "      <td>1.529019</td>\n",
       "      <td>2.439519</td>\n",
       "      <td>2.971721</td>\n",
       "      <td>2.243851</td>\n",
       "      <td>1.673655</td>\n",
       "      <td>1.701424</td>\n",
       "      <td>0.472633</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523973</td>\n",
       "      <td>0.615076</td>\n",
       "      <td>0.563608</td>\n",
       "      <td>0.577708</td>\n",
       "      <td>0.536653</td>\n",
       "      <td>0.565550</td>\n",
       "      <td>0.661444</td>\n",
       "      <td>0.643379</td>\n",
       "      <td>0.719187</td>\n",
       "      <td>0.600445</td>\n",
       "      <td>...</td>\n",
       "      <td>1.535579</td>\n",
       "      <td>1.655584</td>\n",
       "      <td>2.537666</td>\n",
       "      <td>3.056356</td>\n",
       "      <td>2.314811</td>\n",
       "      <td>1.652796</td>\n",
       "      <td>1.740957</td>\n",
       "      <td>0.570579</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.521867</td>\n",
       "      <td>0.585397</td>\n",
       "      <td>0.514375</td>\n",
       "      <td>0.554391</td>\n",
       "      <td>0.509185</td>\n",
       "      <td>0.557026</td>\n",
       "      <td>0.588465</td>\n",
       "      <td>0.606894</td>\n",
       "      <td>0.623689</td>\n",
       "      <td>0.568644</td>\n",
       "      <td>...</td>\n",
       "      <td>1.446881</td>\n",
       "      <td>1.501696</td>\n",
       "      <td>2.350605</td>\n",
       "      <td>3.039381</td>\n",
       "      <td>2.209710</td>\n",
       "      <td>1.695750</td>\n",
       "      <td>1.661805</td>\n",
       "      <td>0.603008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520318</td>\n",
       "      <td>0.607385</td>\n",
       "      <td>0.544917</td>\n",
       "      <td>0.574134</td>\n",
       "      <td>0.548106</td>\n",
       "      <td>0.562364</td>\n",
       "      <td>0.583918</td>\n",
       "      <td>0.614920</td>\n",
       "      <td>0.654618</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.362363</td>\n",
       "      <td>1.330560</td>\n",
       "      <td>2.080632</td>\n",
       "      <td>2.943398</td>\n",
       "      <td>2.176994</td>\n",
       "      <td>1.660822</td>\n",
       "      <td>1.575143</td>\n",
       "      <td>0.435911</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>1.202281</td>\n",
       "      <td>1.290801</td>\n",
       "      <td>1.271125</td>\n",
       "      <td>1.305875</td>\n",
       "      <td>1.164755</td>\n",
       "      <td>1.178365</td>\n",
       "      <td>1.393361</td>\n",
       "      <td>1.390979</td>\n",
       "      <td>1.085079</td>\n",
       "      <td>1.281914</td>\n",
       "      <td>...</td>\n",
       "      <td>3.599491</td>\n",
       "      <td>3.233487</td>\n",
       "      <td>4.721437</td>\n",
       "      <td>3.916543</td>\n",
       "      <td>5.886878</td>\n",
       "      <td>4.088313</td>\n",
       "      <td>6.122421</td>\n",
       "      <td>3.924364</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>0.722978</td>\n",
       "      <td>0.720824</td>\n",
       "      <td>0.755536</td>\n",
       "      <td>0.760434</td>\n",
       "      <td>0.756769</td>\n",
       "      <td>0.859506</td>\n",
       "      <td>0.879017</td>\n",
       "      <td>0.809056</td>\n",
       "      <td>0.723456</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>...</td>\n",
       "      <td>3.853352</td>\n",
       "      <td>3.410025</td>\n",
       "      <td>5.080214</td>\n",
       "      <td>4.169576</td>\n",
       "      <td>6.019021</td>\n",
       "      <td>3.874508</td>\n",
       "      <td>6.068462</td>\n",
       "      <td>3.071311</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>1.439172</td>\n",
       "      <td>1.433734</td>\n",
       "      <td>1.375746</td>\n",
       "      <td>1.396880</td>\n",
       "      <td>1.182754</td>\n",
       "      <td>1.100798</td>\n",
       "      <td>1.080205</td>\n",
       "      <td>0.930623</td>\n",
       "      <td>0.951749</td>\n",
       "      <td>0.980427</td>\n",
       "      <td>...</td>\n",
       "      <td>3.939145</td>\n",
       "      <td>3.469200</td>\n",
       "      <td>4.786500</td>\n",
       "      <td>3.846884</td>\n",
       "      <td>5.735223</td>\n",
       "      <td>3.777857</td>\n",
       "      <td>6.277089</td>\n",
       "      <td>3.256937</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>1.687076</td>\n",
       "      <td>1.663921</td>\n",
       "      <td>1.522277</td>\n",
       "      <td>1.425893</td>\n",
       "      <td>1.212331</td>\n",
       "      <td>1.112767</td>\n",
       "      <td>1.146947</td>\n",
       "      <td>1.055635</td>\n",
       "      <td>1.047915</td>\n",
       "      <td>0.989870</td>\n",
       "      <td>...</td>\n",
       "      <td>3.470630</td>\n",
       "      <td>3.189984</td>\n",
       "      <td>4.881475</td>\n",
       "      <td>3.785914</td>\n",
       "      <td>5.302870</td>\n",
       "      <td>3.445231</td>\n",
       "      <td>5.274994</td>\n",
       "      <td>3.496227</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>1.183976</td>\n",
       "      <td>1.173874</td>\n",
       "      <td>1.093922</td>\n",
       "      <td>0.992997</td>\n",
       "      <td>0.859864</td>\n",
       "      <td>0.880510</td>\n",
       "      <td>1.061805</td>\n",
       "      <td>0.927424</td>\n",
       "      <td>0.942287</td>\n",
       "      <td>0.812715</td>\n",
       "      <td>...</td>\n",
       "      <td>3.035974</td>\n",
       "      <td>2.876209</td>\n",
       "      <td>4.537331</td>\n",
       "      <td>3.686244</td>\n",
       "      <td>5.232478</td>\n",
       "      <td>2.725681</td>\n",
       "      <td>4.490210</td>\n",
       "      <td>3.523084</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6567 rows × 422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_iqr1  \\\n",
       "0     0.508360  0.556233  0.547783  0.554438  0.538969  0.528093  0.595343   \n",
       "1     0.485241  0.579260  0.549776  0.535239  0.512745  0.543510  0.614083   \n",
       "2     0.523973  0.615076  0.563608  0.577708  0.536653  0.565550  0.661444   \n",
       "3     0.521867  0.585397  0.514375  0.554391  0.509185  0.557026  0.588465   \n",
       "4     0.520318  0.607385  0.544917  0.574134  0.548106  0.562364  0.583918   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6562  1.202281  1.290801  1.271125  1.305875  1.164755  1.178365  1.393361   \n",
       "6563  0.722978  0.720824  0.755536  0.760434  0.756769  0.859506  0.879017   \n",
       "6564  1.439172  1.433734  1.375746  1.396880  1.182754  1.100798  1.080205   \n",
       "6565  1.687076  1.663921  1.522277  1.425893  1.212331  1.112767  1.146947   \n",
       "6566  1.183976  1.173874  1.093922  0.992997  0.859864  0.880510  1.061805   \n",
       "\n",
       "       l1_std2   l1_min2   l1_max2  ...   l4_adj7   l4_adj8   l4_adj9  \\\n",
       "0     0.578696  0.637909  0.631446  ...  1.398378  1.429693  2.379176   \n",
       "1     0.611247  0.662962  0.590504  ...  1.482271  1.529019  2.439519   \n",
       "2     0.643379  0.719187  0.600445  ...  1.535579  1.655584  2.537666   \n",
       "3     0.606894  0.623689  0.568644  ...  1.446881  1.501696  2.350605   \n",
       "4     0.614920  0.654618  0.599471  ...  1.362363  1.330560  2.080632   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6562  1.390979  1.085079  1.281914  ...  3.599491  3.233487  4.721437   \n",
       "6563  0.809056  0.723456  0.669041  ...  3.853352  3.410025  5.080214   \n",
       "6564  0.930623  0.951749  0.980427  ...  3.939145  3.469200  4.786500   \n",
       "6565  1.055635  1.047915  0.989870  ...  3.470630  3.189984  4.881475   \n",
       "6566  0.927424  0.942287  0.812715  ...  3.035974  2.876209  4.537331   \n",
       "\n",
       "      l4_adj10  l4_adj11  l4_adj12    l4_euc    l4_rss  GT  session  \n",
       "0     2.900677  2.177376  1.711222  1.581755  0.514346   0        1  \n",
       "1     2.971721  2.243851  1.673655  1.701424  0.472633   0        1  \n",
       "2     3.056356  2.314811  1.652796  1.740957  0.570579   0        1  \n",
       "3     3.039381  2.209710  1.695750  1.661805  0.603008   0        1  \n",
       "4     2.943398  2.176994  1.660822  1.575143  0.435911   0        1  \n",
       "...        ...       ...       ...       ...       ...  ..      ...  \n",
       "6562  3.916543  5.886878  4.088313  6.122421  3.924364  10        3  \n",
       "6563  4.169576  6.019021  3.874508  6.068462  3.071311  10        3  \n",
       "6564  3.846884  5.735223  3.777857  6.277089  3.256937  10        3  \n",
       "6565  3.785914  5.302870  3.445231  5.274994  3.496227  10        3  \n",
       "6566  3.686244  5.232478  2.725681  4.490210  3.523084  10        3  \n",
       "\n",
       "[6567 rows x 422 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row index reset\n",
    "\n",
    "df_sess_tot = df_sess_tot.reset_index()\n",
    "df_sess_tot = df_sess_tot.drop('index', axis = 1)\n",
    "\n",
    "df_sess_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_std1</th>\n",
       "      <th>l1_min1</th>\n",
       "      <th>l1_max1</th>\n",
       "      <th>l1_qtl1</th>\n",
       "      <th>l1_qtu1</th>\n",
       "      <th>l1_avg1</th>\n",
       "      <th>l1_iqr1</th>\n",
       "      <th>l1_std2</th>\n",
       "      <th>l1_min2</th>\n",
       "      <th>l1_max2</th>\n",
       "      <th>...</th>\n",
       "      <th>l4_adj5</th>\n",
       "      <th>l4_adj6</th>\n",
       "      <th>l4_adj7</th>\n",
       "      <th>l4_adj8</th>\n",
       "      <th>l4_adj9</th>\n",
       "      <th>l4_adj10</th>\n",
       "      <th>l4_adj11</th>\n",
       "      <th>l4_adj12</th>\n",
       "      <th>l4_euc</th>\n",
       "      <th>l4_rss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508360</td>\n",
       "      <td>0.556233</td>\n",
       "      <td>0.547783</td>\n",
       "      <td>0.554438</td>\n",
       "      <td>0.538969</td>\n",
       "      <td>0.528093</td>\n",
       "      <td>0.595343</td>\n",
       "      <td>0.578696</td>\n",
       "      <td>0.637909</td>\n",
       "      <td>0.631446</td>\n",
       "      <td>...</td>\n",
       "      <td>3.255593</td>\n",
       "      <td>2.824882</td>\n",
       "      <td>1.398378</td>\n",
       "      <td>1.429693</td>\n",
       "      <td>2.379176</td>\n",
       "      <td>2.900677</td>\n",
       "      <td>2.177376</td>\n",
       "      <td>1.711222</td>\n",
       "      <td>1.581755</td>\n",
       "      <td>0.514346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.579260</td>\n",
       "      <td>0.549776</td>\n",
       "      <td>0.535239</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>0.543510</td>\n",
       "      <td>0.614083</td>\n",
       "      <td>0.611247</td>\n",
       "      <td>0.662962</td>\n",
       "      <td>0.590504</td>\n",
       "      <td>...</td>\n",
       "      <td>3.329217</td>\n",
       "      <td>2.945392</td>\n",
       "      <td>1.482271</td>\n",
       "      <td>1.529019</td>\n",
       "      <td>2.439519</td>\n",
       "      <td>2.971721</td>\n",
       "      <td>2.243851</td>\n",
       "      <td>1.673655</td>\n",
       "      <td>1.701424</td>\n",
       "      <td>0.472633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523973</td>\n",
       "      <td>0.615076</td>\n",
       "      <td>0.563608</td>\n",
       "      <td>0.577708</td>\n",
       "      <td>0.536653</td>\n",
       "      <td>0.565550</td>\n",
       "      <td>0.661444</td>\n",
       "      <td>0.643379</td>\n",
       "      <td>0.719187</td>\n",
       "      <td>0.600445</td>\n",
       "      <td>...</td>\n",
       "      <td>3.390512</td>\n",
       "      <td>3.144561</td>\n",
       "      <td>1.535579</td>\n",
       "      <td>1.655584</td>\n",
       "      <td>2.537666</td>\n",
       "      <td>3.056356</td>\n",
       "      <td>2.314811</td>\n",
       "      <td>1.652796</td>\n",
       "      <td>1.740957</td>\n",
       "      <td>0.570579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.521867</td>\n",
       "      <td>0.585397</td>\n",
       "      <td>0.514375</td>\n",
       "      <td>0.554391</td>\n",
       "      <td>0.509185</td>\n",
       "      <td>0.557026</td>\n",
       "      <td>0.588465</td>\n",
       "      <td>0.606894</td>\n",
       "      <td>0.623689</td>\n",
       "      <td>0.568644</td>\n",
       "      <td>...</td>\n",
       "      <td>3.327382</td>\n",
       "      <td>3.027890</td>\n",
       "      <td>1.446881</td>\n",
       "      <td>1.501696</td>\n",
       "      <td>2.350605</td>\n",
       "      <td>3.039381</td>\n",
       "      <td>2.209710</td>\n",
       "      <td>1.695750</td>\n",
       "      <td>1.661805</td>\n",
       "      <td>0.603008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520318</td>\n",
       "      <td>0.607385</td>\n",
       "      <td>0.544917</td>\n",
       "      <td>0.574134</td>\n",
       "      <td>0.548106</td>\n",
       "      <td>0.562364</td>\n",
       "      <td>0.583918</td>\n",
       "      <td>0.614920</td>\n",
       "      <td>0.654618</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>...</td>\n",
       "      <td>3.273700</td>\n",
       "      <td>2.818021</td>\n",
       "      <td>1.362363</td>\n",
       "      <td>1.330560</td>\n",
       "      <td>2.080632</td>\n",
       "      <td>2.943398</td>\n",
       "      <td>2.176994</td>\n",
       "      <td>1.660822</td>\n",
       "      <td>1.575143</td>\n",
       "      <td>0.435911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>1.202281</td>\n",
       "      <td>1.290801</td>\n",
       "      <td>1.271125</td>\n",
       "      <td>1.305875</td>\n",
       "      <td>1.164755</td>\n",
       "      <td>1.178365</td>\n",
       "      <td>1.393361</td>\n",
       "      <td>1.390979</td>\n",
       "      <td>1.085079</td>\n",
       "      <td>1.281914</td>\n",
       "      <td>...</td>\n",
       "      <td>3.177322</td>\n",
       "      <td>5.855425</td>\n",
       "      <td>3.599491</td>\n",
       "      <td>3.233487</td>\n",
       "      <td>4.721437</td>\n",
       "      <td>3.916543</td>\n",
       "      <td>5.886878</td>\n",
       "      <td>4.088313</td>\n",
       "      <td>6.122421</td>\n",
       "      <td>3.924364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>0.722978</td>\n",
       "      <td>0.720824</td>\n",
       "      <td>0.755536</td>\n",
       "      <td>0.760434</td>\n",
       "      <td>0.756769</td>\n",
       "      <td>0.859506</td>\n",
       "      <td>0.879017</td>\n",
       "      <td>0.809056</td>\n",
       "      <td>0.723456</td>\n",
       "      <td>0.669041</td>\n",
       "      <td>...</td>\n",
       "      <td>3.688230</td>\n",
       "      <td>6.062943</td>\n",
       "      <td>3.853352</td>\n",
       "      <td>3.410025</td>\n",
       "      <td>5.080214</td>\n",
       "      <td>4.169576</td>\n",
       "      <td>6.019021</td>\n",
       "      <td>3.874508</td>\n",
       "      <td>6.068462</td>\n",
       "      <td>3.071311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>1.439172</td>\n",
       "      <td>1.433734</td>\n",
       "      <td>1.375746</td>\n",
       "      <td>1.396880</td>\n",
       "      <td>1.182754</td>\n",
       "      <td>1.100798</td>\n",
       "      <td>1.080205</td>\n",
       "      <td>0.930623</td>\n",
       "      <td>0.951749</td>\n",
       "      <td>0.980427</td>\n",
       "      <td>...</td>\n",
       "      <td>3.616793</td>\n",
       "      <td>5.867715</td>\n",
       "      <td>3.939145</td>\n",
       "      <td>3.469200</td>\n",
       "      <td>4.786500</td>\n",
       "      <td>3.846884</td>\n",
       "      <td>5.735223</td>\n",
       "      <td>3.777857</td>\n",
       "      <td>6.277089</td>\n",
       "      <td>3.256937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>1.687076</td>\n",
       "      <td>1.663921</td>\n",
       "      <td>1.522277</td>\n",
       "      <td>1.425893</td>\n",
       "      <td>1.212331</td>\n",
       "      <td>1.112767</td>\n",
       "      <td>1.146947</td>\n",
       "      <td>1.055635</td>\n",
       "      <td>1.047915</td>\n",
       "      <td>0.989870</td>\n",
       "      <td>...</td>\n",
       "      <td>3.374324</td>\n",
       "      <td>5.820106</td>\n",
       "      <td>3.470630</td>\n",
       "      <td>3.189984</td>\n",
       "      <td>4.881475</td>\n",
       "      <td>3.785914</td>\n",
       "      <td>5.302870</td>\n",
       "      <td>3.445231</td>\n",
       "      <td>5.274994</td>\n",
       "      <td>3.496227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>1.183976</td>\n",
       "      <td>1.173874</td>\n",
       "      <td>1.093922</td>\n",
       "      <td>0.992997</td>\n",
       "      <td>0.859864</td>\n",
       "      <td>0.880510</td>\n",
       "      <td>1.061805</td>\n",
       "      <td>0.927424</td>\n",
       "      <td>0.942287</td>\n",
       "      <td>0.812715</td>\n",
       "      <td>...</td>\n",
       "      <td>3.286019</td>\n",
       "      <td>5.821257</td>\n",
       "      <td>3.035974</td>\n",
       "      <td>2.876209</td>\n",
       "      <td>4.537331</td>\n",
       "      <td>3.686244</td>\n",
       "      <td>5.232478</td>\n",
       "      <td>2.725681</td>\n",
       "      <td>4.490210</td>\n",
       "      <td>3.523084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6567 rows × 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       l1_std1   l1_min1   l1_max1   l1_qtl1   l1_qtu1   l1_avg1   l1_iqr1  \\\n",
       "0     0.508360  0.556233  0.547783  0.554438  0.538969  0.528093  0.595343   \n",
       "1     0.485241  0.579260  0.549776  0.535239  0.512745  0.543510  0.614083   \n",
       "2     0.523973  0.615076  0.563608  0.577708  0.536653  0.565550  0.661444   \n",
       "3     0.521867  0.585397  0.514375  0.554391  0.509185  0.557026  0.588465   \n",
       "4     0.520318  0.607385  0.544917  0.574134  0.548106  0.562364  0.583918   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6562  1.202281  1.290801  1.271125  1.305875  1.164755  1.178365  1.393361   \n",
       "6563  0.722978  0.720824  0.755536  0.760434  0.756769  0.859506  0.879017   \n",
       "6564  1.439172  1.433734  1.375746  1.396880  1.182754  1.100798  1.080205   \n",
       "6565  1.687076  1.663921  1.522277  1.425893  1.212331  1.112767  1.146947   \n",
       "6566  1.183976  1.173874  1.093922  0.992997  0.859864  0.880510  1.061805   \n",
       "\n",
       "       l1_std2   l1_min2   l1_max2  ...   l4_adj5   l4_adj6   l4_adj7  \\\n",
       "0     0.578696  0.637909  0.631446  ...  3.255593  2.824882  1.398378   \n",
       "1     0.611247  0.662962  0.590504  ...  3.329217  2.945392  1.482271   \n",
       "2     0.643379  0.719187  0.600445  ...  3.390512  3.144561  1.535579   \n",
       "3     0.606894  0.623689  0.568644  ...  3.327382  3.027890  1.446881   \n",
       "4     0.614920  0.654618  0.599471  ...  3.273700  2.818021  1.362363   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6562  1.390979  1.085079  1.281914  ...  3.177322  5.855425  3.599491   \n",
       "6563  0.809056  0.723456  0.669041  ...  3.688230  6.062943  3.853352   \n",
       "6564  0.930623  0.951749  0.980427  ...  3.616793  5.867715  3.939145   \n",
       "6565  1.055635  1.047915  0.989870  ...  3.374324  5.820106  3.470630   \n",
       "6566  0.927424  0.942287  0.812715  ...  3.286019  5.821257  3.035974   \n",
       "\n",
       "       l4_adj8   l4_adj9  l4_adj10  l4_adj11  l4_adj12    l4_euc    l4_rss  \n",
       "0     1.429693  2.379176  2.900677  2.177376  1.711222  1.581755  0.514346  \n",
       "1     1.529019  2.439519  2.971721  2.243851  1.673655  1.701424  0.472633  \n",
       "2     1.655584  2.537666  3.056356  2.314811  1.652796  1.740957  0.570579  \n",
       "3     1.501696  2.350605  3.039381  2.209710  1.695750  1.661805  0.603008  \n",
       "4     1.330560  2.080632  2.943398  2.176994  1.660822  1.575143  0.435911  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6562  3.233487  4.721437  3.916543  5.886878  4.088313  6.122421  3.924364  \n",
       "6563  3.410025  5.080214  4.169576  6.019021  3.874508  6.068462  3.071311  \n",
       "6564  3.469200  4.786500  3.846884  5.735223  3.777857  6.277089  3.256937  \n",
       "6565  3.189984  4.881475  3.785914  5.302870  3.445231  5.274994  3.496227  \n",
       "6566  2.876209  4.537331  3.686244  5.232478  2.725681  4.490210  3.523084  \n",
       "\n",
       "[6567 rows x 420 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data seperation for leave-one-session-out\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "sessions = df_sess_tot['session']\n",
    "y = df_sess_tot['GT']\n",
    "\n",
    "df_sess_tot2 = df_sess_tot.drop('session', axis = 1)\n",
    "df_sess_tot2 = df_sess_tot2.drop('GT', axis = 1)\n",
    "\n",
    "X = df_sess_tot2.copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataframe to numpy\n",
    "\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(X, y, groups = sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping setting\n",
    "early_stopping =  EarlyStopping(\n",
    "                            monitor='val_mae',\n",
    "                            min_delta=0,\n",
    "                            patience=100,\n",
    "                            verbose=1,\n",
    "                            mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:34:01.690627\n",
      "Epoch 1/10000\n",
      "40/40 [==============================] - 1s 9ms/step - loss: 4.7537 - mae: 1.3767 - val_loss: 0.8628 - val_mae: 0.6939\n",
      "Epoch 2/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.5758 - mae: 0.5555 - val_loss: 0.5697 - val_mae: 0.5512\n",
      "Epoch 3/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3983 - mae: 0.4678 - val_loss: 0.4983 - val_mae: 0.5212\n",
      "Epoch 4/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3275 - mae: 0.4200 - val_loss: 0.4810 - val_mae: 0.4944\n",
      "Epoch 5/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2724 - mae: 0.3838 - val_loss: 0.4354 - val_mae: 0.4787\n",
      "Epoch 6/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2333 - mae: 0.3538 - val_loss: 0.3638 - val_mae: 0.4411\n",
      "Epoch 7/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1962 - mae: 0.3252 - val_loss: 0.3491 - val_mae: 0.4309\n",
      "Epoch 8/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1756 - mae: 0.3042 - val_loss: 0.3429 - val_mae: 0.4186\n",
      "Epoch 9/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1775 - mae: 0.3044 - val_loss: 0.3035 - val_mae: 0.3964\n",
      "Epoch 10/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1445 - mae: 0.2819 - val_loss: 0.4058 - val_mae: 0.4661\n",
      "Epoch 11/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1273 - mae: 0.2636 - val_loss: 0.2983 - val_mae: 0.3951\n",
      "Epoch 12/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1331 - mae: 0.2679 - val_loss: 0.2699 - val_mae: 0.3822\n",
      "Epoch 13/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1350 - mae: 0.2627 - val_loss: 0.3410 - val_mae: 0.4314\n",
      "Epoch 14/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1101 - mae: 0.2429 - val_loss: 0.2476 - val_mae: 0.3649\n",
      "Epoch 15/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0874 - mae: 0.2141 - val_loss: 0.2556 - val_mae: 0.3783\n",
      "Epoch 16/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0941 - mae: 0.2257 - val_loss: 0.3009 - val_mae: 0.4120\n",
      "Epoch 17/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0988 - mae: 0.2366 - val_loss: 0.2538 - val_mae: 0.3738\n",
      "Epoch 18/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0627 - mae: 0.1849 - val_loss: 0.2586 - val_mae: 0.3668\n",
      "Epoch 19/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0698 - mae: 0.1933 - val_loss: 0.2712 - val_mae: 0.3827\n",
      "Epoch 20/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0706 - mae: 0.1952 - val_loss: 0.2383 - val_mae: 0.3566\n",
      "Epoch 21/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0684 - mae: 0.1907 - val_loss: 0.2474 - val_mae: 0.3658\n",
      "Epoch 22/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0559 - mae: 0.1733 - val_loss: 0.2126 - val_mae: 0.3363\n",
      "Epoch 23/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0474 - mae: 0.1619 - val_loss: 0.2271 - val_mae: 0.3461\n",
      "Epoch 24/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0475 - mae: 0.1628 - val_loss: 0.2354 - val_mae: 0.3553\n",
      "Epoch 25/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0392 - mae: 0.1458 - val_loss: 0.2084 - val_mae: 0.3294\n",
      "Epoch 26/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0479 - mae: 0.1589 - val_loss: 0.2151 - val_mae: 0.3364\n",
      "Epoch 27/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0357 - mae: 0.1395 - val_loss: 0.2106 - val_mae: 0.3317\n",
      "Epoch 28/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0308 - mae: 0.1289 - val_loss: 0.2107 - val_mae: 0.3321\n",
      "Epoch 29/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0272 - mae: 0.1202 - val_loss: 0.2056 - val_mae: 0.3258\n",
      "Epoch 30/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0232 - mae: 0.1127 - val_loss: 0.2142 - val_mae: 0.3340\n",
      "Epoch 31/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0223 - mae: 0.1097 - val_loss: 0.2086 - val_mae: 0.3267\n",
      "Epoch 32/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0258 - mae: 0.1153 - val_loss: 0.2389 - val_mae: 0.3552\n",
      "Epoch 33/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0704 - mae: 0.1919 - val_loss: 0.2745 - val_mae: 0.3788\n",
      "Epoch 34/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0614 - mae: 0.1772 - val_loss: 0.2284 - val_mae: 0.3451\n",
      "Epoch 35/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0549 - mae: 0.1701 - val_loss: 0.2103 - val_mae: 0.3299\n",
      "Epoch 36/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0372 - mae: 0.1406 - val_loss: 0.2014 - val_mae: 0.3236\n",
      "Epoch 37/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0206 - mae: 0.1051 - val_loss: 0.2045 - val_mae: 0.3239\n",
      "Epoch 38/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0946 - val_loss: 0.2250 - val_mae: 0.3444\n",
      "Epoch 39/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0206 - mae: 0.1042 - val_loss: 0.2092 - val_mae: 0.3300\n",
      "Epoch 40/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0350 - mae: 0.1353 - val_loss: 0.2313 - val_mae: 0.3502\n",
      "Epoch 41/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0393 - mae: 0.1446 - val_loss: 0.2556 - val_mae: 0.3756\n",
      "Epoch 42/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0307 - mae: 0.1288 - val_loss: 0.2048 - val_mae: 0.3265\n",
      "Epoch 43/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0265 - mae: 0.1196 - val_loss: 0.2096 - val_mae: 0.3333\n",
      "Epoch 44/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.1190 - val_loss: 0.2047 - val_mae: 0.3248\n",
      "Epoch 45/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.1083 - val_loss: 0.2012 - val_mae: 0.3187\n",
      "Epoch 46/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0308 - mae: 0.1288 - val_loss: 0.2540 - val_mae: 0.3685\n",
      "Epoch 47/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0495 - mae: 0.1637 - val_loss: 0.2233 - val_mae: 0.3467\n",
      "Epoch 48/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0472 - mae: 0.1583 - val_loss: 0.2402 - val_mae: 0.3560\n",
      "Epoch 49/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0394 - mae: 0.1446 - val_loss: 0.2039 - val_mae: 0.3320\n",
      "Epoch 50/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0305 - mae: 0.1277 - val_loss: 0.2239 - val_mae: 0.3376\n",
      "Epoch 51/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0489 - mae: 0.1602 - val_loss: 0.2320 - val_mae: 0.3463\n",
      "Epoch 52/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0455 - mae: 0.1544 - val_loss: 0.2157 - val_mae: 0.3367\n",
      "Epoch 53/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0321 - mae: 0.1309 - val_loss: 0.2017 - val_mae: 0.3273\n",
      "Epoch 54/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0235 - mae: 0.1112 - val_loss: 0.1901 - val_mae: 0.3161\n",
      "Epoch 55/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0276 - mae: 0.1221 - val_loss: 0.2120 - val_mae: 0.3393\n",
      "Epoch 56/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0239 - mae: 0.1142 - val_loss: 0.1985 - val_mae: 0.3156\n",
      "Epoch 57/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.1165 - val_loss: 0.2031 - val_mae: 0.3244\n",
      "Epoch 58/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0279 - mae: 0.1221 - val_loss: 0.2020 - val_mae: 0.3229\n",
      "Epoch 59/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.1061 - val_loss: 0.1929 - val_mae: 0.3150\n",
      "Epoch 60/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0856 - val_loss: 0.1901 - val_mae: 0.3128\n",
      "Epoch 61/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.0844 - val_loss: 0.1932 - val_mae: 0.3127\n",
      "Epoch 62/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0877 - val_loss: 0.1907 - val_mae: 0.3168\n",
      "Epoch 63/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0823 - val_loss: 0.1920 - val_mae: 0.3140\n",
      "Epoch 64/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0937 - val_loss: 0.2003 - val_mae: 0.3209\n",
      "Epoch 65/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0970 - val_loss: 0.1952 - val_mae: 0.3165\n",
      "Epoch 66/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0205 - mae: 0.1040 - val_loss: 0.2039 - val_mae: 0.3267\n",
      "Epoch 67/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0201 - mae: 0.1032 - val_loss: 0.1978 - val_mae: 0.3166\n",
      "Epoch 68/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0200 - mae: 0.1033 - val_loss: 0.1809 - val_mae: 0.2983\n",
      "Epoch 69/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0131 - mae: 0.0861 - val_loss: 0.1947 - val_mae: 0.3121\n",
      "Epoch 70/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.0840 - val_loss: 0.1968 - val_mae: 0.3131\n",
      "Epoch 71/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.0997 - val_loss: 0.1902 - val_mae: 0.3144\n",
      "Epoch 72/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0205 - mae: 0.1047 - val_loss: 0.1950 - val_mae: 0.3107\n",
      "Epoch 73/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0241 - mae: 0.1130 - val_loss: 0.1984 - val_mae: 0.3220\n",
      "Epoch 74/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0320 - mae: 0.1302 - val_loss: 0.2430 - val_mae: 0.3649\n",
      "Epoch 75/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0576 - mae: 0.1749 - val_loss: 0.2502 - val_mae: 0.3620\n",
      "Epoch 76/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0735 - mae: 0.1975 - val_loss: 0.2132 - val_mae: 0.3322\n",
      "Epoch 77/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0485 - mae: 0.1591 - val_loss: 0.2027 - val_mae: 0.3221\n",
      "Epoch 78/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0422 - mae: 0.1471 - val_loss: 0.2588 - val_mae: 0.3692\n",
      "Epoch 79/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0531 - mae: 0.1660 - val_loss: 0.2165 - val_mae: 0.3385\n",
      "Epoch 80/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0402 - mae: 0.1466 - val_loss: 0.2016 - val_mae: 0.3218\n",
      "Epoch 81/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.1034 - val_loss: 0.2034 - val_mae: 0.3237\n",
      "Epoch 82/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0231 - mae: 0.1098 - val_loss: 0.2276 - val_mae: 0.3416\n",
      "Epoch 83/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0397 - mae: 0.1414 - val_loss: 0.2102 - val_mae: 0.3260\n",
      "Epoch 84/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0290 - mae: 0.1231 - val_loss: 0.2045 - val_mae: 0.3291\n",
      "Epoch 85/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0207 - mae: 0.1040 - val_loss: 0.1913 - val_mae: 0.3113\n",
      "Epoch 86/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0158 - mae: 0.0925 - val_loss: 0.1910 - val_mae: 0.3107\n",
      "Epoch 87/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0805 - val_loss: 0.1864 - val_mae: 0.3063\n",
      "Epoch 88/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0151 - mae: 0.0880 - val_loss: 0.2094 - val_mae: 0.3286\n",
      "Epoch 89/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0882 - val_loss: 0.1868 - val_mae: 0.3063\n",
      "Epoch 90/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.0905 - val_loss: 0.2029 - val_mae: 0.3173\n",
      "Epoch 91/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0134 - mae: 0.0848 - val_loss: 0.2000 - val_mae: 0.3180\n",
      "Epoch 92/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0883 - val_loss: 0.1839 - val_mae: 0.3045\n",
      "Epoch 93/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0723 - val_loss: 0.1873 - val_mae: 0.3054\n",
      "Epoch 94/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0744 - val_loss: 0.1946 - val_mae: 0.3090\n",
      "Epoch 95/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0150 - mae: 0.0880 - val_loss: 0.1975 - val_mae: 0.3188\n",
      "Epoch 96/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0816 - val_loss: 0.1960 - val_mae: 0.3146\n",
      "Epoch 97/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0770 - val_loss: 0.1834 - val_mae: 0.3045\n",
      "Epoch 98/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0874 - val_loss: 0.2115 - val_mae: 0.3262\n",
      "Epoch 99/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0592 - mae: 0.1768 - val_loss: 0.2955 - val_mae: 0.3862\n",
      "Epoch 100/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1268 - mae: 0.2576 - val_loss: 0.3025 - val_mae: 0.3945\n",
      "Epoch 101/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0829 - mae: 0.2077 - val_loss: 0.2183 - val_mae: 0.3455\n",
      "Epoch 102/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0451 - mae: 0.1570 - val_loss: 0.2281 - val_mae: 0.3409\n",
      "Epoch 103/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0436 - mae: 0.1502 - val_loss: 0.2095 - val_mae: 0.3222\n",
      "Epoch 104/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0294 - mae: 0.1246 - val_loss: 0.2139 - val_mae: 0.3271\n",
      "Epoch 105/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0281 - mae: 0.1245 - val_loss: 0.1992 - val_mae: 0.3207\n",
      "Epoch 106/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0449 - mae: 0.1538 - val_loss: 0.2029 - val_mae: 0.3260\n",
      "Epoch 107/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0194 - mae: 0.1029 - val_loss: 0.1866 - val_mae: 0.3062\n",
      "Epoch 108/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0918 - val_loss: 0.1864 - val_mae: 0.3088\n",
      "Epoch 109/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0752 - val_loss: 0.1796 - val_mae: 0.2976\n",
      "Epoch 110/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0597 - val_loss: 0.1805 - val_mae: 0.3002\n",
      "Epoch 111/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0478 - val_loss: 0.1756 - val_mae: 0.2957\n",
      "Epoch 112/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0469 - val_loss: 0.1801 - val_mae: 0.3029\n",
      "Epoch 113/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0497 - val_loss: 0.1780 - val_mae: 0.2970\n",
      "Epoch 114/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0545 - val_loss: 0.1789 - val_mae: 0.2968\n",
      "Epoch 115/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0599 - val_loss: 0.1888 - val_mae: 0.3048\n",
      "Epoch 116/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0695 - val_loss: 0.1965 - val_mae: 0.3137\n",
      "Epoch 117/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0637 - val_loss: 0.1847 - val_mae: 0.3039\n",
      "Epoch 118/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0705 - val_loss: 0.1902 - val_mae: 0.3089\n",
      "Epoch 119/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0723 - val_loss: 0.2035 - val_mae: 0.3205\n",
      "Epoch 120/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0771 - val_loss: 0.1925 - val_mae: 0.3165\n",
      "Epoch 121/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0694 - val_loss: 0.1878 - val_mae: 0.3057\n",
      "Epoch 122/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0595 - val_loss: 0.1861 - val_mae: 0.3053\n",
      "Epoch 123/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0584 - val_loss: 0.1884 - val_mae: 0.3052\n",
      "Epoch 124/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0720 - val_loss: 0.1954 - val_mae: 0.3112\n",
      "Epoch 125/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0162 - mae: 0.0910 - val_loss: 0.2048 - val_mae: 0.3191\n",
      "Epoch 126/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0191 - mae: 0.1019 - val_loss: 0.1865 - val_mae: 0.3040\n",
      "Epoch 127/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.1034 - val_loss: 0.1862 - val_mae: 0.3125\n",
      "Epoch 128/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0994 - val_loss: 0.1931 - val_mae: 0.3075\n",
      "Epoch 129/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0235 - mae: 0.1097 - val_loss: 0.2004 - val_mae: 0.3162\n",
      "Epoch 130/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 0.1047 - val_loss: 0.1973 - val_mae: 0.3095\n",
      "Epoch 131/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0419 - mae: 0.1469 - val_loss: 0.1880 - val_mae: 0.3016\n",
      "Epoch 132/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0393 - mae: 0.1422 - val_loss: 0.2221 - val_mae: 0.3331\n",
      "Epoch 133/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0426 - mae: 0.1473 - val_loss: 0.2326 - val_mae: 0.3476\n",
      "Epoch 134/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0351 - mae: 0.1388 - val_loss: 0.2178 - val_mae: 0.3360\n",
      "Epoch 135/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0213 - mae: 0.1056 - val_loss: 0.2025 - val_mae: 0.3177\n",
      "Epoch 136/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0161 - mae: 0.0914 - val_loss: 0.1842 - val_mae: 0.3034\n",
      "Epoch 137/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0725 - val_loss: 0.1885 - val_mae: 0.3101\n",
      "Epoch 138/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0663 - val_loss: 0.1840 - val_mae: 0.3041\n",
      "Epoch 139/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0612 - val_loss: 0.1805 - val_mae: 0.3009\n",
      "Epoch 140/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0706 - val_loss: 0.1832 - val_mae: 0.3034\n",
      "Epoch 141/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0654 - val_loss: 0.1830 - val_mae: 0.3016\n",
      "Epoch 142/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0679 - val_loss: 0.1957 - val_mae: 0.3069\n",
      "Epoch 143/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0205 - mae: 0.1038 - val_loss: 0.2116 - val_mae: 0.3281\n",
      "Epoch 144/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0355 - mae: 0.1348 - val_loss: 0.1944 - val_mae: 0.3165\n",
      "Epoch 145/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0428 - mae: 0.1488 - val_loss: 0.2030 - val_mae: 0.3229\n",
      "Epoch 146/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0238 - mae: 0.1121 - val_loss: 0.1946 - val_mae: 0.3037\n",
      "Epoch 147/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.1044 - val_loss: 0.1970 - val_mae: 0.3182\n",
      "Epoch 148/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0813 - val_loss: 0.1912 - val_mae: 0.3132\n",
      "Epoch 149/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0157 - mae: 0.0921 - val_loss: 0.1951 - val_mae: 0.3163\n",
      "Epoch 150/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0893 - val_loss: 0.1973 - val_mae: 0.3158\n",
      "Epoch 151/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.0756 - val_loss: 0.1864 - val_mae: 0.3066\n",
      "Epoch 152/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0946 - val_loss: 0.1961 - val_mae: 0.3086\n",
      "Epoch 153/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0906 - val_loss: 0.1833 - val_mae: 0.3009\n",
      "Epoch 154/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0715 - val_loss: 0.1837 - val_mae: 0.3030\n",
      "Epoch 155/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0157 - mae: 0.0910 - val_loss: 0.1899 - val_mae: 0.3078\n",
      "Epoch 156/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.0763 - val_loss: 0.1877 - val_mae: 0.3027\n",
      "Epoch 157/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0571 - val_loss: 0.1836 - val_mae: 0.3003\n",
      "Epoch 158/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0657 - val_loss: 0.1800 - val_mae: 0.3006\n",
      "Epoch 159/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0591 - val_loss: 0.1793 - val_mae: 0.2972\n",
      "Epoch 160/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0587 - val_loss: 0.1826 - val_mae: 0.2976\n",
      "Epoch 161/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0691 - val_loss: 0.2033 - val_mae: 0.3171\n",
      "Epoch 162/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0191 - mae: 0.0996 - val_loss: 0.1898 - val_mae: 0.3013\n",
      "Epoch 163/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0733 - val_loss: 0.1906 - val_mae: 0.3061\n",
      "Epoch 164/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0736 - val_loss: 0.1767 - val_mae: 0.2946\n",
      "Epoch 165/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0880 - val_loss: 0.1933 - val_mae: 0.3107\n",
      "Epoch 166/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0191 - mae: 0.0984 - val_loss: 0.1912 - val_mae: 0.3120\n",
      "Epoch 167/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0364 - mae: 0.1355 - val_loss: 0.2120 - val_mae: 0.3163\n",
      "Epoch 168/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0468 - mae: 0.1509 - val_loss: 0.2108 - val_mae: 0.3227\n",
      "Epoch 169/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0266 - mae: 0.1195 - val_loss: 0.1966 - val_mae: 0.3127\n",
      "Epoch 170/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1071 - val_loss: 0.2025 - val_mae: 0.3235\n",
      "Epoch 171/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0986 - val_loss: 0.2018 - val_mae: 0.3113\n",
      "Epoch 172/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.1070 - val_loss: 0.1876 - val_mae: 0.2985\n",
      "Epoch 173/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0930 - val_loss: 0.1902 - val_mae: 0.3065\n",
      "Epoch 174/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.0863 - val_loss: 0.1814 - val_mae: 0.3003\n",
      "Epoch 175/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0646 - val_loss: 0.1777 - val_mae: 0.2981\n",
      "Epoch 176/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0655 - val_loss: 0.1831 - val_mae: 0.3003\n",
      "Epoch 177/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0749 - val_loss: 0.2079 - val_mae: 0.3202\n",
      "Epoch 178/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0205 - mae: 0.1031 - val_loss: 0.1963 - val_mae: 0.3102\n",
      "Epoch 179/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0162 - mae: 0.0927 - val_loss: 0.1931 - val_mae: 0.3152\n",
      "Epoch 180/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0738 - val_loss: 0.2030 - val_mae: 0.3139\n",
      "Epoch 181/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.0985 - val_loss: 0.1913 - val_mae: 0.3073\n",
      "Epoch 182/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.1001 - val_loss: 0.1916 - val_mae: 0.3102\n",
      "Epoch 183/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0808 - val_loss: 0.1989 - val_mae: 0.3145\n",
      "Epoch 184/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0737 - val_loss: 0.1839 - val_mae: 0.3018\n",
      "Epoch 185/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0589 - val_loss: 0.1892 - val_mae: 0.3093\n",
      "Epoch 186/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0660 - val_loss: 0.1860 - val_mae: 0.3037\n",
      "Epoch 187/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0660 - val_loss: 0.1821 - val_mae: 0.2982\n",
      "Epoch 188/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0593 - val_loss: 0.1839 - val_mae: 0.3021\n",
      "Epoch 189/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0596 - val_loss: 0.1777 - val_mae: 0.2945\n",
      "Epoch 190/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0576 - val_loss: 0.1814 - val_mae: 0.2977\n",
      "Epoch 191/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0602 - val_loss: 0.1785 - val_mae: 0.2957\n",
      "Epoch 192/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0508 - val_loss: 0.1782 - val_mae: 0.2940\n",
      "Epoch 193/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0551 - val_loss: 0.1866 - val_mae: 0.3024\n",
      "Epoch 194/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0630 - val_loss: 0.1767 - val_mae: 0.2917\n",
      "Epoch 195/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0561 - val_loss: 0.1792 - val_mae: 0.2941\n",
      "Epoch 196/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.0744 - val_loss: 0.1857 - val_mae: 0.3021\n",
      "Epoch 197/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0414 - mae: 0.1429 - val_loss: 0.2058 - val_mae: 0.3233\n",
      "Epoch 198/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0573 - mae: 0.1701 - val_loss: 0.2553 - val_mae: 0.3634\n",
      "Epoch 199/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0304 - mae: 0.1270 - val_loss: 0.2153 - val_mae: 0.3280\n",
      "Epoch 200/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0986 - val_loss: 0.1824 - val_mae: 0.3029\n",
      "Epoch 201/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.1024 - val_loss: 0.1923 - val_mae: 0.3125\n",
      "Epoch 202/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0179 - mae: 0.0959 - val_loss: 0.1835 - val_mae: 0.3030\n",
      "Epoch 203/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0713 - val_loss: 0.1772 - val_mae: 0.2994\n",
      "Epoch 204/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0577 - val_loss: 0.1799 - val_mae: 0.3010\n",
      "Epoch 205/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0616 - val_loss: 0.1806 - val_mae: 0.2970\n",
      "Epoch 206/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0783 - val_loss: 0.1811 - val_mae: 0.2996\n",
      "Epoch 207/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0631 - val_loss: 0.1775 - val_mae: 0.2944\n",
      "Epoch 208/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0678 - val_loss: 0.1890 - val_mae: 0.2999\n",
      "Epoch 209/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0574 - val_loss: 0.1804 - val_mae: 0.2964\n",
      "Epoch 210/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0569 - val_loss: 0.1802 - val_mae: 0.2967\n",
      "Epoch 211/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0519 - val_loss: 0.1859 - val_mae: 0.3027\n",
      "Epoch 212/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0681 - val_loss: 0.1772 - val_mae: 0.2923\n",
      "Epoch 213/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0857 - val_loss: 0.1846 - val_mae: 0.3036\n",
      "Epoch 214/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0774 - val_loss: 0.2126 - val_mae: 0.3220\n",
      "Epoch 215/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0800 - val_loss: 0.1806 - val_mae: 0.2966\n",
      "Epoch 216/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0655 - val_loss: 0.1800 - val_mae: 0.2992\n",
      "Epoch 217/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0772 - val_loss: 0.1975 - val_mae: 0.3128\n",
      "Epoch 218/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0860 - val_loss: 0.1861 - val_mae: 0.3042\n",
      "Epoch 219/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0850 - val_loss: 0.1847 - val_mae: 0.3013\n",
      "Epoch 220/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0754 - val_loss: 0.1855 - val_mae: 0.2997\n",
      "Epoch 221/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0217 - mae: 0.1024 - val_loss: 0.2160 - val_mae: 0.3224\n",
      "Epoch 222/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.0957 - val_loss: 0.1881 - val_mae: 0.3032\n",
      "Epoch 223/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0830 - val_loss: 0.1793 - val_mae: 0.2906\n",
      "Epoch 224/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0726 - val_loss: 0.1797 - val_mae: 0.2970\n",
      "Epoch 225/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0731 - val_loss: 0.1850 - val_mae: 0.3001\n",
      "Epoch 226/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0723 - val_loss: 0.1850 - val_mae: 0.3000\n",
      "Epoch 227/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0636 - val_loss: 0.1799 - val_mae: 0.2932\n",
      "Epoch 228/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0519 - val_loss: 0.1800 - val_mae: 0.2958\n",
      "Epoch 229/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0475 - val_loss: 0.1776 - val_mae: 0.2943\n",
      "Epoch 230/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0513 - val_loss: 0.1808 - val_mae: 0.2958\n",
      "Epoch 231/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0529 - val_loss: 0.1821 - val_mae: 0.2979\n",
      "Epoch 232/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0585 - val_loss: 0.1823 - val_mae: 0.2995\n",
      "Epoch 233/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0514 - val_loss: 0.1785 - val_mae: 0.2937\n",
      "Epoch 234/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0604 - val_loss: 0.1800 - val_mae: 0.3005\n",
      "Epoch 235/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0645 - val_loss: 0.1892 - val_mae: 0.3050\n",
      "Epoch 236/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0577 - val_loss: 0.1797 - val_mae: 0.2952\n",
      "Epoch 237/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0561 - val_loss: 0.1853 - val_mae: 0.2973\n",
      "Epoch 238/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0610 - val_loss: 0.1873 - val_mae: 0.3025\n",
      "Epoch 239/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0619 - val_loss: 0.1757 - val_mae: 0.2919\n",
      "Epoch 240/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0611 - val_loss: 0.1785 - val_mae: 0.2991\n",
      "Epoch 241/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0610 - val_loss: 0.1835 - val_mae: 0.3013\n",
      "Epoch 242/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.0762 - val_loss: 0.2020 - val_mae: 0.3136\n",
      "Epoch 243/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0862 - val_loss: 0.1822 - val_mae: 0.3003\n",
      "Epoch 244/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.0742 - val_loss: 0.1876 - val_mae: 0.3011\n",
      "Epoch 245/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0773 - val_loss: 0.1846 - val_mae: 0.3028\n",
      "Epoch 246/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0706 - val_loss: 0.1722 - val_mae: 0.2890\n",
      "Epoch 247/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0711 - val_loss: 0.1961 - val_mae: 0.3088\n",
      "Epoch 248/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0306 - mae: 0.1249 - val_loss: 0.2007 - val_mae: 0.3118\n",
      "Epoch 249/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0241 - mae: 0.1116 - val_loss: 0.1988 - val_mae: 0.3108\n",
      "Epoch 250/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.1011 - val_loss: 0.1979 - val_mae: 0.3106\n",
      "Epoch 251/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.0822 - val_loss: 0.1806 - val_mae: 0.2970\n",
      "Epoch 252/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 0.0910 - val_loss: 0.2035 - val_mae: 0.3179\n",
      "Epoch 253/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.1025 - val_loss: 0.1905 - val_mae: 0.3061\n",
      "Epoch 254/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0242 - mae: 0.1142 - val_loss: 0.1954 - val_mae: 0.3075\n",
      "Epoch 255/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.0965 - val_loss: 0.1781 - val_mae: 0.2939\n",
      "Epoch 256/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0809 - val_loss: 0.1909 - val_mae: 0.3061\n",
      "Epoch 257/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0139 - mae: 0.0855 - val_loss: 0.1878 - val_mae: 0.2989\n",
      "Epoch 258/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0798 - val_loss: 0.1851 - val_mae: 0.2983\n",
      "Epoch 259/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0672 - val_loss: 0.1723 - val_mae: 0.2932\n",
      "Epoch 260/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0519 - val_loss: 0.1751 - val_mae: 0.2925\n",
      "Epoch 261/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0418 - val_loss: 0.1760 - val_mae: 0.2928\n",
      "Epoch 262/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.1743 - val_mae: 0.2930\n",
      "Epoch 263/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0343 - val_loss: 0.1762 - val_mae: 0.2959\n",
      "Epoch 264/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0334 - val_loss: 0.1741 - val_mae: 0.2908\n",
      "Epoch 265/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0328 - val_loss: 0.1753 - val_mae: 0.2925\n",
      "Epoch 266/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.1770 - val_mae: 0.2941\n",
      "Epoch 267/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.1724 - val_mae: 0.2906\n",
      "Epoch 268/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.1733 - val_mae: 0.2901\n",
      "Epoch 269/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.1731 - val_mae: 0.2908\n",
      "Epoch 270/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.1752 - val_mae: 0.2952\n",
      "Epoch 271/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0511 - val_loss: 0.1769 - val_mae: 0.2938\n",
      "Epoch 272/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0699 - val_loss: 0.1826 - val_mae: 0.2984\n",
      "Epoch 273/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.0778 - val_loss: 0.1860 - val_mae: 0.3048\n",
      "Epoch 274/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0733 - val_loss: 0.1866 - val_mae: 0.3019\n",
      "Epoch 275/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0907 - val_loss: 0.1879 - val_mae: 0.3059\n",
      "Epoch 276/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0208 - mae: 0.1038 - val_loss: 0.1822 - val_mae: 0.3016\n",
      "Epoch 277/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0907 - val_loss: 0.1834 - val_mae: 0.2949\n",
      "Epoch 278/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0792 - val_loss: 0.1830 - val_mae: 0.2963\n",
      "Epoch 279/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0738 - val_loss: 0.1886 - val_mae: 0.3045\n",
      "Epoch 280/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.0709 - val_loss: 0.1854 - val_mae: 0.3008\n",
      "Epoch 281/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0582 - val_loss: 0.1828 - val_mae: 0.2989\n",
      "Epoch 282/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0582 - val_loss: 0.1791 - val_mae: 0.2940\n",
      "Epoch 283/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0584 - val_loss: 0.1723 - val_mae: 0.2925\n",
      "Epoch 284/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0574 - val_loss: 0.1845 - val_mae: 0.3031\n",
      "Epoch 285/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0589 - val_loss: 0.1806 - val_mae: 0.2967\n",
      "Epoch 286/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0531 - val_loss: 0.1826 - val_mae: 0.2980\n",
      "Epoch 287/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0478 - val_loss: 0.1850 - val_mae: 0.3012\n",
      "Epoch 288/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0628 - val_loss: 0.1993 - val_mae: 0.3102\n",
      "Epoch 289/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0742 - val_loss: 0.1806 - val_mae: 0.2946\n",
      "Epoch 290/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0147 - mae: 0.0855 - val_loss: 0.1891 - val_mae: 0.3037\n",
      "Epoch 291/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0665 - val_loss: 0.1861 - val_mae: 0.2991\n",
      "Epoch 292/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0638 - val_loss: 0.1835 - val_mae: 0.3010\n",
      "Epoch 293/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0776 - val_loss: 0.1811 - val_mae: 0.2993\n",
      "Epoch 294/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0116 - mae: 0.0769 - val_loss: 0.1733 - val_mae: 0.2947\n",
      "Epoch 295/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0604 - val_loss: 0.1777 - val_mae: 0.2993\n",
      "Epoch 296/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0775 - val_loss: 0.1835 - val_mae: 0.3016\n",
      "Epoch 297/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0694 - val_loss: 0.1873 - val_mae: 0.3034\n",
      "Epoch 298/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0849 - val_loss: 0.1821 - val_mae: 0.3002\n",
      "Epoch 299/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0679 - val_loss: 0.1804 - val_mae: 0.2965\n",
      "Epoch 300/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0652 - val_loss: 0.1835 - val_mae: 0.3011\n",
      "Epoch 301/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0568 - val_loss: 0.1770 - val_mae: 0.2961\n",
      "Epoch 302/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0686 - val_loss: 0.1952 - val_mae: 0.3049\n",
      "Epoch 303/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.1005 - val_loss: 0.2057 - val_mae: 0.3132\n",
      "Epoch 304/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0216 - mae: 0.1038 - val_loss: 0.1740 - val_mae: 0.2906\n",
      "Epoch 305/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0728 - val_loss: 0.1874 - val_mae: 0.3018\n",
      "Epoch 306/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0595 - val_loss: 0.1743 - val_mae: 0.2905\n",
      "Epoch 307/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0520 - val_loss: 0.1738 - val_mae: 0.2925\n",
      "Epoch 308/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0582 - val_loss: 0.1839 - val_mae: 0.2982\n",
      "Epoch 309/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0646 - val_loss: 0.1833 - val_mae: 0.2937\n",
      "Epoch 310/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0639 - val_loss: 0.2081 - val_mae: 0.3177\n",
      "Epoch 311/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0722 - val_loss: 0.1814 - val_mae: 0.2961\n",
      "Epoch 312/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0745 - val_loss: 0.1842 - val_mae: 0.3013\n",
      "Epoch 313/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0815 - val_loss: 0.1889 - val_mae: 0.3037\n",
      "Epoch 314/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0967 - mae: 0.1765 - val_loss: 0.8238 - val_mae: 0.6723\n",
      "Epoch 315/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2256 - mae: 0.3358 - val_loss: 0.2175 - val_mae: 0.3337\n",
      "Epoch 316/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0487 - mae: 0.1604 - val_loss: 0.1927 - val_mae: 0.3142\n",
      "Epoch 317/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0885 - val_loss: 0.1826 - val_mae: 0.3028\n",
      "Epoch 318/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0662 - val_loss: 0.1855 - val_mae: 0.3064\n",
      "Epoch 319/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0536 - val_loss: 0.1796 - val_mae: 0.3013\n",
      "Epoch 320/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0450 - val_loss: 0.1800 - val_mae: 0.2997\n",
      "Epoch 321/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0429 - val_loss: 0.1799 - val_mae: 0.3017\n",
      "Epoch 322/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0356 - val_loss: 0.1790 - val_mae: 0.2982\n",
      "Epoch 323/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0016 - mae: 0.0315 - val_loss: 0.1777 - val_mae: 0.2971\n",
      "Epoch 324/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0301 - val_loss: 0.1790 - val_mae: 0.2984\n",
      "Epoch 325/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.1784 - val_mae: 0.2966\n",
      "Epoch 326/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.1810 - val_mae: 0.2987\n",
      "Epoch 327/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0011 - mae: 0.0262 - val_loss: 0.1785 - val_mae: 0.2959\n",
      "Epoch 328/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 9.2591e-04 - mae: 0.0235 - val_loss: 0.1791 - val_mae: 0.2974\n",
      "Epoch 329/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 8.6581e-04 - mae: 0.0230 - val_loss: 0.1794 - val_mae: 0.2973\n",
      "Epoch 330/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 7.0264e-04 - mae: 0.0205 - val_loss: 0.1780 - val_mae: 0.2962\n",
      "Epoch 331/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 5.5967e-04 - mae: 0.0180 - val_loss: 0.1788 - val_mae: 0.2957\n",
      "Epoch 332/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 4.7838e-04 - mae: 0.0165 - val_loss: 0.1780 - val_mae: 0.2959\n",
      "Epoch 333/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 4.5738e-04 - mae: 0.0159 - val_loss: 0.1782 - val_mae: 0.2955\n",
      "Epoch 334/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 4.2741e-04 - mae: 0.0154 - val_loss: 0.1773 - val_mae: 0.2952\n",
      "Epoch 335/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 3.7881e-04 - mae: 0.0145 - val_loss: 0.1777 - val_mae: 0.2944\n",
      "Epoch 336/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 5.6840e-04 - mae: 0.0181 - val_loss: 0.1786 - val_mae: 0.2955\n",
      "Epoch 337/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 6.7091e-04 - mae: 0.0199 - val_loss: 0.1785 - val_mae: 0.2957\n",
      "Epoch 338/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 6.9225e-04 - mae: 0.0201 - val_loss: 0.1765 - val_mae: 0.2929\n",
      "Epoch 339/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 6.9154e-04 - mae: 0.0200 - val_loss: 0.1780 - val_mae: 0.2943\n",
      "Epoch 340/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 7.8044e-04 - mae: 0.0208 - val_loss: 0.1782 - val_mae: 0.2952\n",
      "Epoch 341/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 9.6261e-04 - mae: 0.0232 - val_loss: 0.1790 - val_mae: 0.2959\n",
      "Epoch 342/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 9.9384e-04 - mae: 0.0232 - val_loss: 0.1774 - val_mae: 0.2950\n",
      "Epoch 343/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.1788 - val_mae: 0.2953\n",
      "Epoch 344/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0012 - mae: 0.0256 - val_loss: 0.1809 - val_mae: 0.2962\n",
      "Epoch 345/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.1778 - val_mae: 0.2930\n",
      "Epoch 346/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0357 - val_loss: 0.1800 - val_mae: 0.3002\n",
      "Epoch 00346: early stopping\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "40/40 [==============================] - 1s 7ms/step - loss: 3.1915 - mae: 1.1335 - val_loss: 0.5806 - val_mae: 0.5515\n",
      "Epoch 2/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.4665 - mae: 0.4973 - val_loss: 0.4453 - val_mae: 0.4873\n",
      "Epoch 3/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3153 - mae: 0.4068 - val_loss: 0.3273 - val_mae: 0.4311\n",
      "Epoch 4/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2451 - mae: 0.3617 - val_loss: 0.3090 - val_mae: 0.4113\n",
      "Epoch 5/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2138 - mae: 0.3407 - val_loss: 0.3407 - val_mae: 0.4290\n",
      "Epoch 6/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1857 - mae: 0.3145 - val_loss: 0.2570 - val_mae: 0.3721\n",
      "Epoch 7/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1566 - mae: 0.2859 - val_loss: 0.2491 - val_mae: 0.3627\n",
      "Epoch 8/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1262 - mae: 0.2616 - val_loss: 0.2155 - val_mae: 0.3404\n",
      "Epoch 9/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1289 - mae: 0.2637 - val_loss: 0.2275 - val_mae: 0.3467\n",
      "Epoch 10/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1010 - mae: 0.2307 - val_loss: 0.2518 - val_mae: 0.3630\n",
      "Epoch 11/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0952 - mae: 0.2246 - val_loss: 0.2593 - val_mae: 0.3745\n",
      "Epoch 12/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0942 - mae: 0.2277 - val_loss: 0.2293 - val_mae: 0.3496\n",
      "Epoch 13/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0920 - mae: 0.2206 - val_loss: 0.2178 - val_mae: 0.3395\n",
      "Epoch 14/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1244 - mae: 0.2535 - val_loss: 0.2430 - val_mae: 0.3595\n",
      "Epoch 15/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1092 - mae: 0.2391 - val_loss: 0.1879 - val_mae: 0.3105\n",
      "Epoch 16/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0687 - mae: 0.1893 - val_loss: 0.2082 - val_mae: 0.3253\n",
      "Epoch 17/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0555 - mae: 0.1741 - val_loss: 0.1921 - val_mae: 0.3203\n",
      "Epoch 18/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0364 - mae: 0.1388 - val_loss: 0.1811 - val_mae: 0.3078\n",
      "Epoch 19/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0519 - mae: 0.1642 - val_loss: 0.2105 - val_mae: 0.3305\n",
      "Epoch 20/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0488 - mae: 0.1603 - val_loss: 0.1954 - val_mae: 0.3113\n",
      "Epoch 21/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0386 - mae: 0.1426 - val_loss: 0.1975 - val_mae: 0.3192\n",
      "Epoch 22/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0433 - mae: 0.1519 - val_loss: 0.1819 - val_mae: 0.3197\n",
      "Epoch 23/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0315 - mae: 0.1320 - val_loss: 0.1766 - val_mae: 0.2973\n",
      "Epoch 24/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0362 - mae: 0.1365 - val_loss: 0.2016 - val_mae: 0.3266\n",
      "Epoch 25/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0686 - mae: 0.1889 - val_loss: 0.2433 - val_mae: 0.3633\n",
      "Epoch 26/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0846 - mae: 0.2128 - val_loss: 0.2645 - val_mae: 0.3673\n",
      "Epoch 27/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.1911 - val_loss: 0.1909 - val_mae: 0.3173\n",
      "Epoch 28/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0394 - mae: 0.1456 - val_loss: 0.1851 - val_mae: 0.3098\n",
      "Epoch 29/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0432 - mae: 0.1514 - val_loss: 0.1954 - val_mae: 0.3197\n",
      "Epoch 30/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0475 - mae: 0.1568 - val_loss: 0.2115 - val_mae: 0.3280\n",
      "Epoch 31/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0386 - mae: 0.1444 - val_loss: 0.1848 - val_mae: 0.3047\n",
      "Epoch 32/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0244 - mae: 0.1136 - val_loss: 0.1711 - val_mae: 0.2959\n",
      "Epoch 33/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0329 - mae: 0.1305 - val_loss: 0.2012 - val_mae: 0.3148\n",
      "Epoch 34/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0251 - mae: 0.1161 - val_loss: 0.1692 - val_mae: 0.3007\n",
      "Epoch 35/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0229 - mae: 0.1104 - val_loss: 0.1689 - val_mae: 0.2983\n",
      "Epoch 36/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 0.0964 - val_loss: 0.1642 - val_mae: 0.2876\n",
      "Epoch 37/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0240 - mae: 0.1123 - val_loss: 0.1655 - val_mae: 0.2939\n",
      "Epoch 38/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0975 - val_loss: 0.1678 - val_mae: 0.2893\n",
      "Epoch 39/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0242 - mae: 0.1122 - val_loss: 0.1718 - val_mae: 0.2972\n",
      "Epoch 40/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0443 - mae: 0.1510 - val_loss: 0.2080 - val_mae: 0.3227\n",
      "Epoch 41/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0703 - mae: 0.1876 - val_loss: 0.2157 - val_mae: 0.3372\n",
      "Epoch 42/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0763 - mae: 0.2021 - val_loss: 0.2493 - val_mae: 0.3478\n",
      "Epoch 43/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0506 - mae: 0.1611 - val_loss: 0.2046 - val_mae: 0.3274\n",
      "Epoch 44/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0469 - mae: 0.1549 - val_loss: 0.2195 - val_mae: 0.3302\n",
      "Epoch 45/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0397 - mae: 0.1446 - val_loss: 0.1845 - val_mae: 0.3094\n",
      "Epoch 46/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0338 - mae: 0.1335 - val_loss: 0.1942 - val_mae: 0.3141\n",
      "Epoch 47/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0270 - mae: 0.1200 - val_loss: 0.1889 - val_mae: 0.3064\n",
      "Epoch 48/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0212 - mae: 0.1058 - val_loss: 0.1668 - val_mae: 0.2944\n",
      "Epoch 49/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0213 - mae: 0.1056 - val_loss: 0.1860 - val_mae: 0.3045\n",
      "Epoch 50/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0261 - mae: 0.1147 - val_loss: 0.1702 - val_mae: 0.2958\n",
      "Epoch 51/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0959 - val_loss: 0.1599 - val_mae: 0.2862\n",
      "Epoch 52/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0845 - val_loss: 0.1597 - val_mae: 0.2834\n",
      "Epoch 53/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0823 - val_loss: 0.1751 - val_mae: 0.2921\n",
      "Epoch 54/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0742 - val_loss: 0.1512 - val_mae: 0.2736\n",
      "Epoch 55/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0773 - val_loss: 0.1531 - val_mae: 0.2786\n",
      "Epoch 56/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0817 - val_loss: 0.1521 - val_mae: 0.2803\n",
      "Epoch 57/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.0879 - val_loss: 0.1591 - val_mae: 0.2802\n",
      "Epoch 58/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0248 - mae: 0.1139 - val_loss: 0.1681 - val_mae: 0.2956\n",
      "Epoch 59/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0194 - mae: 0.1015 - val_loss: 0.1568 - val_mae: 0.2835\n",
      "Epoch 60/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.0989 - val_loss: 0.1769 - val_mae: 0.2894\n",
      "Epoch 61/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 0.0938 - val_loss: 0.1726 - val_mae: 0.2974\n",
      "Epoch 62/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0899 - val_loss: 0.1686 - val_mae: 0.2889\n",
      "Epoch 63/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0199 - mae: 0.1018 - val_loss: 0.1684 - val_mae: 0.2847\n",
      "Epoch 64/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0966 - val_loss: 0.1478 - val_mae: 0.2739\n",
      "Epoch 65/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0214 - mae: 0.1061 - val_loss: 0.1577 - val_mae: 0.2871\n",
      "Epoch 66/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.1002 - val_loss: 0.1605 - val_mae: 0.2853\n",
      "Epoch 67/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0277 - mae: 0.1168 - val_loss: 0.1722 - val_mae: 0.2967\n",
      "Epoch 68/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0324 - mae: 0.1264 - val_loss: 0.1560 - val_mae: 0.2875\n",
      "Epoch 69/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0458 - mae: 0.1450 - val_loss: 0.1829 - val_mae: 0.3108\n",
      "Epoch 70/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2023 - mae: 0.3143 - val_loss: 0.3190 - val_mae: 0.4038\n",
      "Epoch 71/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1172 - mae: 0.2537 - val_loss: 0.2163 - val_mae: 0.3389\n",
      "Epoch 72/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0462 - mae: 0.1565 - val_loss: 0.1611 - val_mae: 0.2837\n",
      "Epoch 73/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0256 - mae: 0.1173 - val_loss: 0.1858 - val_mae: 0.3096\n",
      "Epoch 74/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0203 - mae: 0.1060 - val_loss: 0.1764 - val_mae: 0.2925\n",
      "Epoch 75/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 0.0916 - val_loss: 0.1578 - val_mae: 0.2858\n",
      "Epoch 76/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0862 - val_loss: 0.1543 - val_mae: 0.2794\n",
      "Epoch 77/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0745 - val_loss: 0.1549 - val_mae: 0.2811\n",
      "Epoch 78/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0703 - val_loss: 0.1499 - val_mae: 0.2745\n",
      "Epoch 79/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0671 - val_loss: 0.1454 - val_mae: 0.2680\n",
      "Epoch 80/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0554 - val_loss: 0.1477 - val_mae: 0.2691\n",
      "Epoch 81/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0727 - val_loss: 0.1565 - val_mae: 0.2827\n",
      "Epoch 82/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0151 - mae: 0.0890 - val_loss: 0.1559 - val_mae: 0.2759\n",
      "Epoch 83/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0308 - mae: 0.1273 - val_loss: 0.1624 - val_mae: 0.2956\n",
      "Epoch 84/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0339 - mae: 0.1391 - val_loss: 0.2369 - val_mae: 0.3435\n",
      "Epoch 85/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0506 - mae: 0.1635 - val_loss: 0.1754 - val_mae: 0.2989\n",
      "Epoch 86/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0426 - mae: 0.1472 - val_loss: 0.1966 - val_mae: 0.3116\n",
      "Epoch 87/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0285 - mae: 0.1238 - val_loss: 0.1695 - val_mae: 0.2979\n",
      "Epoch 88/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0945 - val_loss: 0.1480 - val_mae: 0.2720\n",
      "Epoch 89/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0905 - val_loss: 0.1534 - val_mae: 0.2837\n",
      "Epoch 90/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.1080 - val_loss: 0.1904 - val_mae: 0.3147\n",
      "Epoch 91/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0451 - mae: 0.1487 - val_loss: 0.1917 - val_mae: 0.3089\n",
      "Epoch 92/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0236 - mae: 0.1101 - val_loss: 0.1521 - val_mae: 0.2745\n",
      "Epoch 93/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0881 - val_loss: 0.1537 - val_mae: 0.2746\n",
      "Epoch 94/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0793 - val_loss: 0.1516 - val_mae: 0.2707\n",
      "Epoch 95/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0826 - val_loss: 0.1476 - val_mae: 0.2666\n",
      "Epoch 96/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 0.0940 - val_loss: 0.1899 - val_mae: 0.3039\n",
      "Epoch 97/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0275 - mae: 0.1195 - val_loss: 0.1825 - val_mae: 0.2982\n",
      "Epoch 98/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 0.1041 - val_loss: 0.1578 - val_mae: 0.2795\n",
      "Epoch 99/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0120 - mae: 0.0798 - val_loss: 0.1425 - val_mae: 0.2641\n",
      "Epoch 100/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0664 - val_loss: 0.1465 - val_mae: 0.2703\n",
      "Epoch 101/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0594 - val_loss: 0.1440 - val_mae: 0.2669\n",
      "Epoch 102/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0624 - val_loss: 0.1512 - val_mae: 0.2733\n",
      "Epoch 103/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.0821 - val_loss: 0.1490 - val_mae: 0.2690\n",
      "Epoch 104/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0768 - val_loss: 0.1495 - val_mae: 0.2736\n",
      "Epoch 105/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0817 - val_loss: 0.1733 - val_mae: 0.2919\n",
      "Epoch 106/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 0.0940 - val_loss: 0.1478 - val_mae: 0.2663\n",
      "Epoch 107/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0507 - mae: 0.1544 - val_loss: 0.1926 - val_mae: 0.3094\n",
      "Epoch 108/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0482 - mae: 0.1587 - val_loss: 0.1661 - val_mae: 0.2863\n",
      "Epoch 109/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0688 - mae: 0.1867 - val_loss: 0.1875 - val_mae: 0.3082\n",
      "Epoch 110/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0438 - mae: 0.1550 - val_loss: 0.1680 - val_mae: 0.2969\n",
      "Epoch 111/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0292 - mae: 0.1211 - val_loss: 0.1537 - val_mae: 0.2737\n",
      "Epoch 112/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0912 - val_loss: 0.1467 - val_mae: 0.2727\n",
      "Epoch 113/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 0.1011 - val_loss: 0.1631 - val_mae: 0.2861\n",
      "Epoch 114/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0237 - mae: 0.1108 - val_loss: 0.1432 - val_mae: 0.2627\n",
      "Epoch 115/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0941 - val_loss: 0.1627 - val_mae: 0.2811\n",
      "Epoch 116/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0139 - mae: 0.0848 - val_loss: 0.1562 - val_mae: 0.2779\n",
      "Epoch 117/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0901 - val_loss: 0.1416 - val_mae: 0.2641\n",
      "Epoch 118/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0693 - val_loss: 0.1420 - val_mae: 0.2657\n",
      "Epoch 119/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0647 - val_loss: 0.1392 - val_mae: 0.2592\n",
      "Epoch 120/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0701 - val_loss: 0.1538 - val_mae: 0.2757\n",
      "Epoch 121/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0812 - val_loss: 0.1513 - val_mae: 0.2738\n",
      "Epoch 122/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0589 - val_loss: 0.1435 - val_mae: 0.2616\n",
      "Epoch 123/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0721 - val_loss: 0.1384 - val_mae: 0.2606\n",
      "Epoch 124/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0588 - val_loss: 0.1406 - val_mae: 0.2628\n",
      "Epoch 125/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0592 - val_loss: 0.1390 - val_mae: 0.2604\n",
      "Epoch 126/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0552 - val_loss: 0.1480 - val_mae: 0.2673\n",
      "Epoch 127/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.1462 - val_mae: 0.2645\n",
      "Epoch 128/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0474 - val_loss: 0.1442 - val_mae: 0.2586\n",
      "Epoch 129/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0542 - val_loss: 0.1465 - val_mae: 0.2628\n",
      "Epoch 130/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0554 - val_loss: 0.1408 - val_mae: 0.2578\n",
      "Epoch 131/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0593 - val_loss: 0.1545 - val_mae: 0.2706\n",
      "Epoch 132/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0868 - val_loss: 0.1647 - val_mae: 0.2874\n",
      "Epoch 133/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0168 - mae: 0.0930 - val_loss: 0.1472 - val_mae: 0.2667\n",
      "Epoch 134/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0214 - mae: 0.1041 - val_loss: 0.1638 - val_mae: 0.2853\n",
      "Epoch 135/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0250 - mae: 0.1136 - val_loss: 0.1481 - val_mae: 0.2734\n",
      "Epoch 136/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0231 - mae: 0.1093 - val_loss: 0.1690 - val_mae: 0.2836\n",
      "Epoch 137/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0304 - mae: 0.1247 - val_loss: 0.1590 - val_mae: 0.2772\n",
      "Epoch 138/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0262 - mae: 0.1147 - val_loss: 0.1653 - val_mae: 0.2844\n",
      "Epoch 139/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1310 - val_loss: 0.2381 - val_mae: 0.3434\n",
      "Epoch 140/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0543 - mae: 0.1670 - val_loss: 0.1828 - val_mae: 0.3189\n",
      "Epoch 141/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0280 - mae: 0.1229 - val_loss: 0.1827 - val_mae: 0.3114\n",
      "Epoch 142/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0294 - mae: 0.1241 - val_loss: 0.1688 - val_mae: 0.2945\n",
      "Epoch 143/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0258 - mae: 0.1152 - val_loss: 0.1711 - val_mae: 0.2851\n",
      "Epoch 144/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 0.1074 - val_loss: 0.1476 - val_mae: 0.2691\n",
      "Epoch 145/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0937 - val_loss: 0.1554 - val_mae: 0.2764\n",
      "Epoch 146/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0114 - mae: 0.0794 - val_loss: 0.1478 - val_mae: 0.2687\n",
      "Epoch 147/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0663 - val_loss: 0.1407 - val_mae: 0.2597\n",
      "Epoch 148/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0732 - val_loss: 0.1519 - val_mae: 0.2681\n",
      "Epoch 149/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0777 - val_loss: 0.1619 - val_mae: 0.2790\n",
      "Epoch 150/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0786 - val_loss: 0.1421 - val_mae: 0.2670\n",
      "Epoch 151/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0805 - val_loss: 0.1462 - val_mae: 0.2662\n",
      "Epoch 152/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0673 - val_loss: 0.1468 - val_mae: 0.2665\n",
      "Epoch 153/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0542 - val_loss: 0.1403 - val_mae: 0.2597\n",
      "Epoch 154/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0633 - val_loss: 0.1487 - val_mae: 0.2668\n",
      "Epoch 155/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0588 - val_loss: 0.1395 - val_mae: 0.2605\n",
      "Epoch 156/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0543 - val_loss: 0.1411 - val_mae: 0.2605\n",
      "Epoch 157/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0688 - val_loss: 0.1430 - val_mae: 0.2613\n",
      "Epoch 158/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0603 - val_loss: 0.1452 - val_mae: 0.2619\n",
      "Epoch 159/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0711 - val_loss: 0.1460 - val_mae: 0.2680\n",
      "Epoch 160/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0636 - val_loss: 0.1447 - val_mae: 0.2674\n",
      "Epoch 161/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0601 - val_loss: 0.1516 - val_mae: 0.2674\n",
      "Epoch 162/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0595 - val_loss: 0.1389 - val_mae: 0.2607\n",
      "Epoch 163/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0634 - val_loss: 0.1598 - val_mae: 0.2745\n",
      "Epoch 164/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 0.1014 - val_loss: 0.1557 - val_mae: 0.2691\n",
      "Epoch 165/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0230 - mae: 0.1078 - val_loss: 0.1634 - val_mae: 0.2878\n",
      "Epoch 166/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0246 - mae: 0.1154 - val_loss: 0.1764 - val_mae: 0.2967\n",
      "Epoch 167/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0477 - mae: 0.150 - 0s 6ms/step - loss: 0.0470 - mae: 0.1510 - val_loss: 0.1930 - val_mae: 0.3000\n",
      "Epoch 168/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0519 - mae: 0.1631 - val_loss: 0.1588 - val_mae: 0.2774\n",
      "Epoch 169/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0298 - mae: 0.1230 - val_loss: 0.1652 - val_mae: 0.2811\n",
      "Epoch 170/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0225 - mae: 0.1091 - val_loss: 0.2221 - val_mae: 0.3218\n",
      "Epoch 171/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0492 - mae: 0.1546 - val_loss: 0.1810 - val_mae: 0.3074\n",
      "Epoch 172/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0277 - mae: 0.1186 - val_loss: 0.1664 - val_mae: 0.2861\n",
      "Epoch 173/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.0908 - val_loss: 0.1600 - val_mae: 0.2769\n",
      "Epoch 174/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0779 - val_loss: 0.1493 - val_mae: 0.2635\n",
      "Epoch 175/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0626 - val_loss: 0.1440 - val_mae: 0.2611\n",
      "Epoch 176/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0594 - val_loss: 0.1409 - val_mae: 0.2609\n",
      "Epoch 177/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0497 - val_loss: 0.1475 - val_mae: 0.2650\n",
      "Epoch 178/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0468 - val_loss: 0.1414 - val_mae: 0.2559\n",
      "Epoch 179/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0035 - mae: 0.0439 - val_loss: 0.1422 - val_mae: 0.2576\n",
      "Epoch 180/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0539 - val_loss: 0.1422 - val_mae: 0.2594\n",
      "Epoch 181/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0534 - val_loss: 0.1451 - val_mae: 0.2616\n",
      "Epoch 182/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.0815 - val_loss: 0.1507 - val_mae: 0.2690\n",
      "Epoch 183/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0800 - val_loss: 0.1509 - val_mae: 0.2685\n",
      "Epoch 184/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.0844 - val_loss: 0.1560 - val_mae: 0.2730\n",
      "Epoch 185/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0788 - val_loss: 0.1493 - val_mae: 0.2684\n",
      "Epoch 186/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0676 - val_loss: 0.1450 - val_mae: 0.2650\n",
      "Epoch 187/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0624 - val_loss: 0.1475 - val_mae: 0.2669\n",
      "Epoch 188/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0613 - val_loss: 0.1478 - val_mae: 0.2696\n",
      "Epoch 189/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0602 - val_loss: 0.1401 - val_mae: 0.2583\n",
      "Epoch 190/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0641 - val_loss: 0.1531 - val_mae: 0.2652\n",
      "Epoch 191/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0694 - val_loss: 0.1424 - val_mae: 0.2583\n",
      "Epoch 192/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0572 - val_loss: 0.1415 - val_mae: 0.2572\n",
      "Epoch 193/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0649 - val_loss: 0.1380 - val_mae: 0.2587\n",
      "Epoch 194/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0806 - val_loss: 0.1524 - val_mae: 0.2660\n",
      "Epoch 195/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0836 - val_loss: 0.1479 - val_mae: 0.2711\n",
      "Epoch 196/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0757 - val_loss: 0.1417 - val_mae: 0.2586\n",
      "Epoch 197/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0941 - val_loss: 0.1710 - val_mae: 0.2864\n",
      "Epoch 198/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0242 - mae: 0.1121 - val_loss: 0.1672 - val_mae: 0.2901\n",
      "Epoch 199/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0253 - mae: 0.1153 - val_loss: 0.1538 - val_mae: 0.2848\n",
      "Epoch 200/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0205 - mae: 0.1037 - val_loss: 0.1698 - val_mae: 0.2770\n",
      "Epoch 201/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0823 - val_loss: 0.1435 - val_mae: 0.2645\n",
      "Epoch 202/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0706 - val_loss: 0.1471 - val_mae: 0.2691\n",
      "Epoch 203/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.0776 - val_loss: 0.1646 - val_mae: 0.2799\n",
      "Epoch 204/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0667 - val_loss: 0.1647 - val_mae: 0.2833\n",
      "Epoch 205/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0688 - val_loss: 0.1443 - val_mae: 0.2681\n",
      "Epoch 206/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0753 - val_loss: 0.1433 - val_mae: 0.2628\n",
      "Epoch 207/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0703 - val_loss: 0.1453 - val_mae: 0.2661\n",
      "Epoch 208/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0624 - val_loss: 0.1423 - val_mae: 0.2570\n",
      "Epoch 209/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0590 - val_loss: 0.1422 - val_mae: 0.2562\n",
      "Epoch 210/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0593 - val_loss: 0.1699 - val_mae: 0.2821\n",
      "Epoch 211/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0327 - mae: 0.1285 - val_loss: 0.1634 - val_mae: 0.2844\n",
      "Epoch 212/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0347 - mae: 0.1321 - val_loss: 0.1565 - val_mae: 0.2749\n",
      "Epoch 213/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0363 - mae: 0.1290 - val_loss: 0.1722 - val_mae: 0.2987\n",
      "Epoch 214/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0229 - mae: 0.1117 - val_loss: 0.1524 - val_mae: 0.2687\n",
      "Epoch 215/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0875 - val_loss: 0.1510 - val_mae: 0.2689\n",
      "Epoch 216/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0792 - val_loss: 0.1563 - val_mae: 0.2677\n",
      "Epoch 217/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0758 - val_loss: 0.1474 - val_mae: 0.2673\n",
      "Epoch 218/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0674 - val_loss: 0.1418 - val_mae: 0.2587\n",
      "Epoch 219/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0698 - val_loss: 0.1368 - val_mae: 0.2537\n",
      "Epoch 220/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0689 - val_loss: 0.1458 - val_mae: 0.2607\n",
      "Epoch 221/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0589 - val_loss: 0.1509 - val_mae: 0.2661\n",
      "Epoch 222/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0585 - val_loss: 0.1407 - val_mae: 0.2564\n",
      "Epoch 223/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0587 - val_loss: 0.1565 - val_mae: 0.2725\n",
      "Epoch 224/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0766 - val_loss: 0.1472 - val_mae: 0.2638\n",
      "Epoch 225/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0613 - val_loss: 0.1370 - val_mae: 0.2537\n",
      "Epoch 226/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0672 - val_loss: 0.1446 - val_mae: 0.2597\n",
      "Epoch 227/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0601 - val_loss: 0.1404 - val_mae: 0.2536\n",
      "Epoch 228/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0565 - val_loss: 0.1435 - val_mae: 0.2622\n",
      "Epoch 229/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0521 - val_loss: 0.1396 - val_mae: 0.2555\n",
      "Epoch 230/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0535 - val_loss: 0.1390 - val_mae: 0.2540\n",
      "Epoch 231/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0458 - val_loss: 0.1421 - val_mae: 0.2562\n",
      "Epoch 232/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0421 - val_loss: 0.1404 - val_mae: 0.2522\n",
      "Epoch 233/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0416 - val_loss: 0.1433 - val_mae: 0.2556\n",
      "Epoch 234/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0561 - val_loss: 0.1448 - val_mae: 0.2550\n",
      "Epoch 235/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0557 - val_loss: 0.1433 - val_mae: 0.2568\n",
      "Epoch 236/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0580 - val_loss: 0.1461 - val_mae: 0.2589\n",
      "Epoch 237/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0638 - val_loss: 0.1404 - val_mae: 0.2571\n",
      "Epoch 238/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0730 - val_loss: 0.1428 - val_mae: 0.2552\n",
      "Epoch 239/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0558 - val_loss: 0.1387 - val_mae: 0.2542\n",
      "Epoch 240/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0572 - val_loss: 0.1457 - val_mae: 0.2610\n",
      "Epoch 241/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0763 - val_loss: 0.1445 - val_mae: 0.2601\n",
      "Epoch 242/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0809 - val_loss: 0.1443 - val_mae: 0.2626\n",
      "Epoch 243/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0219 - mae: 0.1061 - val_loss: 0.1633 - val_mae: 0.2815\n",
      "Epoch 244/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0915 - val_loss: 0.1622 - val_mae: 0.2768\n",
      "Epoch 245/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0116 - mae: 0.0797 - val_loss: 0.1452 - val_mae: 0.2638\n",
      "Epoch 246/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0758 - val_loss: 0.1628 - val_mae: 0.2755\n",
      "Epoch 247/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0877 - val_loss: 0.1518 - val_mae: 0.2626\n",
      "Epoch 248/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0937 - val_loss: 0.1664 - val_mae: 0.2841\n",
      "Epoch 249/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0873 - val_loss: 0.1407 - val_mae: 0.2567\n",
      "Epoch 250/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0766 - val_loss: 0.1533 - val_mae: 0.2697\n",
      "Epoch 251/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0709 - val_loss: 0.1468 - val_mae: 0.2646\n",
      "Epoch 252/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0668 - val_loss: 0.1386 - val_mae: 0.2546\n",
      "Epoch 253/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0555 - val_loss: 0.1410 - val_mae: 0.2560\n",
      "Epoch 254/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0513 - val_loss: 0.1412 - val_mae: 0.2578\n",
      "Epoch 255/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0469 - val_loss: 0.1421 - val_mae: 0.2552\n",
      "Epoch 256/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0491 - val_loss: 0.1377 - val_mae: 0.2516\n",
      "Epoch 257/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0421 - val_loss: 0.1402 - val_mae: 0.2532\n",
      "Epoch 258/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0575 - val_loss: 0.1429 - val_mae: 0.2602\n",
      "Epoch 259/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0612 - val_loss: 0.1417 - val_mae: 0.2607\n",
      "Epoch 260/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0649 - val_loss: 0.1566 - val_mae: 0.2723\n",
      "Epoch 261/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0580 - val_loss: 0.1434 - val_mae: 0.2615\n",
      "Epoch 262/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0564 - val_loss: 0.1502 - val_mae: 0.2628\n",
      "Epoch 263/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0671 - val_loss: 0.1496 - val_mae: 0.2625\n",
      "Epoch 264/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.0976 - val_loss: 0.1488 - val_mae: 0.2700\n",
      "Epoch 265/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0949 - val_loss: 0.1502 - val_mae: 0.2694\n",
      "Epoch 266/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 0.0901 - val_loss: 0.1447 - val_mae: 0.2589\n",
      "Epoch 267/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0632 - val_loss: 0.1565 - val_mae: 0.2706\n",
      "Epoch 268/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0600 - val_loss: 0.1475 - val_mae: 0.2596\n",
      "Epoch 269/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0655 - val_loss: 0.1426 - val_mae: 0.2578\n",
      "Epoch 270/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0587 - val_loss: 0.1473 - val_mae: 0.2640\n",
      "Epoch 271/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0526 - val_loss: 0.1454 - val_mae: 0.2617\n",
      "Epoch 272/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0694 - val_loss: 0.1487 - val_mae: 0.2634\n",
      "Epoch 273/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0749 - val_loss: 0.1415 - val_mae: 0.2564\n",
      "Epoch 274/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0611 - val_loss: 0.1424 - val_mae: 0.2570\n",
      "Epoch 275/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0594 - val_loss: 0.1424 - val_mae: 0.2593\n",
      "Epoch 276/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0643 - val_loss: 0.1456 - val_mae: 0.2642\n",
      "Epoch 277/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0777 - val_loss: 0.1568 - val_mae: 0.2753\n",
      "Epoch 278/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0152 - mae: 0.0885 - val_loss: 0.1997 - val_mae: 0.2985\n",
      "Epoch 279/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0293 - mae: 0.1208 - val_loss: 0.1662 - val_mae: 0.2835\n",
      "Epoch 280/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0230 - mae: 0.1094 - val_loss: 0.1656 - val_mae: 0.2909\n",
      "Epoch 281/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0856 - val_loss: 0.1477 - val_mae: 0.2665\n",
      "Epoch 282/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0748 - val_loss: 0.1488 - val_mae: 0.2686\n",
      "Epoch 283/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0594 - val_loss: 0.1457 - val_mae: 0.2601\n",
      "Epoch 284/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0505 - val_loss: 0.1455 - val_mae: 0.2609\n",
      "Epoch 285/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0476 - val_loss: 0.1473 - val_mae: 0.2611\n",
      "Epoch 286/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0483 - val_loss: 0.1461 - val_mae: 0.2607\n",
      "Epoch 287/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0410 - val_loss: 0.1484 - val_mae: 0.2601\n",
      "Epoch 288/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0478 - val_loss: 0.1452 - val_mae: 0.2604\n",
      "Epoch 289/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0485 - val_loss: 0.1453 - val_mae: 0.2583\n",
      "Epoch 290/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0417 - val_loss: 0.1424 - val_mae: 0.2561\n",
      "Epoch 291/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0402 - val_loss: 0.1437 - val_mae: 0.2572\n",
      "Epoch 292/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0427 - val_loss: 0.1483 - val_mae: 0.2625\n",
      "Epoch 293/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0416 - val_loss: 0.1437 - val_mae: 0.2567\n",
      "Epoch 294/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0427 - val_loss: 0.1404 - val_mae: 0.2532\n",
      "Epoch 295/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0408 - val_loss: 0.1448 - val_mae: 0.2593\n",
      "Epoch 296/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0460 - val_loss: 0.1403 - val_mae: 0.2553\n",
      "Epoch 297/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0395 - val_loss: 0.1390 - val_mae: 0.2537\n",
      "Epoch 298/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0420 - val_loss: 0.1408 - val_mae: 0.2533\n",
      "Epoch 299/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0398 - val_loss: 0.1450 - val_mae: 0.2567\n",
      "Epoch 300/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0369 - val_loss: 0.1392 - val_mae: 0.2531\n",
      "Epoch 301/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0028 - mae: 0.0358 - val_loss: 0.1391 - val_mae: 0.2508\n",
      "Epoch 302/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0394 - val_loss: 0.1475 - val_mae: 0.2608\n",
      "Epoch 303/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0470 - val_loss: 0.1450 - val_mae: 0.2572\n",
      "Epoch 304/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0535 - val_loss: 0.1404 - val_mae: 0.2542\n",
      "Epoch 305/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0511 - val_loss: 0.1491 - val_mae: 0.2617\n",
      "Epoch 306/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0514 - val_loss: 0.1409 - val_mae: 0.2539\n",
      "Epoch 307/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0632 - val_loss: 0.1425 - val_mae: 0.2570\n",
      "Epoch 308/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0613 - val_loss: 0.1413 - val_mae: 0.2571\n",
      "Epoch 309/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0548 - val_loss: 0.1476 - val_mae: 0.2602\n",
      "Epoch 310/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0782 - val_loss: 0.1504 - val_mae: 0.2642\n",
      "Epoch 311/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0251 - mae: 0.1101 - val_loss: 0.1847 - val_mae: 0.3019\n",
      "Epoch 312/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0753 - mae: 0.1971 - val_loss: 0.1745 - val_mae: 0.3033\n",
      "Epoch 313/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0336 - mae: 0.1349 - val_loss: 0.1463 - val_mae: 0.2648\n",
      "Epoch 314/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0866 - val_loss: 0.1507 - val_mae: 0.2671\n",
      "Epoch 315/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0727 - val_loss: 0.1469 - val_mae: 0.2612\n",
      "Epoch 316/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0577 - val_loss: 0.1484 - val_mae: 0.2603\n",
      "Epoch 317/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0651 - val_loss: 0.1609 - val_mae: 0.2717\n",
      "Epoch 318/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0564 - val_loss: 0.1413 - val_mae: 0.2574\n",
      "Epoch 319/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0564 - val_loss: 0.1408 - val_mae: 0.2580\n",
      "Epoch 320/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0537 - val_loss: 0.1508 - val_mae: 0.2632\n",
      "Epoch 321/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0433 - val_loss: 0.1428 - val_mae: 0.2599\n",
      "Epoch 322/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0381 - val_loss: 0.1434 - val_mae: 0.2567\n",
      "Epoch 323/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0024 - mae: 0.0363 - val_loss: 0.1427 - val_mae: 0.2564\n",
      "Epoch 324/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0348 - val_loss: 0.1469 - val_mae: 0.2614\n",
      "Epoch 325/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0342 - val_loss: 0.1423 - val_mae: 0.2536\n",
      "Epoch 326/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0312 - val_loss: 0.1456 - val_mae: 0.2569\n",
      "Epoch 327/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.1428 - val_mae: 0.2576\n",
      "Epoch 328/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.1476 - val_mae: 0.2610\n",
      "Epoch 329/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.1406 - val_mae: 0.2533\n",
      "Epoch 330/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.1427 - val_mae: 0.2544\n",
      "Epoch 331/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.1442 - val_mae: 0.2563\n",
      "Epoch 332/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.1425 - val_mae: 0.2542\n",
      "Epoch 333/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0333 - val_loss: 0.1415 - val_mae: 0.2521\n",
      "Epoch 334/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0461 - val_loss: 0.1483 - val_mae: 0.2594\n",
      "Epoch 335/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0473 - val_loss: 0.1415 - val_mae: 0.2574\n",
      "Epoch 336/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0429 - val_loss: 0.1406 - val_mae: 0.2544\n",
      "Epoch 337/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0577 - val_loss: 0.1526 - val_mae: 0.2679\n",
      "Epoch 338/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0528 - val_loss: 0.1344 - val_mae: 0.2488\n",
      "Epoch 339/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0569 - val_loss: 0.1488 - val_mae: 0.2599\n",
      "Epoch 340/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0648 - val_loss: 0.1477 - val_mae: 0.2586\n",
      "Epoch 341/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0099 - mae: 0.070 - 0s 6ms/step - loss: 0.0093 - mae: 0.0690 - val_loss: 0.1528 - val_mae: 0.2676\n",
      "Epoch 342/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0806 - val_loss: 0.1622 - val_mae: 0.2762\n",
      "Epoch 343/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.0829 - val_loss: 0.1604 - val_mae: 0.2674\n",
      "Epoch 344/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0717 - val_loss: 0.1478 - val_mae: 0.2619\n",
      "Epoch 345/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0581 - val_loss: 0.1521 - val_mae: 0.2634\n",
      "Epoch 346/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0452 - val_loss: 0.1409 - val_mae: 0.2516\n",
      "Epoch 347/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.1379 - val_mae: 0.2518\n",
      "Epoch 348/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0371 - val_loss: 0.1503 - val_mae: 0.2623\n",
      "Epoch 349/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0354 - val_loss: 0.1399 - val_mae: 0.2527\n",
      "Epoch 350/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.1426 - val_mae: 0.2537\n",
      "Epoch 351/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0330 - val_loss: 0.1421 - val_mae: 0.2534\n",
      "Epoch 352/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0597 - val_loss: 0.1454 - val_mae: 0.2637\n",
      "Epoch 353/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0642 - val_loss: 0.1456 - val_mae: 0.2601\n",
      "Epoch 354/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0628 - val_loss: 0.1555 - val_mae: 0.2676\n",
      "Epoch 355/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0768 - val_loss: 0.1485 - val_mae: 0.2647\n",
      "Epoch 356/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0651 - val_loss: 0.1417 - val_mae: 0.2533\n",
      "Epoch 357/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0523 - val_loss: 0.1439 - val_mae: 0.2597\n",
      "Epoch 358/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0667 - val_loss: 0.1479 - val_mae: 0.2605\n",
      "Epoch 359/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0617 - val_loss: 0.1462 - val_mae: 0.2579\n",
      "Epoch 360/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0566 - val_loss: 0.1506 - val_mae: 0.2640\n",
      "Epoch 361/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0468 - val_loss: 0.1423 - val_mae: 0.2555\n",
      "Epoch 362/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0437 - val_loss: 0.1438 - val_mae: 0.2550\n",
      "Epoch 363/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.1412 - val_mae: 0.2546\n",
      "Epoch 364/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0401 - val_loss: 0.1386 - val_mae: 0.2539\n",
      "Epoch 365/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0450 - val_loss: 0.1418 - val_mae: 0.2594\n",
      "Epoch 366/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0477 - val_loss: 0.1426 - val_mae: 0.2548\n",
      "Epoch 367/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0489 - val_loss: 0.1425 - val_mae: 0.2557\n",
      "Epoch 368/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0626 - val_loss: 0.1443 - val_mae: 0.2571\n",
      "Epoch 369/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0715 - val_loss: 0.2208 - val_mae: 0.3206\n",
      "Epoch 370/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0254 - mae: 0.1126 - val_loss: 0.1595 - val_mae: 0.2705\n",
      "Epoch 371/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0930 - val_loss: 0.1456 - val_mae: 0.2624\n",
      "Epoch 372/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0787 - val_loss: 0.1505 - val_mae: 0.2631\n",
      "Epoch 373/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0645 - val_loss: 0.1482 - val_mae: 0.2618\n",
      "Epoch 374/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0477 - val_loss: 0.1405 - val_mae: 0.2520\n",
      "Epoch 375/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0536 - val_loss: 0.1411 - val_mae: 0.2554\n",
      "Epoch 376/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0457 - val_loss: 0.1410 - val_mae: 0.2503\n",
      "Epoch 377/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0370 - val_loss: 0.1387 - val_mae: 0.2494\n",
      "Epoch 378/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0343 - val_loss: 0.1425 - val_mae: 0.2527\n",
      "Epoch 379/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0024 - mae: 0.0359 - val_loss: 0.1385 - val_mae: 0.2514\n",
      "Epoch 380/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0365 - val_loss: 0.1472 - val_mae: 0.2596\n",
      "Epoch 381/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0344 - val_loss: 0.1389 - val_mae: 0.2503\n",
      "Epoch 382/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0317 - val_loss: 0.1432 - val_mae: 0.2543\n",
      "Epoch 383/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.1453 - val_mae: 0.2554\n",
      "Epoch 384/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0342 - val_loss: 0.1435 - val_mae: 0.2566\n",
      "Epoch 385/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0326 - val_loss: 0.1413 - val_mae: 0.2525\n",
      "Epoch 386/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0354 - val_loss: 0.1412 - val_mae: 0.2544\n",
      "Epoch 387/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0429 - val_loss: 0.1441 - val_mae: 0.2551\n",
      "Epoch 388/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0517 - val_loss: 0.1432 - val_mae: 0.2554\n",
      "Epoch 389/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0521 - val_loss: 0.1556 - val_mae: 0.2683\n",
      "Epoch 390/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0530 - val_loss: 0.1410 - val_mae: 0.2521\n",
      "Epoch 391/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.0873 - val_loss: 0.1614 - val_mae: 0.2808\n",
      "Epoch 392/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0227 - mae: 0.1099 - val_loss: 0.1554 - val_mae: 0.2737\n",
      "Epoch 393/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0929 - val_loss: 0.1642 - val_mae: 0.2781\n",
      "Epoch 394/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0780 - val_loss: 0.1397 - val_mae: 0.2541\n",
      "Epoch 395/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0543 - val_loss: 0.1405 - val_mae: 0.2553\n",
      "Epoch 396/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0519 - val_loss: 0.1466 - val_mae: 0.2630\n",
      "Epoch 397/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0461 - val_loss: 0.1376 - val_mae: 0.2522\n",
      "Epoch 398/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.1393 - val_mae: 0.2522\n",
      "Epoch 399/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0469 - val_loss: 0.1431 - val_mae: 0.2536\n",
      "Epoch 400/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0419 - val_loss: 0.1377 - val_mae: 0.2507\n",
      "Epoch 401/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0028 - mae: 0.0386 - val_loss: 0.1464 - val_mae: 0.2580\n",
      "Epoch 402/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0359 - val_loss: 0.1380 - val_mae: 0.2512\n",
      "Epoch 403/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0354 - val_loss: 0.1433 - val_mae: 0.2536\n",
      "Epoch 404/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0325 - val_loss: 0.1405 - val_mae: 0.2527\n",
      "Epoch 405/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.1417 - val_mae: 0.2533\n",
      "Epoch 406/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0508 - val_loss: 0.1441 - val_mae: 0.2558\n",
      "Epoch 407/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0436 - val_loss: 0.1408 - val_mae: 0.2534\n",
      "Epoch 408/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0502 - val_loss: 0.1404 - val_mae: 0.2506\n",
      "Epoch 409/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0474 - val_loss: 0.1403 - val_mae: 0.2517\n",
      "Epoch 410/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0439 - val_loss: 0.1433 - val_mae: 0.2548\n",
      "Epoch 411/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0408 - val_loss: 0.1418 - val_mae: 0.2549\n",
      "Epoch 412/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0437 - val_loss: 0.1432 - val_mae: 0.2532\n",
      "Epoch 413/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0442 - val_loss: 0.1406 - val_mae: 0.2524\n",
      "Epoch 414/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0028 - mae: 0.0380 - val_loss: 0.1441 - val_mae: 0.2554\n",
      "Epoch 415/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0393 - val_loss: 0.1383 - val_mae: 0.2505\n",
      "Epoch 416/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0430 - val_loss: 0.1359 - val_mae: 0.2472\n",
      "Epoch 417/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0421 - val_loss: 0.1396 - val_mae: 0.2509\n",
      "Epoch 418/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0466 - val_loss: 0.1472 - val_mae: 0.2583\n",
      "Epoch 419/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0557 - val_loss: 0.1421 - val_mae: 0.2550\n",
      "Epoch 420/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0512 - val_loss: 0.1459 - val_mae: 0.2606\n",
      "Epoch 421/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 0.1398 - val_mae: 0.2543\n",
      "Epoch 422/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0550 - val_loss: 0.1653 - val_mae: 0.2888\n",
      "Epoch 423/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0854 - val_loss: 0.1470 - val_mae: 0.2638\n",
      "Epoch 424/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.0825 - val_loss: 0.1537 - val_mae: 0.2720\n",
      "Epoch 425/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0116 - mae: 0.0773 - val_loss: 0.1434 - val_mae: 0.2573\n",
      "Epoch 426/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0733 - val_loss: 0.1432 - val_mae: 0.2555\n",
      "Epoch 427/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0532 - val_loss: 0.1409 - val_mae: 0.2553\n",
      "Epoch 428/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0479 - val_loss: 0.1370 - val_mae: 0.2515\n",
      "Epoch 429/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0602 - val_loss: 0.1401 - val_mae: 0.2522\n",
      "Epoch 430/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0599 - val_loss: 0.1619 - val_mae: 0.2733\n",
      "Epoch 431/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0147 - mae: 0.0851 - val_loss: 0.1501 - val_mae: 0.2656\n",
      "Epoch 432/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0678 - val_loss: 0.1515 - val_mae: 0.2592\n",
      "Epoch 433/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0676 - val_loss: 0.1516 - val_mae: 0.2624\n",
      "Epoch 434/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0717 - val_loss: 0.1426 - val_mae: 0.2600\n",
      "Epoch 435/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0542 - val_loss: 0.1474 - val_mae: 0.2571\n",
      "Epoch 436/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.1422 - val_mae: 0.2536\n",
      "Epoch 437/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0345 - val_loss: 0.1377 - val_mae: 0.2506\n",
      "Epoch 438/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.1374 - val_mae: 0.2473\n",
      "Epoch 439/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0334 - val_loss: 0.1427 - val_mae: 0.2528\n",
      "Epoch 440/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0388 - val_loss: 0.1396 - val_mae: 0.2496\n",
      "Epoch 441/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.1421 - val_mae: 0.2532\n",
      "Epoch 442/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.1432 - val_mae: 0.2557\n",
      "Epoch 443/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 0.1401 - val_mae: 0.2499\n",
      "Epoch 444/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 0.1417 - val_mae: 0.2512\n",
      "Epoch 445/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.1409 - val_mae: 0.2499\n",
      "Epoch 446/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 0.1392 - val_mae: 0.2492\n",
      "Epoch 447/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 0.1432 - val_mae: 0.2536\n",
      "Epoch 448/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 9.9156e-04 - mae: 0.0230 - val_loss: 0.1399 - val_mae: 0.2512\n",
      "Epoch 449/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 8.6051e-04 - mae: 0.0213 - val_loss: 0.1394 - val_mae: 0.2508\n",
      "Epoch 450/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 9.5888e-04 - mae: 0.0225 - val_loss: 0.1429 - val_mae: 0.2533\n",
      "Epoch 451/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0028 - mae: 0.0374 - val_loss: 0.1527 - val_mae: 0.2647\n",
      "Epoch 452/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0500 - val_loss: 0.1417 - val_mae: 0.2522\n",
      "Epoch 453/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.1359 - val_mae: 0.2513\n",
      "Epoch 454/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0467 - val_loss: 0.1396 - val_mae: 0.2511\n",
      "Epoch 455/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0408 - val_loss: 0.1386 - val_mae: 0.2493\n",
      "Epoch 456/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0024 - mae: 0.0357 - val_loss: 0.1405 - val_mae: 0.2535\n",
      "Epoch 457/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0490 - val_loss: 0.1445 - val_mae: 0.2580\n",
      "Epoch 458/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0675 - val_loss: 0.1462 - val_mae: 0.2582\n",
      "Epoch 459/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0572 - val_loss: 0.1430 - val_mae: 0.2537\n",
      "Epoch 460/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0588 - val_loss: 0.1450 - val_mae: 0.2569\n",
      "Epoch 461/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0877 - val_loss: 0.1490 - val_mae: 0.2612\n",
      "Epoch 462/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0783 - val_loss: 0.1571 - val_mae: 0.2643\n",
      "Epoch 463/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0638 - val_loss: 0.1495 - val_mae: 0.2623\n",
      "Epoch 464/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0511 - val_loss: 0.1495 - val_mae: 0.2605\n",
      "Epoch 465/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0451 - val_loss: 0.1421 - val_mae: 0.2558\n",
      "Epoch 466/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0407 - val_loss: 0.1396 - val_mae: 0.2518\n",
      "Epoch 467/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0445 - val_loss: 0.1418 - val_mae: 0.2543\n",
      "Epoch 468/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0410 - val_loss: 0.1416 - val_mae: 0.2542\n",
      "Epoch 469/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0352 - val_loss: 0.1405 - val_mae: 0.2516\n",
      "Epoch 470/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0334 - val_loss: 0.1386 - val_mae: 0.2517\n",
      "Epoch 471/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.1425 - val_mae: 0.2526\n",
      "Epoch 472/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0367 - val_loss: 0.1377 - val_mae: 0.2498\n",
      "Epoch 473/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.1469 - val_mae: 0.2566\n",
      "Epoch 474/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0365 - val_loss: 0.1389 - val_mae: 0.2521\n",
      "Epoch 475/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0403 - val_loss: 0.1424 - val_mae: 0.2540\n",
      "Epoch 476/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0482 - val_loss: 0.1416 - val_mae: 0.2496\n",
      "Epoch 477/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0398 - val_loss: 0.1397 - val_mae: 0.2508\n",
      "Epoch 478/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0024 - mae: 0.0360 - val_loss: 0.1380 - val_mae: 0.2515\n",
      "Epoch 479/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0364 - val_loss: 0.1418 - val_mae: 0.2529\n",
      "Epoch 480/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0368 - val_loss: 0.1397 - val_mae: 0.2521\n",
      "Epoch 481/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0027 - mae: 0.0371 - val_loss: 0.1400 - val_mae: 0.2532\n",
      "Epoch 482/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.1391 - val_mae: 0.2519\n",
      "Epoch 483/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0027 - mae: 0.0367 - val_loss: 0.1415 - val_mae: 0.2509\n",
      "Epoch 484/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0382 - val_loss: 0.1399 - val_mae: 0.2524\n",
      "Epoch 485/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 0.1465 - val_mae: 0.2557\n",
      "Epoch 486/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0674 - val_loss: 0.1641 - val_mae: 0.2864\n",
      "Epoch 487/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0687 - val_loss: 0.1451 - val_mae: 0.2607\n",
      "Epoch 488/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0585 - val_loss: 0.1423 - val_mae: 0.2552\n",
      "Epoch 489/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0494 - val_loss: 0.1431 - val_mae: 0.2560\n",
      "Epoch 490/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0440 - val_loss: 0.1401 - val_mae: 0.2546\n",
      "Epoch 491/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.1423 - val_mae: 0.2552\n",
      "Epoch 492/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0569 - val_loss: 0.1468 - val_mae: 0.2585\n",
      "Epoch 493/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0746 - val_loss: 0.1461 - val_mae: 0.2570\n",
      "Epoch 494/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0850 - val_loss: 0.1442 - val_mae: 0.2537\n",
      "Epoch 495/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0649 - val_loss: 0.1411 - val_mae: 0.2535\n",
      "Epoch 496/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0649 - val_loss: 0.1438 - val_mae: 0.2580\n",
      "Epoch 497/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0654 - val_loss: 0.1637 - val_mae: 0.2737\n",
      "Epoch 498/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0548 - val_loss: 0.1417 - val_mae: 0.2542\n",
      "Epoch 499/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.1429 - val_mae: 0.2563\n",
      "Epoch 500/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0478 - val_loss: 0.1500 - val_mae: 0.2617\n",
      "Epoch 501/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0483 - val_loss: 0.1455 - val_mae: 0.2589\n",
      "Epoch 502/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0477 - val_loss: 0.1493 - val_mae: 0.2619\n",
      "Epoch 503/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0654 - val_loss: 0.1447 - val_mae: 0.2571\n",
      "Epoch 504/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0616 - val_loss: 0.1678 - val_mae: 0.2743\n",
      "Epoch 505/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0667 - val_loss: 0.1469 - val_mae: 0.2561\n",
      "Epoch 506/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0441 - val_loss: 0.1407 - val_mae: 0.2519\n",
      "Epoch 507/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0374 - val_loss: 0.1401 - val_mae: 0.2510\n",
      "Epoch 508/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.1419 - val_mae: 0.2516\n",
      "Epoch 509/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.1417 - val_mae: 0.2523\n",
      "Epoch 510/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0010 - mae: 0.0233 - val_loss: 0.1405 - val_mae: 0.2517\n",
      "Epoch 511/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 7.7727e-04 - mae: 0.0207 - val_loss: 0.1449 - val_mae: 0.2557\n",
      "Epoch 512/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 6.1866e-04 - mae: 0.0186 - val_loss: 0.1436 - val_mae: 0.2542\n",
      "Epoch 513/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 9.4172e-04 - mae: 0.0224 - val_loss: 0.1407 - val_mae: 0.2504\n",
      "Epoch 514/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 7.4988e-04 - mae: 0.0202 - val_loss: 0.1415 - val_mae: 0.2516\n",
      "Epoch 515/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 8.7188e-04 - mae: 0.0217 - val_loss: 0.1414 - val_mae: 0.2524\n",
      "Epoch 516/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 0.1411 - val_mae: 0.2522\n",
      "Epoch 00516: early stopping\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqpElEQVR4nO3deZwU9Z3/8deHYWTkUE4jcg1GTeQ+JojBCATNgkeMrkkwGMWNouhuYk6vRI2uSTY/Vlk8o8YT4oXnKkZlhaDGg0NAEFTkkJFrQDmGQ4H5/P741jA9M90z3TM9DFPzfj4e9eg6vvXtz7e6+9PV36quMndHREQavib1HYCIiGSHErqISEwooYuIxIQSuohITCihi4jEhBK6iEhMKKFLUmb2opmdn+2y9cnMVprZSXVQ70wzuzAaH2NmL6dTtgbP09XMis0sp6axVlG3m9lR2a5X9i8l9BiJPuylQ4mZ7UyYHpNJXe4+yt0fzHbZA5GZXWVms5LMb29mX5pZr3Trcvcp7v6dLMVV7gvI3T9x95buvjcb9Uv8KKHHSPRhb+nuLYFPgNMT5k0pLWdmTesvygPSw8A3zax7hfmjgffcfVE9xCSSMSX0RsDMhplZoZldYWbrgPvNrI2ZPW9mRWb2eTTeOWGdxG6EsWb2uplNiMquMLNRNSzb3cxmmdk2M5tuZreb2eQUcacT441m9kZU38tm1j5h+Y/NbJWZbTKza1JtH3cvBF4Fflxh0XnAg9XFUSHmsWb2esL0yWa21My2mNltgCUs+6qZvRrFt9HMpphZ62jZw0BX4H+jX1i/MbP8qGukaVTmCDN7zsw+M7NlZnZRQt3Xm9njZvZQtG0Wm1lBqm1QoQ2HRusVRdvvt2bWJFp2lJn9I2rPRjN7LJpvZnaLmW2Ili3M5JeNZIcSeuNxONAW6AaMI7z290fTXYGdwG1VrH8c8AHQHvgz8FczsxqU/RvwDtAOuJ7KSTRROjH+CLgAOAw4CPgVgJn1AO6M6j8ier6kSTjyYGIsZvY1oB/wSJpxVBJ9uTwJ/JawLT4GhiQWAf4YxXcs0IWwTXD3H1P+V9afkzzFI0BhtP7ZwB/MbETC8u8CjwKtgefSiTlyK3AocCQwlPDFdkG07EbgZaANYXveGs3/DnAicEz0fD8ENqX5fJIt7q4hhgOwEjgpGh8GfAnkVVG+H/B5wvRM4MJofCywLGFZc8CBwzMpS0iGe4DmCcsnA5PTbFOyGH+bMH0p8Pdo/Frg0YRlLaJtcFKKupsDW4FvRtM3Ac/WcFu9Ho2fB7yVUM4ICfjCFPV+D3g32WsYTedH27IpIfnvBVolLP8j8EA0fj0wPWFZD2BnFdvWgaOAHOALoEfCsouBmdH4Q8DdQOcK638b+BAYDDSp7/d/Yx20h954FLn7rtIJM2tuZn+JflJvBWYBrS31GRTrSkfcfUc02jLDskcAnyXMA1idKuA0Y1yXML4jIaYjEut29+1UsccYxfQEcF70a2IMYa+9JtuqVMUYPHHazA4zs0fN7NOo3smEPfl0lG7LbQnzVgGdEqYrbps8q/74SXvCL51VKer9DeGL6Z2oG+ffora9SvgFcDuw3szuNrND0myLZIkSeuNR8bKavwS+Bhzn7ocQfi5DQh9vHVgLtDWz5gnzulRRvjYxrk2sO3rOdtWs8yDwA+BkoBXwfC3jqBiDUb69fyS8Ln2ies+tUGdVl0JdQ9iWrRLmdQU+rSam6mwEdhO6lyrV6+7r3P0idz+CsOd+h0WnO7r7JHcfCPQkdL38upaxSIaU0BuvVoS+4M1m1ha4rq6f0N1XAXOA683sIDM7Hji9jmKcCpxmZieY2UHADVT/fn8N2EzoUnjU3b+sZRwvAD3N7Kxoz/inhK6nUq2A4qjeTlROgOsJ/diVuPtq4J/AH80sz8z6AD8BpiQrny4Pp0Q+DtxkZq3MrBvwC8KvB8zs+wkHhD8nfOnsNbNvmNlxZpYLbAd2EbqEZD9SQm+8JgIHE/bI3gL+vp+edwxwPKH74z+Bxwh9tslMpIYxuvti4DLCQdi1hORTWM06Tugj7hY91ioOd98IfB/4E6G9RwNvJBT5PTAA2EJI/k9VqOKPwG/NbLOZ/SrJU5xD6FdfAzwNXOfur6QTWzX+g5CUlwOvE7bhfdGybwBvm1kx4UDrz9x9BXAIcA9hO68itHdCFmKRDFh0QEOkXkSnvS119zr/hSASd9pDl/0q+mn+VTNrYmYjgTOAZ+o5LJFY0D8GZX87nNC10I7QBTLe3d+t35BE4kFdLiIiMaEuFxGRmKi3Lpf27dt7fn5+fT29iEiDNHfu3I3u3iHZsnpL6Pn5+cyZM6e+nl5EpEEys1WplqnLRUQkJpTQRURiQgldRCQmdB66SCOye/duCgsL2bVrV/WFpV7l5eXRuXNncnNz015HCV2kESksLKRVq1bk5+eT+v4kUt/cnU2bNlFYWEj37hXvjJhag+pymTIF8vOhSZPwOKVW15UTaXx27dpFu3btlMwPcGZGu3btMv4l1WD20KdMgXHjYEd0a4RVq8I0wJiM7mcv0rgpmTcMNXmdGswe+jXXlCXzUjt2hPkiItKAEvonn2Q2X0QOPJs3b+aOO+6o0bqnnHIKmzdvrrLMtddey/Tp02tUf0X5+fls3LgxK3XtLw0moXftmtl8Eam9bB+3qiqh791b9Q2Opk2bRuvWrassc8MNN3DSSSfVNLwGr8Ek9JtugubNy89r3jzMF5HsKz1utWoVuJcdt6pNUr/yyiv5+OOP6devH7/+9a+ZOXMmw4cP50c/+hG9e/cG4Hvf+x4DBw6kZ8+e3H333fvWLd1jXrlyJcceeywXXXQRPXv25Dvf+Q47d+4EYOzYsUydOnVf+euuu44BAwbQu3dvli5dCkBRUREnn3wyAwYM4OKLL6Zbt27V7onffPPN9OrVi169ejFx4kQAtm/fzqmnnkrfvn3p1asXjz322L429ujRgz59+vCrXyW70VQdcvd6GQYOHOiZmjzZvVs3d7PwOHlyxlWINGrvv/9+2mW7dXMPqbz80K1bzZ9/xYoV3rNnz33TM2bM8ObNm/vy5cv3zdu0aZO7u+/YscN79uzpGzdujOLp5kVFRb5ixQrPycnxd999193dv//97/vDDz/s7u7nn3++P/HEE/vKT5o0yd3db7/9dv/JT37i7u6XXXaZ/+EPf3B39xdffNEBLyoqStL+8Hxz5szxXr16eXFxsW/bts179Ojh8+bN86lTp/qFF164r/zmzZt906ZNfswxx3hJSYm7u3/++ec131ie/PUC5niKvNpg9tAhnM2yciWUlIRHnd0iUnf213GrQYMGlTvXetKkSfTt25fBgwezevVqPvroo0rrdO/enX79+gEwcOBAVq5cmbTus846q1KZ119/ndGjRwMwcuRI2rRpU2V8r7/+OmeeeSYtWrSgZcuWnHXWWbz22mv07t2b6dOnc8UVV/Daa69x6KGHcsghh5CXl8eFF17IU089RfOK3Qp1rEEldBHZf/bXcasWLVrsG585cybTp0/nzTffZMGCBfTv3z/pudjNmjXbN56Tk8OePXuS1l1aLrGMZ3hTn1TljznmGObOnUvv3r256qqruOGGG2jatCnvvPMO//qv/8ozzzzDyJEjM3qu2lJCF5Gk6uK4VatWrdi2bVvK5Vu2bKFNmzY0b96cpUuX8tZbb9X8yVI44YQTePzxxwF4+eWX+fzzz6ssf+KJJ/LMM8+wY8cOtm/fztNPP823vvUt1qxZQ/PmzTn33HP51a9+xbx58yguLmbLli2ccsopTJw4kfnz52c9/qo0mD8Wicj+Vdqlec01oZula9eQzGvT1dmuXTuGDBlCr169GDVqFKeeemq55SNHjuSuu+6iT58+fO1rX2Pw4MG1aEFy1113Heeccw6PPfYYQ4cOpWPHjrRq1Spl+QEDBjB27FgGDRoEwIUXXkj//v156aWX+PWvf02TJk3Izc3lzjvvZNu2bZxxxhns2rULd+eWW27JevxVqbd7ihYUFLhucCGyfy1ZsoRjjz22vsOoV1988QU5OTk0bdqUN998k/Hjx+/3Pel0JXu9zGyuuxckK1/tHrqZ5QGzgGZR+anufl2FMgb8D3AKsAMY6+7zatQCEZE69Mknn/CDH/yAkpISDjroIO655576Dilr0uly+QL4trsXm1ku8LqZvejuiZ1bo4Cjo+E44M7oUUTkgHL00Ufz7rvv1ncYdaLag6LRqY/F0WRuNFTspzkDeCgq+xbQ2sw6ZjdUERGpSlpnuZhZjpnNBzYAr7j72xWKdAJWJ0wXRvMq1jPOzOaY2ZyioqIahiwiIsmkldDdfa+79wM6A4PMrFeFIsmu81jpaKu73+3uBe5e0KFDh4yDFRGR1DI6D93dNwMzgYpnyxcCXRKmOwNrahOYiIhkptqEbmYdzKx1NH4wcBKwtEKx54DzLBgMbHH3tdkOVkQan5YtWwKwZs0azj777KRlhg0bRnWnQU+cOJEdCTdVSOdyvOm4/vrrmTBhQq3ryYZ09tA7AjPMbCEwm9CH/ryZXWJml0RlpgHLgWXAPcCldRKtiDRaRxxxxL4rKdZExYSezuV4G5p0znJZ6O793b2Pu/dy9xui+Xe5+13RuLv7Ze7+VXfv7e76x5CIVHLFFVeUux769ddfz3//939TXFzMiBEj9l3q9tlnn6207sqVK+nVKxy+27lzJ6NHj6ZPnz788Ic/3Hf5XIDx48dTUFBAz549ue668JeZSZMmsWbNGoYPH87w4cOB8jewSHZ53Kou05vK/PnzGTx4MH369OHMM8/cd1mBSZMm7bukbumFwf7xj3/Qr18/+vXrR//+/au8JEK69Nd/kUbq8ssh23+Q7NcPonyY1OjRo7n88su59NLwI/7xxx/n73//O3l5eTz99NMccsghbNy4kcGDB/Pd73435X0177zzTpo3b87ChQtZuHAhAwYM2Lfspptuom3btuzdu5cRI0awcOFCfvrTn3LzzTczY8YM2rdvX66uuXPncv/99/P222/j7hx33HEMHTqUNm3a8NFHH/HII49wzz338IMf/IAnn3ySc889N2X7zjvvPG699VaGDh3Ktddey+9//3smTpzIn/70J1asWEGzZs32dfNMmDCB22+/nSFDhlBcXExeXl5a27gqujiXiOw3/fv3Z8OGDaxZs4YFCxbQpk0bunbtirtz9dVX06dPH0466SQ+/fRT1q9fn7KeWbNm7Uusffr0oU+fPvuWPf744wwYMID+/fuzePFi3n///SpjSnV5XEj/Mr0QLiy2efNmhg4dCsD555/PrFmz9sU4ZswYJk+eTNOmYT96yJAh/OIXv2DSpEls3rx53/za0B66SCNV1Z50XTr77LOZOnUq69at29f9MGXKFIqKipg7dy65ubnk5+cnvWxuomR77ytWrGDChAnMnj2bNm3aMHbs2Grrqep6VhUv01tdl0sqL7zwArNmzeK5557jxhtvZPHixVx55ZWceuqpTJs2jcGDBzN9+nS+/vWv16j+UtpDF5H9avTo0Tz66KNMnTp131krW7Zs4bDDDiM3N5cZM2awatWqKus48cQTmRLdC2/RokUsXLgQgK1bt9KiRQsOPfRQ1q9fz4svvrhvnVSX7k11edxMHXroobRp02bf3v3DDz/M0KFDKSkpYfXq1QwfPpw///nPbN68meLiYj7++GN69+7NFVdcQUFBwb5b5NWG9tBFZL/q2bMn27Zto1OnTnTsGK4QMmbMGE4//XQKCgro169ftXuq48eP54ILLqBPnz7069dv36Vt+/btS//+/enZsydHHnkkQ4YM2bfOuHHjGDVqFB07dmTGjBn75qe6PG5V3SupPPjgg1xyySXs2LGDI488kvvvv5+9e/dy7rnnsmXLFtydn//857Ru3Zrf/e53zJgxg5ycHHr06MGoUaMyfr6KdPlckUZEl89tWDK9fK66XEREYkIJXUQkJpTQRRqZ+upmlczU5HVSQhdpRPLy8ti0aZOS+gHO3dm0aVPGfzbSWS4ijUjnzp0pLCxE9yM48OXl5dG5c+eM1lFCF2lEcnNz6d69e32HIXVEXS4iIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuIhITSugiIjGhhC4iEhNK6CIiMaGELiISE9UmdDPrYmYzzGyJmS02s58lKTPMzLaY2fxouLZuwhURkVTSuZbLHuCX7j7PzFoBc83sFXeveCvt19z9tOyHKCIi6ah2D93d17r7vGh8G7AE6FTXgYmISGYy6kM3s3ygP/B2ksXHm9kCM3vRzHqmWH+cmc0xszm6fKeISHalndDNrCXwJHC5u2+tsHge0M3d+wK3As8kq8Pd73b3Ancv6NChQw1DFhGRZNJK6GaWS0jmU9z9qYrL3X2ruxdH49OAXDNrn9VIRUSkSumc5WLAX4El7n5zijKHR+Uws0FRvZuyGaiIiFQtnbNchgA/Bt4zs/nRvKuBrgDufhdwNjDezPYAO4HRrpsWiojsV9UmdHd/HbBqytwG3JatoEREJHP6p6iISEwooYuIxIQSuohITCihi4jEhBK6iEhMKKGLiMSEErqISEwooYuIxIQSuohITCihi4jEhBK6iEhMKKGLiMSEErqISEwooYuIxIQSuohITCihi4jEhBK6iEhMKKGLiMSEErqISEwooYuIxIQSuohITCihi4jERLUJ3cy6mNkMM1tiZovN7GdJypiZTTKzZWa20MwG1E24IiKSStM0yuwBfunu88ysFTDXzF5x9/cTyowCjo6G44A7o0cREdlPqt1Dd/e17j4vGt8GLAE6VSh2BvCQB28Brc2sY9ajFRGRlDLqQzezfKA/8HaFRZ2A1QnThVRO+pjZODObY2ZzioqKMgxVRESqknZCN7OWwJPA5e6+teLiJKt4pRnud7t7gbsXdOjQIbNIRUSkSmkldDPLJSTzKe7+VJIihUCXhOnOwJrahyciIulK5ywXA/4KLHH3m1MUew44LzrbZTCwxd3XZjFOERGpRjpnuQwBfgy8Z2bzo3lXA10B3P0uYBpwCrAM2AFckPVIRUSkStUmdHd/neR95IllHLgsW0GJiEjm9E9REZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiYlqE7qZ3WdmG8xsUYrlw8xsi5nNj4Zrsx+miIhUp2kaZR4AbgMeqqLMa+5+WlYiEhGRGql2D93dZwGf7YdYRESkFrLVh368mS0wsxfNrGeqQmY2zszmmNmcoqKiLD21iIhAdhL6PKCbu/cFbgWeSVXQ3e929wJ3L+jQoUMWnlpERErVOqG7+1Z3L47GpwG5Zta+1pGJiEhGap3QzexwM7NofFBU56ba1isiIpmp9iwXM3sEGAa0N7NC4DogF8Dd7wLOBsab2R5gJzDa3b3OIhYRkaSqTejufk41y28jnNYoIiL1SP8UFRGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZioNqGb2X1mtsHMFqVYbmY2ycyWmdlCMxuQ/TBFRKQ66eyhPwCMrGL5KODoaBgH3Fn7sEREJFPVJnR3nwV8VkWRM4CHPHgLaG1mHbMVoIiIpCcbfeidgNUJ04XRvErMbJyZzTGzOUVFRVl4ahERKZWNhG5J5nmygu5+t7sXuHtBhw4dsvDUIiJSKhsJvRDokjDdGViThXpFRCQD2UjozwHnRWe7DAa2uPvaLNQrIiIZaFpdATN7BBgGtDezQuA6IBfA3e8CpgGnAMuAHcAFdRWsiIikVm1Cd/dzqlnuwGVZi0hERGpE/xQVEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYkJJXQRkZhQQhcRiQkldBGRmFBCFxGJCSV0EZGYUEIXEYmJBpfQ/+//4Pjj4ZNP6jsSEZEDS4NL6Dt2wFtvwfr19R2JiMiBpcEl9Pbtw+PGjfUbh4jIgSathG5mI83sAzNbZmZXJlk+zMy2mNn8aLg2+6EG7dqFx02b6uoZREQapqbVFTCzHOB24GSgEJhtZs+5+/sVir7m7qfVQYzlKKGLiCSXzh76IGCZuy939y+BR4Ez6jas1KZNC4+XXw75+TBlSn1FIiJyYEknoXcCVidMF0bzKjrezBaY2Ytm1jNZRWY2zszmmNmcoqKijIOdMgUuuaRsetUqGDdOSV1EBNJL6JZknleYngd0c/e+wK3AM8kqcve73b3A3Qs6dOiQUaAA11wTznJJtGNHmC8i0tilk9ALgS4J052BNYkF3H2ruxdH49OAXDNrn7UoI6nOPdc56SIi6SX02cDRZtbdzA4CRgPPJRYws8PNzKLxQVG9WT9s2bVrZvNFRBqTahO6u+8B/h14CVgCPO7ui83sEjMr7dE+G1hkZguAScBod6/YLVNrN90EzZuXn9e8eZgvItLYWR3k3bQUFBT4nDlzMl5vyhS49FLYuhW6dQvJfMyYOghQROQAZGZz3b0g2bJqz0M/0IwZE/rMr74a3n+/8h67iEhj1eD++g9lf//Xn4tERMo0yIS+eHF47NpVfy4SESnV4BL6lClw111l0/pzkYhI0OAS+jXXwBdflJ93oP256MMP4Ykn6jsKEWlsGtxB0Ybw56L+/cOXTEkJWLL/2YqI1IEGt4feEP5cVHp5gs8/r984RKRxaXAJ/aabIDe3/LymTdP7c9GePbB5c52EldS6dfvvuUREGlxCh8rdGGYwYwacfjrs3Jl6vZEjoU0bqO6/VCtXwt69tQ5TCV1E9qsGl9CvuQa+/LL8vN274a9/heefhzPPhF/8ovJ6n30WbjANVXeFfPQRdO8Of/pTzeJLPNvmhz9MfvbN7t3wt7+FPvb6MnMm/POf9ff8IpJ9DS6hV3fw86WX4JZbKifLWbPKxlesSL3+yy+Hx9/9DtauzSy2KVPCKZSlNm5MfkrlbbeFf7xOnpxZ/dk0fDgMGVL7ej79FO69t/pfPdKwvPEGfPBBfUchmWpwCb2qg5+JlwH43vdgwoRwZyP38nuj06fDwIEwfz4sW1Y2f8OGsj1zdzjnnMxiS/d67Wuiiw+vWpVZ/dmSmHxr+ythzBi46KLy27Ex+fJLKC6u7yiy74QT4Otfr+8oJGPuXi/DwIEDvSYmT3YPKSn58MILlee1aePetat7r17J11m5MtQ9aVKYHj26bNmPfuQ+e7b7jh3Vx2aWvH6z8uX+/d/Llr34ovv//q/72LHuq1a5794d4vjkk8r1P/aY++9+5/7qqzXadPusX1/2/IsX16yONWvCdmrRItTzwAO1i6mhOvXU0P6SkuzU9+mn7nv3Zqeumvryy7L3hxx4gDmeIq82uITuXnVCv/de92bNyqZbty4bv+029+HDK69zwQXumza5H3+8+5FHhud47LHyZQoKQiK99dawfPt29+eec//+990ff9x93Tr3Ll2Sx3TEEeXjP+20smU9e7p36xbG//M/3f/+9zDepIn7nj1l6zz7bPk6Fy2q2bbbtcv9iSfK1zVlSub1jBpVvo6zz65ZPJ99Fr6Ely8PX2gVrVzpXljo/vzzoWw27dxZ+zpK2z9vXu3rWrYs1HX66bWvqzaWLy9r165d9RtLQ7VuXd19Mccuobdrlzqhl+4ld+kS9oT37HGfOjXsTW7eHPaAly0Lb9qmTSuvf8UV4TlKStw//NB94MDKZf7rv9y/+tXK8w8/PHlMX/+6+5NPhgRy773uzZsnL3fIIe4XX1w2/cILId4lSyqX7ds3DIcdFmLeu9d9zpzQtorWrnXv379yHZddVjb+y1+GhHnRRe733Ve2DRJt3er+1FPu3/pW8vivuKL8OiUlIZ5773UvKgrztmwJibukxP2DD9wvvbTyF2ebNqHM3r3u3buXfUEfc4z7X/7iXlwc1t+4Mfxi27AhvffNO++E+kq/QCG8N778sny57dvdH3wwxLxtW3jfPPBA+GWTqKiorJ4mTcKvlkyVlJRts1tuKavv3XdDbL/5Tfh1WDHGZDZvdv/881D+4ovdTzrJ/eWXw3soMTEvWOD+xhtl01u2lK/n1VfL4njjjfI7Fqm8+KL7uHHuX/lK2MmpjYkTw07Qyy+XbZvrrnO/8Ub3pUvTS5R79iT/LJSUuD/8cGhjpgn3ssuSt+3jj9179Aifv5KS8Osa3K++OrP601VVQm9w10OHcJDx3HOrL2cWbip9xx3Jl+/aFc5Lnzkz9Gd/4xswbBg0STiyUFQUDqI+8QQ8+WTlA6pTpsDSpXDjjWXzDjqo7Eycgw8Oz+MOOTnhdMiWLeGpp+Coo+DII0O5k04KffsAPXqE670XFob1E0/F/PGP4dhjw+WDE+Xnh9MtAS67LFyJctYsOOywcKygot/+Fm64ISwbMCDMa9myrD/48MPDaZfDhkGXLuFSxQsXhjN0IBxfOOEEeOUVuPVW+P3vw8HRfv1CHf37h371d98t2w7NmpX9D+BrX6v6oFuHDnDooaGOo48OZx+VKu3bXbq0bN7QoSHOY48Nx0KKisKxir17w3GX5cvDa5fsVNI+fWDEiPA/hbZt4YEHkh/fyM0N22XnTigogNWrw3b5j/+ASZPKYtuyJZQ56qhQ38KFYRu3bRuWz5kDrVuH4zobNoR2fuMbMHUq5OWF90tFXbqEOlasCNty/Xro3Tu8r4qLw/xUx2Ratgx1nnBCeA1eeinM/+Y3Q/ybN8OgQfCtb4XXd/ZsePPNsvU7dQqvd14eLFgQXrfOncO27dYtXOrirbfKP2d+fni+gw8O7WzdOsS7cWNYNycntL30q2PECHjwwfC+XbSorJ4TTwwH7//4x/L1n3oq/Mu/wMcfl70nW7QoWz5/fnhv/vzn4TM2e3Z4HUqXARxzDHz3uyFPNG8O77wTPnP9+oXXrkmTEFteXoh1woSw3qhRod2zZsEhh4T3WaqTNa64Ilyq5JNPYPv28P5p1y583keNSr5Odaq6HnqDTOgQLqGbzuVzzeDhh7N3E4zZs0Oy7du37DK+JSUhmY0cGV7kiy8uf3D04INh/PiQZIYNg/PPD29oCF8UbduGD9TcueED069fSAhXXQUdO4YDuF/9avjgXXppSCwPPQQvvBD+VJWXB48/HuZ/85swbVqoe+DA8CZftgyuvDJ8yZSUwL/9W3hTlXr++RD3E0/AKafAa6+FN+obb4TlnTqFRLlkSTir5YUXQrlEJSXw//5fuHDaxo0hSR15ZNgm+fnh7KFdu+Cxx0L5nJyQ9Hftgv/5n/DhuuSSkJgPOii0b8eO8EGbOTM8vvxySOwTJoQ42rYNSXjXrjCUJsOcnPBF1qlTKLd+ffj/Qd++YUfgvffg5JPD++KJJ8J2Kz04/MUX8JWvhFNbzzwzxLh6dahn27ZQdsuW8MHv3h0uvDB8yT72WNheq1eHtpeUhDJr14bXcP78kHh37w7vSfeQNEoPJrdvH9p+442hncuXh+3w/PPhi6tt29CGgw8O7du0KSSITp3C+Oefl30RHHUU/OUv4bW/8srw2paUhOmuXaFXr1Du/ffDe+STT0L7Vq4M7evaNXzJnXVWWHfGjJC0E/+b0b59eM1WrAj1rlkTpv/2t5DIP/us8menadMQb+kX7Ve+ErbHxo1lZTp1Cut++9th223cGOJr3Tpsm3Xr4Nlnw7Yt3Tlo2TK8t93Lkntubtk4QKtW4Qtx92447bSwbe+4I9TdtGn5L9FmzSpfLwpg8ODwGixaFOIYNCi8Fh9+GJ7PLOyotG0bpmfPDstatAjvzfz88F7ctCmcWp24E5iJqhJ6g+xyca/+4Gji0K1bKN+tW+iSKZ1OVW865VJJ/DlfMYa6tHdv2c/yzz5L7yBudUpKws/1ROn89K+uTvfQPfDFFzWrY+fOsgPZ7qGrY+fOUPemTZV/Su/ZU/VBy507Qzt37Ei/+6Ym9uwJ7S4pKTsekBhXbd97JSXur71Webt+9lnZ9qnK9u1V95lv2RK63Xbtqvp9sHt3eK7CwtA9VlQUuscqxlpq1y73f/4zdBdVXOYeujS2bq0c63vvhXX37g3r7N1b1oYvvgjTc+eGLpBk8Za+v0vfNxs2hOk9e8J7Yd268FhcXPnzlO5B8LroRydufeilmjRJP6kfdFDleePHl69v/PjKZ6o0b57ZByvdM11qorYfeDlwTZ5c+dhKpu89aRxim9DHj08/oacaWrYMH5qq6mrRIv2YUh2wTdxDnzy5fLkWLcJ0VYk6VXwVv5TSVdsvh/Hj3XNyKrdRCahm6uuXnTQ8sU3o7qn3iOtiaNcuJKxkyXDy5LJzspMNI0aEeEeMSP/5EutOJ67qpBtjdapqQ25uZkk98YshJ6f6X02lX8AHimz9aqrqfby/6ZfggS3WCT0be+lxHUo/jPt7G5mF56zq9NK6GCp+sSX7FVHV0LJlWCfV3nK6Q7pfjO6Vf62liqu6pFqahJOt36RJaFdVz1W67VK9V0pf06o+hxW/lNLd0UinropdptXFk2z7VGx76XapyfotWiTvxq04P5PnSFetEzowEvgAWAZcmWS5AZOi5QuBAdXVma2E7p78DaBBgwYNB/JQ01+bVSX0aq/lYmY5wO3AKKAHcI6Z9ahQbBRwdDSMA+7M4CycWrvjjnBaVn1e7EpEJBPFxTB2bHbvh5zOxbkGAcvcfbm7fwk8CpxRocwZwEPRF8hbQGsz65i9MNMzZkw4J1VEpCHYsye790NOJ6F3AlYnTBdG8zItg5mNM7M5ZjanqKgo01jTctdd4U8DIiINQTbvh5xOQk92m2OvQRnc/W53L3D3gg4dOqQTX8bGjIH77gt/zYXKdzdqkk6LCX+/FxGpa9m8H3I66a0Q6JIw3RlYU4My+82YMeFvzO6hbz3xUMTeveWnx48vn/Rbtgx98YsXh8fEv8inq7SO8eOrLnfEEZW/cNIxYkTN4krUrl2IcfLk8tfAyFReXu3iEGnM0r0fctpSHS0tHYCmwHKgO3AQsADoWaHMqcCLhD31wcA71dWbzbNcGoKanNub6TrVnQKX7ilU6ZxKV/GUtKrOcW/WLPmyqk5rqxhDYtl04ssk7urqatGicvyl/1JO938ImcZX2/pycsIVAFMtb9YsvdMlR4zI/AyyTE4VzbSuZs2Sny5Yn0OqUxirG+riLJe0Ls5lZqcAE4Ec4D53v8nMLom+EO4yMwNuI5zeuAO4wN2rvPJWbS/OJSLSGFV1ca6m6VTg7tOAaRXm3ZUw7sBltQlSRERqp8HdU1RERJJTQhcRiQkldBGRmFBCFxGJiXq7BZ2ZFQEp7oJYrfbAxmpLxUdjaq/aGk9qa/Z0c/ek/8yst4ReG2Y2J9VpO3HUmNqrtsaT2rp/qMtFRCQmlNBFRGKioSb0u+s7gP2sMbVXbY0ntXU/aJB96CIiUllD3UMXEZEKlNBFRGKiwSV0MxtpZh+Y2TIzu7K+46ktM7vPzDaY2aKEeW3N7BUz+yh6bJOw7Kqo7R+Y2b/UT9Q1Y2ZdzGyGmS0xs8Vm9rNofuzaa2Z5ZvaOmS2I2vr7aH7s2lrKzHLM7F0zez6ajmVbzWylmb1nZvPNbE4078Boa6rr6h6IA+HyvR8DR1J2bfYe9R1XLdt0IjAAWJQw78/AldH4lcB/ReM9ojY3I1yf/mMgp77bkEFbOwIDovFWwIdRm2LXXsK9AVpG47nA24R7BcSurQlt/gXwN+D5aDqWbQVWAu0rzDsg2trQ9tDTuWF1g+Lus4DPKsw+A3gwGn8Q+F7C/Efd/Qt3XwEsI2yTBsHd17r7vGh8G7CEcO/Z2LXXg+JoMjcanBi2FcDMOhNudHNvwuxYtjWFA6KtDS2hp3Uz6hj4iruvhZAEgcOi+bFpv5nlA/0Je66xbG/UBTEf2AC84u6xbSvhBji/AUoS5sW1rQ68bGZzzWxcNO+AaGtaN7g4gKR1M+oYi0X7zawl8CRwubtvtdQ3Vm3Q7XX3vUA/M2sNPG1mvaoo3mDbamanARvcfa6ZDUtnlSTzGkRbI0PcfY2ZHQa8YmZLqyi7X9va0PbQD6ibUdeh9WbWESB63BDNb/DtN7NcQjKf4u5PRbNj214Ad98MzCTcojGObR0CfNfMVhK6Qb9tZpOJZ1tx9zXR4wbgaUIXygHR1oaW0GcDR5tZdzM7CBgNPFfPMdWF54Dzo/HzgWcT5o82s2Zm1h04GninHuKrkejes38Flrj7zQmLYtdeM+sQ7ZljZgcDJwFLiWFb3f0qd+/s7vmEz+Sr7n4uMWyrmbUws1al48B3gEUcKG2t7yPGNTjCfArh7IiPgWvqO54stOcRYC2wm/Bt/hOgHfB/wEfRY9uE8tdEbf8AGFXf8WfY1hMIPzcXAvOj4ZQ4thfoA7wbtXURcG00P3ZtrdDuYZSd5RK7thLOsFsQDYtLc9CB0lb99V9EJCYaWpeLiIikoIQuIhITSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIx8f8BkFDklZqdEQkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "40/40 [==============================] - 1s 7ms/step - loss: 4.9068 - mae: 1.4193 - val_loss: 0.7048 - val_mae: 0.6140\n",
      "Epoch 2/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5656 - mae: 0.553 - 0s 6ms/step - loss: 0.5478 - mae: 0.5424 - val_loss: 0.5625 - val_mae: 0.5338\n",
      "Epoch 3/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3921 - mae: 0.4630 - val_loss: 0.3969 - val_mae: 0.4491\n",
      "Epoch 4/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3025 - mae: 0.4038 - val_loss: 0.3865 - val_mae: 0.4342\n",
      "Epoch 5/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2554 - mae: 0.3717 - val_loss: 0.3742 - val_mae: 0.4447\n",
      "Epoch 6/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2364 - mae: 0.3577 - val_loss: 0.3250 - val_mae: 0.4230\n",
      "Epoch 7/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1897 - mae: 0.3171 - val_loss: 0.3097 - val_mae: 0.3979\n",
      "Epoch 8/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1798 - mae: 0.3097 - val_loss: 0.2893 - val_mae: 0.3910\n",
      "Epoch 9/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1442 - mae: 0.2813 - val_loss: 0.3097 - val_mae: 0.3992\n",
      "Epoch 10/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1449 - mae: 0.2797 - val_loss: 0.3028 - val_mae: 0.3975\n",
      "Epoch 11/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1439 - mae: 0.2777 - val_loss: 0.2671 - val_mae: 0.3892\n",
      "Epoch 12/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1263 - mae: 0.2605 - val_loss: 0.2630 - val_mae: 0.3664\n",
      "Epoch 13/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1369 - mae: 0.2709 - val_loss: 0.2423 - val_mae: 0.3598\n",
      "Epoch 14/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1003 - mae: 0.2332 - val_loss: 0.2191 - val_mae: 0.3354\n",
      "Epoch 15/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0801 - mae: 0.2067 - val_loss: 0.2692 - val_mae: 0.3797\n",
      "Epoch 16/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0768 - mae: 0.2043 - val_loss: 0.2046 - val_mae: 0.3342\n",
      "Epoch 17/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0827 - mae: 0.2134 - val_loss: 0.2478 - val_mae: 0.3509\n",
      "Epoch 18/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0928 - mae: 0.2271 - val_loss: 0.2384 - val_mae: 0.3569\n",
      "Epoch 19/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0700 - mae: 0.1952 - val_loss: 0.2053 - val_mae: 0.3170\n",
      "Epoch 20/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0748 - mae: 0.2014 - val_loss: 0.2533 - val_mae: 0.3569\n",
      "Epoch 21/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0658 - mae: 0.1892 - val_loss: 0.2096 - val_mae: 0.3302\n",
      "Epoch 22/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0560 - mae: 0.1754 - val_loss: 0.2057 - val_mae: 0.3217\n",
      "Epoch 23/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0485 - mae: 0.1595 - val_loss: 0.2351 - val_mae: 0.3461\n",
      "Epoch 24/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0447 - mae: 0.1557 - val_loss: 0.1683 - val_mae: 0.2906\n",
      "Epoch 25/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0431 - mae: 0.1516 - val_loss: 0.1914 - val_mae: 0.3101\n",
      "Epoch 26/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0371 - mae: 0.1401 - val_loss: 0.1778 - val_mae: 0.3039\n",
      "Epoch 27/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0497 - mae: 0.1625 - val_loss: 0.2051 - val_mae: 0.3201\n",
      "Epoch 28/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0406 - mae: 0.1488 - val_loss: 0.1894 - val_mae: 0.3052\n",
      "Epoch 29/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0263 - mae: 0.1201 - val_loss: 0.1747 - val_mae: 0.2930\n",
      "Epoch 30/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0258 - mae: 0.1195 - val_loss: 0.1929 - val_mae: 0.3139\n",
      "Epoch 31/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0394 - mae: 0.1447 - val_loss: 0.1957 - val_mae: 0.3049\n",
      "Epoch 32/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0977 - mae: 0.2287 - val_loss: 0.3290 - val_mae: 0.3923\n",
      "Epoch 33/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1071 - mae: 0.2353 - val_loss: 0.1826 - val_mae: 0.3017\n",
      "Epoch 34/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0444 - mae: 0.1548 - val_loss: 0.1854 - val_mae: 0.3039\n",
      "Epoch 35/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0239 - mae: 0.1128 - val_loss: 0.1693 - val_mae: 0.2866\n",
      "Epoch 36/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0246 - mae: 0.1146 - val_loss: 0.1840 - val_mae: 0.2969\n",
      "Epoch 37/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0232 - mae: 0.1121 - val_loss: 0.1951 - val_mae: 0.3060\n",
      "Epoch 38/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0219 - mae: 0.1063 - val_loss: 0.1903 - val_mae: 0.2996\n",
      "Epoch 39/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0246 - mae: 0.1137 - val_loss: 0.1855 - val_mae: 0.2950\n",
      "Epoch 40/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.1059 - val_loss: 0.1710 - val_mae: 0.2886\n",
      "Epoch 41/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0224 - mae: 0.1080 - val_loss: 0.1862 - val_mae: 0.3018\n",
      "Epoch 42/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0217 - mae: 0.1055 - val_loss: 0.1715 - val_mae: 0.2888\n",
      "Epoch 43/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0961 - val_loss: 0.2170 - val_mae: 0.3093\n",
      "Epoch 44/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0238 - mae: 0.1118 - val_loss: 0.1728 - val_mae: 0.2897\n",
      "Epoch 45/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0281 - mae: 0.1208 - val_loss: 0.2049 - val_mae: 0.3107\n",
      "Epoch 46/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0278 - mae: 0.1213 - val_loss: 0.1678 - val_mae: 0.2875\n",
      "Epoch 47/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0227 - mae: 0.1082 - val_loss: 0.2133 - val_mae: 0.3138\n",
      "Epoch 48/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0234 - mae: 0.1098 - val_loss: 0.1781 - val_mae: 0.2910\n",
      "Epoch 49/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0408 - mae: 0.1443 - val_loss: 0.2073 - val_mae: 0.3205\n",
      "Epoch 50/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0307 - mae: 0.1267 - val_loss: 0.2038 - val_mae: 0.3058\n",
      "Epoch 51/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 0.1030 - val_loss: 0.1958 - val_mae: 0.3084\n",
      "Epoch 52/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 0.0961 - val_loss: 0.1698 - val_mae: 0.2893\n",
      "Epoch 53/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0871 - val_loss: 0.1903 - val_mae: 0.2995\n",
      "Epoch 54/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0948 - val_loss: 0.1815 - val_mae: 0.2910\n",
      "Epoch 55/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0829 - val_loss: 0.1697 - val_mae: 0.2825\n",
      "Epoch 56/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1070 - val_loss: 0.1913 - val_mae: 0.2996\n",
      "Epoch 57/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.1007 - val_loss: 0.1760 - val_mae: 0.2902\n",
      "Epoch 58/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0155 - mae: 0.0896 - val_loss: 0.1736 - val_mae: 0.2821\n",
      "Epoch 59/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0892 - val_loss: 0.1707 - val_mae: 0.2845\n",
      "Epoch 60/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0875 - val_loss: 0.1785 - val_mae: 0.2866\n",
      "Epoch 61/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0228 - mae: 0.1081 - val_loss: 0.1842 - val_mae: 0.2946\n",
      "Epoch 62/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0340 - mae: 0.1332 - val_loss: 0.1962 - val_mae: 0.3052\n",
      "Epoch 63/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0414 - mae: 0.1443 - val_loss: 0.1836 - val_mae: 0.2993\n",
      "Epoch 64/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0218 - mae: 0.1076 - val_loss: 0.1893 - val_mae: 0.2976\n",
      "Epoch 65/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0905 - val_loss: 0.1722 - val_mae: 0.2854\n",
      "Epoch 66/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0943 - val_loss: 0.1809 - val_mae: 0.2883\n",
      "Epoch 67/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0207 - mae: 0.1039 - val_loss: 0.1745 - val_mae: 0.2847\n",
      "Epoch 68/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 0.0996 - val_loss: 0.1900 - val_mae: 0.3058\n",
      "Epoch 69/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0964 - val_loss: 0.1733 - val_mae: 0.2869\n",
      "Epoch 70/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.0997 - val_loss: 0.1705 - val_mae: 0.2803\n",
      "Epoch 71/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0856 - val_loss: 0.1882 - val_mae: 0.2964\n",
      "Epoch 72/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0217 - mae: 0.1046 - val_loss: 0.1816 - val_mae: 0.2923\n",
      "Epoch 73/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0368 - mae: 0.1351 - val_loss: 0.1796 - val_mae: 0.2939\n",
      "Epoch 74/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0242 - mae: 0.1122 - val_loss: 0.1722 - val_mae: 0.2914\n",
      "Epoch 75/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.1030 - val_loss: 0.1758 - val_mae: 0.2881\n",
      "Epoch 76/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0160 - mae: 0.0898 - val_loss: 0.1723 - val_mae: 0.2860\n",
      "Epoch 77/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0848 - val_loss: 0.1706 - val_mae: 0.2807\n",
      "Epoch 78/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.0879 - val_loss: 0.2108 - val_mae: 0.3198\n",
      "Epoch 79/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0273 - mae: 0.1160 - val_loss: 0.1685 - val_mae: 0.2880\n",
      "Epoch 80/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0352 - mae: 0.1332 - val_loss: 0.1954 - val_mae: 0.3092\n",
      "Epoch 81/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0451 - mae: 0.1493 - val_loss: 0.2143 - val_mae: 0.3195\n",
      "Epoch 82/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0282 - mae: 0.1214 - val_loss: 0.1740 - val_mae: 0.2875\n",
      "Epoch 83/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0340 - mae: 0.1302 - val_loss: 0.2020 - val_mae: 0.3075\n",
      "Epoch 84/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0309 - mae: 0.1258 - val_loss: 0.2026 - val_mae: 0.3015\n",
      "Epoch 85/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0250 - mae: 0.1142 - val_loss: 0.1822 - val_mae: 0.2860\n",
      "Epoch 86/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0223 - mae: 0.1062 - val_loss: 0.1810 - val_mae: 0.2988\n",
      "Epoch 87/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0215 - mae: 0.1044 - val_loss: 0.1749 - val_mae: 0.2873\n",
      "Epoch 88/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0263 - mae: 0.1142 - val_loss: 0.1999 - val_mae: 0.3022\n",
      "Epoch 89/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0229 - mae: 0.1092 - val_loss: 0.1734 - val_mae: 0.2832\n",
      "Epoch 90/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0934 - val_loss: 0.1797 - val_mae: 0.2921\n",
      "Epoch 91/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0750 - val_loss: 0.1670 - val_mae: 0.2807\n",
      "Epoch 92/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0884 - val_loss: 0.1633 - val_mae: 0.2790\n",
      "Epoch 93/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0803 - val_loss: 0.1762 - val_mae: 0.2894\n",
      "Epoch 94/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0969 - val_loss: 0.1891 - val_mae: 0.2913\n",
      "Epoch 95/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0884 - val_loss: 0.1814 - val_mae: 0.2850\n",
      "Epoch 96/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0724 - val_loss: 0.1763 - val_mae: 0.2839\n",
      "Epoch 97/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0715 - val_loss: 0.1842 - val_mae: 0.2891\n",
      "Epoch 98/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0606 - val_loss: 0.1662 - val_mae: 0.2778\n",
      "Epoch 99/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0563 - val_loss: 0.1727 - val_mae: 0.2800\n",
      "Epoch 100/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0643 - val_loss: 0.1786 - val_mae: 0.2939\n",
      "Epoch 101/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0154 - mae: 0.0881 - val_loss: 0.2039 - val_mae: 0.3085\n",
      "Epoch 102/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0261 - mae: 0.1162 - val_loss: 0.1979 - val_mae: 0.3116\n",
      "Epoch 103/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0324 - mae: 0.1299 - val_loss: 0.1895 - val_mae: 0.2953\n",
      "Epoch 104/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0373 - mae: 0.1369 - val_loss: 0.1976 - val_mae: 0.3133\n",
      "Epoch 105/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0448 - mae: 0.1519 - val_loss: 0.2080 - val_mae: 0.3190\n",
      "Epoch 106/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0334 - mae: 0.1325 - val_loss: 0.1743 - val_mae: 0.2975\n",
      "Epoch 107/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0231 - mae: 0.1110 - val_loss: 0.1852 - val_mae: 0.2965\n",
      "Epoch 108/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 0.0968 - val_loss: 0.1668 - val_mae: 0.2828\n",
      "Epoch 109/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0805 - val_loss: 0.1697 - val_mae: 0.2749\n",
      "Epoch 110/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0671 - val_loss: 0.1752 - val_mae: 0.2827\n",
      "Epoch 111/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0710 - val_loss: 0.1637 - val_mae: 0.2712\n",
      "Epoch 112/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0669 - val_loss: 0.1961 - val_mae: 0.2940\n",
      "Epoch 113/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.0836 - val_loss: 0.1682 - val_mae: 0.2849\n",
      "Epoch 114/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.0867 - val_loss: 0.1550 - val_mae: 0.2776\n",
      "Epoch 115/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0730 - val_loss: 0.1678 - val_mae: 0.2763\n",
      "Epoch 116/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0670 - val_loss: 0.1701 - val_mae: 0.2872\n",
      "Epoch 117/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0616 - val_loss: 0.1652 - val_mae: 0.2754\n",
      "Epoch 118/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0553 - val_loss: 0.1650 - val_mae: 0.2754\n",
      "Epoch 119/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0220 - mae: 0.1059 - val_loss: 0.1921 - val_mae: 0.3006\n",
      "Epoch 120/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1053 - val_loss: 0.1615 - val_mae: 0.2788\n",
      "Epoch 121/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 0.0910 - val_loss: 0.1823 - val_mae: 0.2869\n",
      "Epoch 122/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.0973 - val_loss: 0.1688 - val_mae: 0.2853\n",
      "Epoch 123/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0229 - mae: 0.1064 - val_loss: 0.2013 - val_mae: 0.3149\n",
      "Epoch 124/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0375 - mae: 0.1449 - val_loss: 0.2296 - val_mae: 0.3345\n",
      "Epoch 125/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0729 - mae: 0.1935 - val_loss: 0.1887 - val_mae: 0.3033\n",
      "Epoch 126/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0525 - mae: 0.1682 - val_loss: 0.1677 - val_mae: 0.2927\n",
      "Epoch 127/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0324 - mae: 0.1303 - val_loss: 0.1743 - val_mae: 0.2872\n",
      "Epoch 128/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 0.0972 - val_loss: 0.1669 - val_mae: 0.2840\n",
      "Epoch 129/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0873 - val_loss: 0.1754 - val_mae: 0.2790\n",
      "Epoch 130/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0691 - val_loss: 0.1612 - val_mae: 0.2726\n",
      "Epoch 131/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0553 - val_loss: 0.1556 - val_mae: 0.2713\n",
      "Epoch 132/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0570 - val_loss: 0.1618 - val_mae: 0.2733\n",
      "Epoch 133/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0594 - val_loss: 0.1775 - val_mae: 0.2903\n",
      "Epoch 134/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0779 - val_loss: 0.1570 - val_mae: 0.2752\n",
      "Epoch 135/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0810 - val_loss: 0.1688 - val_mae: 0.2786\n",
      "Epoch 136/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0930 - val_loss: 0.1648 - val_mae: 0.2761\n",
      "Epoch 137/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0228 - mae: 0.1062 - val_loss: 0.1704 - val_mae: 0.2798\n",
      "Epoch 138/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0247 - mae: 0.1123 - val_loss: 0.1758 - val_mae: 0.2901\n",
      "Epoch 139/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0949 - val_loss: 0.1650 - val_mae: 0.2724\n",
      "Epoch 140/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0257 - mae: 0.1127 - val_loss: 0.1584 - val_mae: 0.2746\n",
      "Epoch 141/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0789 - val_loss: 0.1702 - val_mae: 0.2807\n",
      "Epoch 142/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0608 - val_loss: 0.1703 - val_mae: 0.2788\n",
      "Epoch 143/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0640 - val_loss: 0.1690 - val_mae: 0.2760\n",
      "Epoch 144/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0637 - val_loss: 0.1718 - val_mae: 0.2776\n",
      "Epoch 145/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0560 - val_loss: 0.1689 - val_mae: 0.2790\n",
      "Epoch 146/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0509 - val_loss: 0.1632 - val_mae: 0.2709\n",
      "Epoch 147/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0427 - val_loss: 0.1613 - val_mae: 0.2702\n",
      "Epoch 148/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0377 - val_loss: 0.1659 - val_mae: 0.2736\n",
      "Epoch 149/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0502 - val_loss: 0.1663 - val_mae: 0.2731\n",
      "Epoch 150/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0507 - val_loss: 0.1765 - val_mae: 0.2836\n",
      "Epoch 151/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0495 - val_loss: 0.1609 - val_mae: 0.2700\n",
      "Epoch 152/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0424 - val_loss: 0.1618 - val_mae: 0.2707\n",
      "Epoch 153/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0532 - val_loss: 0.1687 - val_mae: 0.2772\n",
      "Epoch 154/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0787 - val_loss: 0.1658 - val_mae: 0.2773\n",
      "Epoch 155/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 0.1006 - val_loss: 0.1720 - val_mae: 0.2822\n",
      "Epoch 156/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0442 - mae: 0.1478 - val_loss: 0.1732 - val_mae: 0.2894\n",
      "Epoch 157/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0223 - mae: 0.1065 - val_loss: 0.1718 - val_mae: 0.2855\n",
      "Epoch 158/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0239 - mae: 0.1120 - val_loss: 0.1787 - val_mae: 0.2858\n",
      "Epoch 159/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.0893 - val_loss: 0.1756 - val_mae: 0.2834\n",
      "Epoch 160/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0354 - mae: 0.1330 - val_loss: 0.1909 - val_mae: 0.2976\n",
      "Epoch 161/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0346 - mae: 0.1333 - val_loss: 0.2004 - val_mae: 0.3165\n",
      "Epoch 162/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0308 - mae: 0.1254 - val_loss: 0.1738 - val_mae: 0.2861\n",
      "Epoch 163/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0233 - mae: 0.1105 - val_loss: 0.1648 - val_mae: 0.2725\n",
      "Epoch 164/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0185 - mae: 0.0974 - val_loss: 0.1785 - val_mae: 0.2907\n",
      "Epoch 165/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0901 - val_loss: 0.1671 - val_mae: 0.2781\n",
      "Epoch 166/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0779 - val_loss: 0.1639 - val_mae: 0.2782\n",
      "Epoch 167/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0623 - val_loss: 0.1697 - val_mae: 0.2827\n",
      "Epoch 168/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0559 - val_loss: 0.1664 - val_mae: 0.2794\n",
      "Epoch 169/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0459 - val_loss: 0.1633 - val_mae: 0.2713\n",
      "Epoch 170/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0439 - val_loss: 0.1615 - val_mae: 0.2727\n",
      "Epoch 171/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.1620 - val_mae: 0.2732\n",
      "Epoch 172/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.1635 - val_mae: 0.2736\n",
      "Epoch 173/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.1641 - val_mae: 0.2734\n",
      "Epoch 174/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.1642 - val_mae: 0.2745\n",
      "Epoch 175/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0415 - val_loss: 0.1632 - val_mae: 0.2754\n",
      "Epoch 176/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0497 - val_loss: 0.1661 - val_mae: 0.2760\n",
      "Epoch 177/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0412 - val_loss: 0.1638 - val_mae: 0.2721\n",
      "Epoch 178/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0400 - val_loss: 0.1633 - val_mae: 0.2734\n",
      "Epoch 179/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0537 - val_loss: 0.1754 - val_mae: 0.2821\n",
      "Epoch 180/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0696 - val_loss: 0.1615 - val_mae: 0.2693\n",
      "Epoch 181/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0274 - mae: 0.1170 - val_loss: 0.1855 - val_mae: 0.3037\n",
      "Epoch 182/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0545 - mae: 0.1720 - val_loss: 0.2325 - val_mae: 0.3181\n",
      "Epoch 183/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0499 - mae: 0.1665 - val_loss: 0.1913 - val_mae: 0.3180\n",
      "Epoch 184/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0320 - mae: 0.1283 - val_loss: 0.1555 - val_mae: 0.2777\n",
      "Epoch 185/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0228 - mae: 0.1083 - val_loss: 0.1767 - val_mae: 0.2866\n",
      "Epoch 186/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0844 - val_loss: 0.1570 - val_mae: 0.2751\n",
      "Epoch 187/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0738 - val_loss: 0.1543 - val_mae: 0.2717\n",
      "Epoch 188/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0624 - val_loss: 0.1586 - val_mae: 0.2747\n",
      "Epoch 189/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0586 - val_loss: 0.1710 - val_mae: 0.2800\n",
      "Epoch 190/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0779 - val_loss: 0.1533 - val_mae: 0.2717\n",
      "Epoch 191/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0695 - val_loss: 0.1605 - val_mae: 0.2741\n",
      "Epoch 192/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0513 - val_loss: 0.1587 - val_mae: 0.2737\n",
      "Epoch 193/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0550 - val_loss: 0.1547 - val_mae: 0.2682\n",
      "Epoch 194/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0576 - val_loss: 0.1671 - val_mae: 0.2831\n",
      "Epoch 195/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0612 - val_loss: 0.1833 - val_mae: 0.2897\n",
      "Epoch 196/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0636 - val_loss: 0.1600 - val_mae: 0.2695\n",
      "Epoch 197/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0572 - val_loss: 0.1675 - val_mae: 0.2826\n",
      "Epoch 198/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0558 - val_loss: 0.1690 - val_mae: 0.2779\n",
      "Epoch 199/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0596 - val_loss: 0.1635 - val_mae: 0.2759\n",
      "Epoch 200/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0509 - val_loss: 0.1581 - val_mae: 0.2717\n",
      "Epoch 201/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0555 - val_loss: 0.1572 - val_mae: 0.2691\n",
      "Epoch 202/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0513 - val_loss: 0.1571 - val_mae: 0.2703\n",
      "Epoch 203/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 0.1615 - val_mae: 0.2760\n",
      "Epoch 204/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0587 - val_loss: 0.1544 - val_mae: 0.2678\n",
      "Epoch 205/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0571 - val_loss: 0.1643 - val_mae: 0.2772\n",
      "Epoch 206/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0477 - val_loss: 0.1639 - val_mae: 0.2754\n",
      "Epoch 207/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0472 - val_loss: 0.1653 - val_mae: 0.2732\n",
      "Epoch 208/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0476 - val_loss: 0.1607 - val_mae: 0.2741\n",
      "Epoch 209/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0626 - val_loss: 0.1689 - val_mae: 0.2865\n",
      "Epoch 210/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 0.0905 - val_loss: 0.1582 - val_mae: 0.2688\n",
      "Epoch 211/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0168 - mae: 0.0927 - val_loss: 0.1747 - val_mae: 0.2885\n",
      "Epoch 212/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0884 - val_loss: 0.1604 - val_mae: 0.2742\n",
      "Epoch 213/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.0854 - val_loss: 0.1650 - val_mae: 0.2814\n",
      "Epoch 214/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.0882 - val_loss: 0.1757 - val_mae: 0.2915\n",
      "Epoch 215/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0802 - val_loss: 0.1628 - val_mae: 0.2777\n",
      "Epoch 216/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.0773 - val_loss: 0.1751 - val_mae: 0.2869\n",
      "Epoch 217/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.0886 - val_loss: 0.1808 - val_mae: 0.2892\n",
      "Epoch 218/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0863 - val_loss: 0.1658 - val_mae: 0.2762\n",
      "Epoch 219/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0727 - val_loss: 0.1826 - val_mae: 0.2901\n",
      "Epoch 220/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0918 - val_loss: 0.1654 - val_mae: 0.2778\n",
      "Epoch 221/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 0.1011 - val_loss: 0.1773 - val_mae: 0.2879\n",
      "Epoch 222/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0745 - val_loss: 0.1675 - val_mae: 0.2782\n",
      "Epoch 223/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.0823 - val_loss: 0.1588 - val_mae: 0.2734\n",
      "Epoch 224/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 0.0935 - val_loss: 0.1911 - val_mae: 0.2964\n",
      "Epoch 225/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0889 - val_loss: 0.1703 - val_mae: 0.2830\n",
      "Epoch 226/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0184 - mae: 0.0971 - val_loss: 0.1663 - val_mae: 0.2815\n",
      "Epoch 227/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0895 - val_loss: 0.1734 - val_mae: 0.2896\n",
      "Epoch 228/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0275 - mae: 0.1166 - val_loss: 0.1726 - val_mae: 0.2852\n",
      "Epoch 229/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0209 - mae: 0.1026 - val_loss: 0.1797 - val_mae: 0.2885\n",
      "Epoch 230/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0212 - mae: 0.1032 - val_loss: 0.1746 - val_mae: 0.2846\n",
      "Epoch 231/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.0745 - val_loss: 0.1624 - val_mae: 0.2807\n",
      "Epoch 232/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0587 - val_loss: 0.1674 - val_mae: 0.2780\n",
      "Epoch 233/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0541 - val_loss: 0.1635 - val_mae: 0.2753\n",
      "Epoch 234/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0514 - val_loss: 0.1606 - val_mae: 0.2707\n",
      "Epoch 235/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0446 - val_loss: 0.1599 - val_mae: 0.2732\n",
      "Epoch 236/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0028 - mae: 0.0383 - val_loss: 0.1594 - val_mae: 0.2719\n",
      "Epoch 237/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0361 - val_loss: 0.1572 - val_mae: 0.2700\n",
      "Epoch 238/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0391 - val_loss: 0.1576 - val_mae: 0.2734\n",
      "Epoch 239/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0314 - val_loss: 0.1581 - val_mae: 0.2691\n",
      "Epoch 240/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0350 - val_loss: 0.1537 - val_mae: 0.2695\n",
      "Epoch 241/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0327 - val_loss: 0.1611 - val_mae: 0.2724\n",
      "Epoch 242/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0017 - mae: 0.0300 - val_loss: 0.1625 - val_mae: 0.2726\n",
      "Epoch 243/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.1643 - val_mae: 0.2763\n",
      "Epoch 244/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0780 - val_loss: 0.1657 - val_mae: 0.2793\n",
      "Epoch 245/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0868 - val_loss: 0.1670 - val_mae: 0.2779\n",
      "Epoch 246/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0861 - val_loss: 0.1695 - val_mae: 0.2789\n",
      "Epoch 247/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.0857 - val_loss: 0.1656 - val_mae: 0.2814\n",
      "Epoch 248/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0677 - val_loss: 0.1738 - val_mae: 0.2857\n",
      "Epoch 249/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0667 - val_loss: 0.1662 - val_mae: 0.2755\n",
      "Epoch 250/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0591 - val_loss: 0.1596 - val_mae: 0.2713\n",
      "Epoch 251/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0587 - val_loss: 0.1618 - val_mae: 0.2777\n",
      "Epoch 252/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0766 - val_loss: 0.1881 - val_mae: 0.2967\n",
      "Epoch 253/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0801 - val_loss: 0.1671 - val_mae: 0.2878\n",
      "Epoch 254/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0157 - mae: 0.0916 - val_loss: 0.1679 - val_mae: 0.2827\n",
      "Epoch 255/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0842 - val_loss: 0.1625 - val_mae: 0.2761\n",
      "Epoch 256/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0608 - val_loss: 0.1602 - val_mae: 0.2746\n",
      "Epoch 257/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0527 - val_loss: 0.1569 - val_mae: 0.2681\n",
      "Epoch 258/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0448 - val_loss: 0.1605 - val_mae: 0.2716\n",
      "Epoch 259/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0438 - val_loss: 0.1605 - val_mae: 0.2722\n",
      "Epoch 260/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0410 - val_loss: 0.1527 - val_mae: 0.2664\n",
      "Epoch 261/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0368 - val_loss: 0.1580 - val_mae: 0.2682\n",
      "Epoch 262/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.1577 - val_mae: 0.2691\n",
      "Epoch 263/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.1513 - val_mae: 0.2635\n",
      "Epoch 264/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0549 - val_loss: 0.1667 - val_mae: 0.2747\n",
      "Epoch 265/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0603 - val_loss: 0.1721 - val_mae: 0.2828\n",
      "Epoch 266/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0701 - val_loss: 0.1886 - val_mae: 0.2912\n",
      "Epoch 267/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0154 - mae: 0.0891 - val_loss: 0.1739 - val_mae: 0.2906\n",
      "Epoch 268/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0226 - mae: 0.1078 - val_loss: 0.1694 - val_mae: 0.2884\n",
      "Epoch 269/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0190 - mae: 0.0997 - val_loss: 0.1667 - val_mae: 0.2836\n",
      "Epoch 270/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0982 - val_loss: 0.1676 - val_mae: 0.2812\n",
      "Epoch 271/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0873 - val_loss: 0.1755 - val_mae: 0.2924\n",
      "Epoch 272/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0151 - mae: 0.0875 - val_loss: 0.1726 - val_mae: 0.2834\n",
      "Epoch 273/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0731 - val_loss: 0.1589 - val_mae: 0.2753\n",
      "Epoch 274/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0653 - val_loss: 0.1717 - val_mae: 0.2893\n",
      "Epoch 275/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.0698 - val_loss: 0.1575 - val_mae: 0.2732\n",
      "Epoch 276/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0547 - val_loss: 0.1565 - val_mae: 0.2715\n",
      "Epoch 277/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0434 - val_loss: 0.1576 - val_mae: 0.2698\n",
      "Epoch 278/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0366 - val_loss: 0.1559 - val_mae: 0.2675\n",
      "Epoch 279/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.1560 - val_mae: 0.2678\n",
      "Epoch 280/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.1551 - val_mae: 0.2652\n",
      "Epoch 281/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.1550 - val_mae: 0.2665\n",
      "Epoch 282/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.1562 - val_mae: 0.2687\n",
      "Epoch 283/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.1615 - val_mae: 0.2712\n",
      "Epoch 284/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.1565 - val_mae: 0.2683\n",
      "Epoch 285/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.1587 - val_mae: 0.2697\n",
      "Epoch 286/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0325 - val_loss: 0.1582 - val_mae: 0.2686\n",
      "Epoch 287/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0024 - mae: 0.0352 - val_loss: 0.1559 - val_mae: 0.2711\n",
      "Epoch 288/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0407 - val_loss: 0.1629 - val_mae: 0.2788\n",
      "Epoch 289/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0581 - val_loss: 0.1653 - val_mae: 0.2778\n",
      "Epoch 290/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0251 - mae: 0.1110 - val_loss: 0.1709 - val_mae: 0.2878\n",
      "Epoch 291/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0247 - mae: 0.1139 - val_loss: 0.1676 - val_mae: 0.2848\n",
      "Epoch 292/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0425 - mae: 0.1522 - val_loss: 0.2145 - val_mae: 0.3475\n",
      "Epoch 293/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1649 - mae: 0.2937 - val_loss: 0.2245 - val_mae: 0.3545\n",
      "Epoch 294/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0672 - mae: 0.2014 - val_loss: 0.1658 - val_mae: 0.3029\n",
      "Epoch 295/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0337 - mae: 0.1462 - val_loss: 0.1857 - val_mae: 0.3118\n",
      "Epoch 296/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0262 - mae: 0.1276 - val_loss: 0.1743 - val_mae: 0.3021\n",
      "Epoch 297/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.1036 - val_loss: 0.1630 - val_mae: 0.2869\n",
      "Epoch 298/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0879 - val_loss: 0.1624 - val_mae: 0.2855\n",
      "Epoch 299/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0713 - val_loss: 0.1605 - val_mae: 0.2850\n",
      "Epoch 300/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0587 - val_loss: 0.1566 - val_mae: 0.2821\n",
      "Epoch 301/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0527 - val_loss: 0.1589 - val_mae: 0.2810\n",
      "Epoch 302/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0528 - val_loss: 0.1567 - val_mae: 0.2778\n",
      "Epoch 303/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0435 - val_loss: 0.1593 - val_mae: 0.2801\n",
      "Epoch 304/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0415 - val_loss: 0.1604 - val_mae: 0.2806\n",
      "Epoch 305/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0028 - mae: 0.0408 - val_loss: 0.1564 - val_mae: 0.2767\n",
      "Epoch 306/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0339 - val_loss: 0.1580 - val_mae: 0.2765\n",
      "Epoch 307/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.1582 - val_mae: 0.2764\n",
      "Epoch 308/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.1557 - val_mae: 0.2748\n",
      "Epoch 309/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.1592 - val_mae: 0.2761\n",
      "Epoch 310/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.1560 - val_mae: 0.2729\n",
      "Epoch 311/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.1558 - val_mae: 0.2737\n",
      "Epoch 312/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 9.4045e-04 - mae: 0.0238 - val_loss: 0.1591 - val_mae: 0.2756\n",
      "Epoch 313/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 8.6311e-04 - mae: 0.0230 - val_loss: 0.1562 - val_mae: 0.2708\n",
      "Epoch 314/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 7.5755e-04 - mae: 0.0214 - val_loss: 0.1555 - val_mae: 0.2723\n",
      "Epoch 315/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 6.8623e-04 - mae: 0.0205 - val_loss: 0.1573 - val_mae: 0.2723\n",
      "Epoch 316/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 5.7198e-04 - mae: 0.0188 - val_loss: 0.1570 - val_mae: 0.2715\n",
      "Epoch 317/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 4.9171e-04 - mae: 0.0175 - val_loss: 0.1564 - val_mae: 0.2710\n",
      "Epoch 318/10000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 4.5917e-04 - mae: 0.0170 - val_loss: 0.1569 - val_mae: 0.2709\n",
      "Epoch 319/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 6.0032e-04 - mae: 0.0194 - val_loss: 0.1563 - val_mae: 0.2709\n",
      "Epoch 320/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 0.1578 - val_mae: 0.2721\n",
      "Epoch 321/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0374 - val_loss: 0.1580 - val_mae: 0.2716\n",
      "Epoch 322/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0434 - val_loss: 0.1607 - val_mae: 0.2716\n",
      "Epoch 323/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0484 - val_loss: 0.1547 - val_mae: 0.2707\n",
      "Epoch 324/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0552 - val_loss: 0.1602 - val_mae: 0.2740\n",
      "Epoch 325/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0568 - val_loss: 0.1721 - val_mae: 0.2835\n",
      "Epoch 326/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.0904 - val_loss: 0.1701 - val_mae: 0.2868\n",
      "Epoch 327/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.0869 - val_loss: 0.1544 - val_mae: 0.2711\n",
      "Epoch 328/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0211 - mae: 0.1045 - val_loss: 0.1745 - val_mae: 0.2845\n",
      "Epoch 329/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.0865 - val_loss: 0.1588 - val_mae: 0.2758\n",
      "Epoch 330/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0828 - val_loss: 0.1760 - val_mae: 0.2901\n",
      "Epoch 331/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0791 - val_loss: 0.1657 - val_mae: 0.2789\n",
      "Epoch 332/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0656 - val_loss: 0.1631 - val_mae: 0.2753\n",
      "Epoch 333/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0550 - val_loss: 0.1629 - val_mae: 0.2726\n",
      "Epoch 334/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0451 - val_loss: 0.1601 - val_mae: 0.2732\n",
      "Epoch 335/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0444 - val_loss: 0.1560 - val_mae: 0.2692\n",
      "Epoch 336/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0476 - val_loss: 0.1573 - val_mae: 0.2700\n",
      "Epoch 337/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0471 - val_loss: 0.1639 - val_mae: 0.2766\n",
      "Epoch 338/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0616 - val_loss: 0.1609 - val_mae: 0.2754\n",
      "Epoch 339/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0501 - val_loss: 0.1623 - val_mae: 0.2740\n",
      "Epoch 340/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 0.1617 - val_mae: 0.2717\n",
      "Epoch 341/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0493 - val_loss: 0.1603 - val_mae: 0.2725\n",
      "Epoch 342/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0465 - val_loss: 0.1563 - val_mae: 0.2688\n",
      "Epoch 343/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0409 - val_loss: 0.1576 - val_mae: 0.2699\n",
      "Epoch 344/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0420 - val_loss: 0.1585 - val_mae: 0.2705\n",
      "Epoch 345/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0397 - val_loss: 0.1572 - val_mae: 0.2707\n",
      "Epoch 346/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0341 - val_loss: 0.1632 - val_mae: 0.2773\n",
      "Epoch 347/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0474 - val_loss: 0.1592 - val_mae: 0.2738\n",
      "Epoch 348/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0569 - val_loss: 0.1651 - val_mae: 0.2748\n",
      "Epoch 349/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0638 - val_loss: 0.1778 - val_mae: 0.2872\n",
      "Epoch 350/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0647 - val_loss: 0.1772 - val_mae: 0.2873\n",
      "Epoch 351/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.0821 - val_loss: 0.1751 - val_mae: 0.2827\n",
      "Epoch 352/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0878 - val_loss: 0.1745 - val_mae: 0.2814\n",
      "Epoch 353/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 0.1021 - val_loss: 0.1712 - val_mae: 0.2884\n",
      "Epoch 354/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0900 - val_loss: 0.1895 - val_mae: 0.3076\n",
      "Epoch 355/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0723 - val_loss: 0.1599 - val_mae: 0.2756\n",
      "Epoch 356/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0532 - val_loss: 0.1543 - val_mae: 0.2707\n",
      "Epoch 357/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0411 - val_loss: 0.1602 - val_mae: 0.2716\n",
      "Epoch 358/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.1594 - val_mae: 0.2703\n",
      "Epoch 359/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.1556 - val_mae: 0.2688\n",
      "Epoch 360/10000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.1565 - val_mae: 0.2697\n",
      "Epoch 361/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0326 - val_loss: 0.1562 - val_mae: 0.2710\n",
      "Epoch 362/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0335 - val_loss: 0.1552 - val_mae: 0.2664\n",
      "Epoch 363/10000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.1624 - val_mae: 0.2729\n",
      "Epoch 00363: early stopping\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:38:44.261692\n"
     ]
    }
   ],
   "source": [
    "# learning\n",
    "\n",
    "result_y_test=[]\n",
    "result_y_pred=[]\n",
    "\n",
    "count = 0\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "for train_index, test_index in logo.split(X, y, sessions):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=100, stratify=y_train)\n",
    "    \n",
    "    # Feature standardization\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train=scaler.transform(X_train)\n",
    "    X_val=scaler.transform(X_val)\n",
    "    X_test=scaler.transform(X_test)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(optimizer=opt,  \n",
    "                  loss='mse', \n",
    "                  metrics=['mae'])\n",
    "\n",
    "    # fit\n",
    "    history = model.fit(X_train, y_train,  \n",
    "                        batch_size=100,  \n",
    "                        epochs=10000,      \n",
    "                        verbose=1,       \n",
    "                        validation_data=(X_val, y_val), \n",
    "                        callbacks=(early_stopping))\n",
    "\n",
    "    # prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # add result\n",
    "    result_y_test.append(y_test)\n",
    "    result_y_pred.append(y_pred)\n",
    "    \n",
    "    count += 1\n",
    "    print(count)\n",
    "    \n",
    "    compare_TV(history, \"mae\", \"val_mae\")\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>9.298397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>9.199242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>8.491396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>8.901321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>9.432898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2189 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.005669\n",
       "1     0.005669\n",
       "2     0.005669\n",
       "3     0.005669\n",
       "4     0.005669\n",
       "...        ...\n",
       "2184  9.298397\n",
       "2185  9.199242\n",
       "2186  8.491396\n",
       "2187  8.901321\n",
       "2188  9.432898\n",
       "\n",
       "[2189 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Regressor\n",
      "###########################\n",
      "Med-abs-err:  0.35\n",
      "Max-err:  4.4564\n",
      "R2_score:  0.9435\n",
      "###########################\n"
     ]
    }
   ],
   "source": [
    "print('DNN Regressor')\n",
    "print('###########################')\n",
    "print('Med-abs-err: ',round(median_absolute_error(np.array(result_y_test).flatten(), np.array(result_y_pred).flatten()),3))\n",
    "print('Max-err: ',round(max_error(np.array(result_y_test).flatten(), np.array(result_y_pred).flatten()),4))\n",
    "print('R2_score: ',round(r2_score(np.array(result_y_test).flatten(), np.array(result_y_pred).flatten()),4))\n",
    "print('###########################')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
